/**
 * UnifiedMediaBunnyModule - MediaBunny æ¸²æŸ“ç³»ç»Ÿæ¨¡å—
 *
 * å®Œå…¨æ›¿ä»£ WebAV çš„æ¸²æŸ“ç³»ç»Ÿï¼Œä½¿ç”¨ MediaBunny å®ç°è‡ªå®šä¹‰æ¸²æŸ“å¾ªç¯
 *
 * æ ¸å¿ƒç‰¹ç‚¹ï¼š
 * - å®Œå…¨æ›¿ä»£ WebAV æ¸²æŸ“
 * - è‡ªå®ç°æ¸²æŸ“å¾ªç¯ï¼ˆä¸ä¾èµ– WebAV çš„ AVCanvasï¼‰
 * - Canvas ç”± Vue ç»„ä»¶ç®¡ç†ï¼Œé€šè¿‡ setCanvas() ä¼ å…¥
 * - ä½¿ç”¨ runtime.bunnyClip (è§†é¢‘/éŸ³é¢‘)ã€runtime.textBitmap (æ–‡æœ¬)ã€runtime.bunny.imageClip (å›¾ç‰‡)
 * - æš‚ä¸æ”¯æŒå¯¼å‡ºåŠŸèƒ½ï¼ˆæœªæ¥å¯æ‰©å±•ï¼‰
 * - ä¼˜å…ˆé¢„è§ˆæ€§èƒ½
 *
 * æ¶æ„è¯´æ˜ï¼š
 * - UnifiedPlaybackModule ä½œä¸ºä¸»æ§ï¼Œç®¡ç†æ‰€æœ‰æ’­æ”¾çŠ¶æ€
 * - UnifiedMediaBunnyModule åªè´Ÿè´£æ¸²æŸ“ï¼Œä¸ç»´æŠ¤ç‹¬ç«‹æ’­æ”¾çŠ¶æ€
 * - é€šè¿‡ç›‘å¬ playbackModule çš„çŠ¶æ€å˜åŒ–æ¥æ§åˆ¶æ¸²æŸ“å¾ªç¯
 */

import { ref, watch, type Ref } from 'vue'
import { workerTimer } from '@/core/mediabunny/worker-timer'
import { RENDERER_FPS, AUDIO_DEFAULT_SAMPLE_RATE } from '@/core/mediabunny/constant'
import { throttle } from 'lodash'
import { canEncodeAudio } from 'mediabunny'
import { registerMp3Encoder } from '@mediabunny/mp3-encoder'
import { ModuleRegistry, MODULE_NAMES } from './ModuleRegistry'
import type { UnifiedTimelineModule } from './UnifiedTimelineModule'
import type { UnifiedMediaModule } from './UnifiedMediaModule'
import type { UnifiedPlaybackModule } from './UnifiedPlaybackModule'
import type { UnifiedConfigModule } from './UnifiedConfigModule'
import type { UnifiedTrackModule } from './UnifiedTrackModule'
import type { UnifiedTimelineItemData } from '@/core/timelineitem/type'
import type { MediaType } from '@/core/mediaitem/types'
import type { WrappedAudioBuffer } from 'mediabunny'
import { applyAnimationToConfig } from '@/core/utils/animationInterpolation'
import { TimelineItemQueries } from '@/core/timelineitem/queries'
import {
  renderToCanvas,
  type FrameData,
  type RenderContext,
} from '@/core/bunnyUtils/canvasRenderer'
import { TimelineItemsBufferManager } from '@/core/mediabunny/TimelineItemsBufferManager'

if (!(await canEncodeAudio('mp3'))) {
  registerMp3Encoder()
  console.log('å·²æ³¨å†Œmp3ç¼–ç å™¨')
}

export function createUnifiedMediaBunnyModule(
  registry: ModuleRegistry,
  contentEndTimeFrames: Ref<number>,
) {
  const playbackModule = registry.get<UnifiedPlaybackModule>(MODULE_NAMES.PLAYBACK)
  const timelineModule = registry.get<UnifiedTimelineModule>(MODULE_NAMES.TIMELINE)
  const mediaModule = registry.get<UnifiedMediaModule>(MODULE_NAMES.MEDIA)
  const trackModule = registry.get<UnifiedTrackModule>(MODULE_NAMES.TRACK)

  // ==================== çŠ¶æ€å®šä¹‰ ====================

  // æ¨¡å—å°±ç»ªçŠ¶æ€
  const isMediaBunnyReady = ref(false)
  const mediaBunnyError = ref<string | null>(null)

  // Canvas ç›¸å…³ï¼ˆç”±å¤–éƒ¨ä¼ å…¥ï¼‰
  let mCanvas: HTMLCanvasElement | null = null
  let mCtx: CanvasRenderingContext2D | null = null

  // æ¸²æŸ“å¾ªç¯ç›¸å…³
  let mRenderLoopCleanup: (() => void) | null = null
  const mExpectFrameTime: number = 1000 / RENDERER_FPS
  let mUpdatingClip: boolean = false

  // âœ¨ åŒç¼“å†²ç®¡ç†å™¨
  let mBufferManager: TimelineItemsBufferManager | null = null

  // Web Audio API ç›¸å…³
  let mAudioContext: AudioContext | null = null
  let mGainNode: GainNode | null = null

  // éŸ³é¢‘è°ƒåº¦ç›¸å…³
  const mQueuedAudioNodes = new Set<AudioBufferSourceNode>()

  // æ—¶é—´åŒæ­¥é”šç‚¹ï¼ˆç”¨äºéŸ³é¢‘è°ƒåº¦ï¼‰
  let mAudioContextStartTime: number | null = null
  let mPlaybackTimeAtStart: number = 0

  // å½“å‰bunnyæ’­æ”¾å¸§æ•°ï¼ˆæ•´æ•°ï¼‰
  const mCurrentBunnyFrame = ref(0)
  // é¡¹ç›®æ—¶é•¿ï¼ˆå¸§æ•°ï¼‰
  let mTimelineDuration: number = 0

  // bunnyCurFrame æ˜ å°„è¡¨ï¼ˆkey: timelineItemId, value: FrameDataï¼‰
  const mBunnyCurFrameMap = new Map<string, FrameData>()

  // ==================== ç”»å¸ƒç®¡ç† ====================

  /**
   * è®¾ç½® Canvas å…ƒç´ å¹¶åˆå§‹åŒ–æ¸²æŸ“ç³»ç»Ÿ
   * @param canvasElement Canvas å…ƒç´ å¼•ç”¨ï¼ˆä» BunnyRender.vue ä¼ å…¥ï¼‰
   */
  async function setCanvas(canvasElement: HTMLCanvasElement): Promise<void> {
    try {
      if (!canvasElement) {
        throw new Error('Canvas å…ƒç´ ä¸èƒ½ä¸ºç©º')
      }

      // è®¾ç½® Canvas å¼•ç”¨
      mCanvas = canvasElement
      mCtx = mCanvas.getContext('2d')

      if (!mCtx) {
        throw new Error('æ— æ³•è·å– Canvas 2D ä¸Šä¸‹æ–‡')
      }

      console.log('âœ… Canvas å…ƒç´ å·²è®¾ç½®', {
        width: mCanvas.width,
        height: mCanvas.height,
      })

      // âœ¨ åˆå§‹åŒ–ç¼“å†²ç®¡ç†å™¨
      mBufferManager = new TimelineItemsBufferManager(RENDERER_FPS)

      // åˆå§‹åŒ–éŸ³é¢‘ç³»ç»Ÿ
      initializeAudioSystem()
      // è®¾ç½®æ’­æ”¾ç›‘å¬å™¨
      setupPlaybackListeners()
      // åˆå§‹åŒ–å°±å¯åŠ¨æ¸²æŸ“å¾ªç¯
      startRenderLoop()

      // æ ‡è®°ä¸ºå°±ç»ª
      isMediaBunnyReady.value = true
      mediaBunnyError.value = null

      console.log('âœ… MediaBunny æ¸²æŸ“ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ')
    } catch (error) {
      const errorMessage = error instanceof Error ? error.message : String(error)
      mediaBunnyError.value = `MediaBunny åˆå§‹åŒ–å¤±è´¥: ${errorMessage}`
      isMediaBunnyReady.value = false
      throw error
    }
  }

  /**
   * é”€æ¯ MediaBunny æ¸²æŸ“ç³»ç»Ÿ
   */
  async function destroy(): Promise<void> {
    console.log('ğŸ§¹ æ¸…ç† MediaBunny æ¸²æŸ“ç³»ç»Ÿèµ„æº')

    // åœæ­¢æ¸²æŸ“å¾ªç¯
    stopRenderLoop()

    // åœæ­¢æ‰€æœ‰éŸ³é¢‘
    stopAllAudioNodes()

    // æ¸…ç©º Canvasï¼ˆå¦‚æœå­˜åœ¨ï¼‰
    if (mCanvas && mCtx) {
      mCtx.clearRect(0, 0, mCanvas.width, mCanvas.height)
    }

    // å…³é—­ AudioContext
    if (mAudioContext) {
      await mAudioContext.close()
      mAudioContext = null
    }

    // æ¸…ç† bunnyCurFrameMap ä¸­çš„æ‰€æœ‰ VideoSample
    for (const [itemId, frameData] of mBunnyCurFrameMap) {
      frameData.videoSample.close()
    }
    mBunnyCurFrameMap.clear()

    // âœ¨ æ¸…ç†ç¼“å†²ç®¡ç†å™¨
    if (mBufferManager) {
      mBufferManager.clearBuffers()
      mBufferManager = null
    }

    // æ¸…ç†å¼•ç”¨ï¼ˆä¸åˆ é™¤ canvas å…ƒç´ ï¼Œç”± Vue ç»„ä»¶ç®¡ç†ï¼‰
    mCanvas = null
    mCtx = null
    mGainNode = null

    // æ¸…ç†çŠ¶æ€
    isMediaBunnyReady.value = false

    console.log('âœ… MediaBunny æ¸²æŸ“ç³»ç»Ÿèµ„æºæ¸…ç†å®Œæˆ')
  }

  // ==================== æ¸²æŸ“å¾ªç¯ ====================

  /**
   * å¯åŠ¨æ¸²æŸ“å¾ªç¯
   */
  function startRenderLoop(): void {
    if (mRenderLoopCleanup) {
      console.warn('âš ï¸ æ¸²æŸ“å¾ªç¯å·²åœ¨è¿è¡Œ')
      return
    }

    const renderStart = performance.now()
    let renderRunCnt = 0
    mRenderLoopCleanup = workerTimer(() => {
      // ä½¿ç”¨çœŸå®æ—¶é—´ä½œä¸ºåŸºå‡†ï¼Œé¿å…éŸ³ç”»ä¸åŒæ­¥
      if ((performance.now() - renderStart) / (mExpectFrameTime * renderRunCnt) < 1) {
        return
      }

      // æ’­æ”¾çš„æƒ…å†µä¸‹ï¼Œä¼šåŸºäºçœŸå®æ—¶é—´å•è°ƒå¢é•¿è·å–å½“å‰æ’­æ”¾æ—¶é—´ï¼ˆç§’ï¼‰
      // æš‚åœçš„æƒ…å†µä¸‹ï¼Œä¼šä½¿ç”¨mPlaybackTimeAtStartä½œä¸ºåŸºå‡†ï¼Œå³seekçš„æ—¶å€™åªéœ€è¦æ›´æ–°mPlaybackTimeAtStartå°±è¡Œäº†
      // ç„¶åå†æ¥è®¡ç®—å½“å‰æ’­æ”¾å¸§æ•°
      let currentTime = Math.floor(getCurrentPlaybackTime() * RENDERER_FPS)

      // æ£€æŸ¥æ˜¯å¦æ’­æ”¾ç»“æŸ
      if (playbackModule.isPlaying.value && currentTime >= mTimelineDuration) {
        playbackModule.setPlaying(false)
        playbackModule.setCurrentFrame(mTimelineDuration)
        console.log('âœ… æ’­æ”¾ç»“æŸ')
        return
      }

      // ä¸æ–­æ›´æ–°clipå¸§æ•°æ®,å¦‚æœæ˜¯æ’­æ”¾åˆ™éœ€è¦è§£ç éŸ³é¢‘
      updateClips(timelineModule.timelineItems.value, currentTime, playbackModule.isPlaying.value)
      if (playbackModule.isPlaying.value) {
        playbackModule.setCurrentFrame(currentTime)
      }

      // æ¸²æŸ“åˆ° Canvasï¼ˆä½¿ç”¨ bunnyCurFrameMap å’Œ runtime ä¸­çš„æ•°æ®ï¼‰
      renderToCanvasWrapper(timelineModule.timelineItems.value, currentTime)

      renderRunCnt++
    }, mExpectFrameTime)

    console.log('ğŸ¬ MediaBunny æ¸²æŸ“å¾ªç¯å·²å¯åŠ¨')
  }

  /**
   * åœæ­¢æ¸²æŸ“å¾ªç¯
   */
  function stopRenderLoop(): void {
    if (mRenderLoopCleanup) {
      mRenderLoopCleanup()
      mRenderLoopCleanup = null
      console.log('â¸ï¸ MediaBunny æ¸²æŸ“å¾ªç¯å·²åœæ­¢')
    }
  }

  /**
   * è·å–å½“å‰æ’­æ”¾æ—¶é—´
   * ä½¿ç”¨ AudioContext æ—¶é’Ÿä½œä¸ºåŸºå‡†ï¼Œç¡®ä¿ç²¾ç¡®åŒæ­¥
   */
  function getCurrentPlaybackTime(): number {
    if (!playbackModule.isPlaying.value || !mAudioContext || mAudioContextStartTime === null) {
      return mPlaybackTimeAtStart
    }

    return mAudioContext.currentTime - mAudioContextStartTime + mPlaybackTimeAtStart
  }

  /**
   * æ›´æ–°å•ä¸ª clip çš„å¸§æ•°æ®
   * å¼‚æ­¥è°ƒç”¨ bunnyClip.tickN() æ›´æ–° bunnyCurFrameMap å’Œå¤„ç†éŸ³é¢‘
   * @param item æ—¶é—´è½´é¡¹ç›®
   * @param currentTime å½“å‰æ—¶é—´ï¼ˆå¸§æ•°ï¼‰
   * @param shouldPlayAudio æ˜¯å¦åº”è¯¥æ’­æ”¾éŸ³é¢‘ï¼ˆè€ƒè™‘è½¨é“å’Œé¡¹ç›®é™éŸ³çŠ¶æ€ï¼‰
   */
  async function updateClipFrame(
    item: UnifiedTimelineItemData<MediaType>,
    currentTime: number,
    shouldPlayAudio: boolean,
    volume: number,
  ): Promise<void> {
    const bunnyClip = item.runtime.bunnyClip
    if (!bunnyClip) return

    // æ£€æŸ¥å½“å‰å¸§æ•°æ˜¯å¦éœ€è¦æ›´æ–°
    const frameData = mBunnyCurFrameMap.get(item.id)
    if (frameData?.frameNumber === currentTime) {
      // å¸§æ•°ç›¸åŒï¼Œè·³è¿‡æ›´æ–°
      return
    }

    // å¼‚æ­¥æ›´æ–°å¸§æ•°æ®
    // tickN å†…éƒ¨é™åˆ¶å¿…é¡»è§£ç å®Œæ‰èƒ½è§£ç ä¸‹ä¸€ä¸ª
    // æœªè§£ç å®Œå°±å†æ¬¡æ‰§è¡Œ tickN ä¼šè¿”å› â€˜skipâ€™
    // è¿™æ˜¯ç¬¬äºŒå±‚é¢‘ç‡é™åˆ¶
    const { audio, video, state } = await bunnyClip.tickN(
      BigInt(currentTime),
      shouldPlayAudio, //æ ¹æ®è½¨é“å’Œé¡¹ç›®é™éŸ³çŠ¶æ€å†³å®šæ˜¯å¦è¯·æ±‚éŸ³é¢‘
      true, //æ€»æ˜¯è¯·æ±‚è§†é¢‘å¸§
    )
    if (state === 'skip') {
      // ä»€ä¹ˆéƒ½ä¸åšï¼Œè°ƒç”¨ tickN å¤ªé¢‘ç¹äº†
    } else if (state === 'success') {
      // æ›´æ–° bunnyCurFrameMap
      if (video) {
        const oldFrame = mBunnyCurFrameMap.get(item.id)
        oldFrame?.videoSample.close()
        mBunnyCurFrameMap.set(item.id, {
          frameNumber: currentTime,
          clockwiseRotation: bunnyClip.clockwiseRotation,
          videoSample: video,
        })
      }

      // è°ƒåº¦éŸ³é¢‘ï¼ˆåªåœ¨éœ€è¦æ’­æ”¾éŸ³é¢‘æ—¶ï¼‰
      if (shouldPlayAudio && audio) {
        scheduleAudioBuffers(audio, bunnyClip.getPlaybackRate(), volume)
      }
    } else {
      // æ¸…ç†æ— æ•ˆå¸§
      const oldFrame = mBunnyCurFrameMap.get(item.id)
      oldFrame?.videoSample.close()
      mBunnyCurFrameMap.delete(item.id)
    }
  }

  /**
   * æ›´æ–°æ‰€æœ‰ clips
   * è°ƒç”¨ bunnyClip.tickN() æ›´æ–° bunnyCurFrameMap å’Œå¤„ç†éŸ³é¢‘
   */
  function updateClips(
    timelineItems: UnifiedTimelineItemData<MediaType>[],
    currentTime: number,
    playAudio: boolean,
  ): void {
    // mUpdatingClip å¯ä»¥é˜²æ­¢è¿‡åº¦æ›´æ–°
    // è¿™æ˜¯ç¬¬ä¸€å±‚é˜²å¾¡ï¼Œç¬¬äºŒå±‚åœ¨clipå†…éƒ¨æ¥é™åˆ¶è¿‡åº¦æ›´æ–°
    if (mUpdatingClip) return
    mUpdatingClip = true

    // âœ¨ ä½¿ç”¨ç¼“å†²ç®¡ç†å™¨è·å–è¦å¤„ç†çš„ items
    const itemsToProcess =
      mBufferManager && playbackModule.isPlaying.value
        ? mBufferManager.getItemsForRendering(timelineItems, currentTime)
        : timelineItems

    // âœ¨ æ£€æŸ¥æ˜¯å¦éœ€è¦æ›´æ–°åå°ç¼“å†²
    if (
      playbackModule.isPlaying.value &&
      mBufferManager &&
      mBufferManager.shouldUpdateBuffer(currentTime)
    ) {
      // å¼‚æ­¥æ›´æ–°åå°ç¼“å†²ï¼Œä¸é˜»å¡å½“å‰æ¸²æŸ“
      void mBufferManager.updateBackBuffer(timelineItems, currentTime)
    }

    for (const item of itemsToProcess) {
      // åº”ç”¨åŠ¨ç”»æ’å€¼åˆ° config
      applyAnimationToConfig(item, currentTime)

      // å¤„ç†è§†é¢‘/éŸ³é¢‘
      if (
        TimelineItemQueries.isVideoTimelineItem(item) ||
        TimelineItemQueries.isAudioTimelineItem(item)
      ) {
        const track = trackModule.getTrack(item.trackId || '')
        const isTrackMuted = track?.isMuted ?? false

        // âœ… ä½¿ç”¨è¾…åŠ©å‡½æ•°è·å–æ¸²æŸ“é…ç½®ï¼ˆåŒ…å«åŠ¨ç”»æ’å€¼åçš„éŸ³é‡ï¼‰
        const config = TimelineItemQueries.getRenderConfig(item)
        const isItemMuted = config.isMuted ?? false
        const itemVolume = config.volume ?? 1.0
        const shouldPlayAudio = playAudio && !isTrackMuted && !isItemMuted

        // æ›´æ–° clip å¸§æ•°æ®ï¼ˆä¸ç­‰å¾…å®Œæˆï¼Œä½¿ç”¨ voidï¼‰
        // è¿™é‡Œä¸ç­‰å¾…ï¼Œå› æ­¤ä¼šåå°æ‰§è¡Œï¼Œé£å¿«åœ°è·³è¿‡è¿™é‡Œï¼Œå¯¼è‡´æ•´ä¸ª updateClips éƒ½ä¼šå¿«é€Ÿæ‰§è¡Œä¸€é
        // æŒ‰ç…§ workerTimer é¢‘ç‡æ¥æ‰§è¡Œï¼Œå¯èƒ½ä¼šåœ¨è§£ç æ…¢è·Ÿä¸ä¸Šçš„æ—¶å€™å¤šæ¬¡é‡å¤æ‰§è¡Œ
        // å› æ­¤å†…éƒ¨ä¹Ÿéœ€è¦ä¸€äº›ç­–ç•¥æ¥é™åˆ¶é¢‘ç‡
        void updateClipFrame(item, currentTime, shouldPlayAudio, itemVolume)
      }
    }

    mCurrentBunnyFrame.value = currentTime
    mUpdatingClip = false
  }

  /**
   * æ¸²æŸ“åˆ° Canvas çš„åŒ…è£…å‡½æ•°
   * è°ƒç”¨ç‹¬ç«‹çš„ renderToCanvas å·¥å…·å‡½æ•°
   *
   * @param timelineItems æ—¶é—´è½´é¡¹ç›®åˆ—è¡¨
   * @param currentTimeN å½“å‰æ’­æ”¾æ—¶é—´ï¼ˆå¸§æ•°ï¼‰
   */
  function renderToCanvasWrapper(
    timelineItems: UnifiedTimelineItemData<MediaType>[],
    currentTimeN: number,
  ): void {
    if (!mCanvas || !mCtx) return

    // æ„å»ºæ¸²æŸ“ä¸Šä¸‹æ–‡
    const renderContext: RenderContext = {
      canvas: mCanvas,
      ctx: mCtx,
      bunnyCurFrameMap: mBunnyCurFrameMap,
      getTrack: (trackId: string) => trackModule.getTrack(trackId),
      getMediaItem: (mediaItemId: string) => mediaModule.getMediaItem(mediaItemId),
      trackIndexMap: trackModule.trackIndexMap.value,
    }

    // è°ƒç”¨ç‹¬ç«‹çš„æ¸²æŸ“å‡½æ•°
    renderToCanvas(renderContext, timelineItems, currentTimeN)
  }

  // ==================== éŸ³é¢‘ç³»ç»Ÿ ====================

  /**
   * åˆå§‹åŒ–éŸ³é¢‘ç³»ç»Ÿ
   */
  function initializeAudioSystem(): void {
    mAudioContext = new AudioContext({
      sampleRate: AUDIO_DEFAULT_SAMPLE_RATE,
    })
    mGainNode = mAudioContext.createGain()
    mGainNode.connect(mAudioContext.destination)
    console.log(`ğŸ§ AudioContext å·²åˆ›å»ºï¼Œé‡‡æ ·ç‡: ${mAudioContext.sampleRate}Hz`)
  }

  /**
   * è°ƒåº¦éŸ³é¢‘ç¼“å†²
   */
  function scheduleAudioBuffers(
    wrappedBuffers: WrappedAudioBuffer[],
    rate: number,
    volume: number,
  ): void {
    if (!mAudioContext || !mGainNode) return

    for (const wrapped of wrappedBuffers) {
      const node = mAudioContext.createBufferSource()
      node.buffer = wrapped.buffer // ç›´æ¥ä½¿ç”¨ AudioBufferï¼Œæ— éœ€è½¬æ¢
      node.playbackRate.value = rate

      // ä¸ºæ¯ä¸ªéŸ³é¢‘èŠ‚ç‚¹åˆ›å»ºç‹¬ç«‹çš„å¢ç›ŠèŠ‚ç‚¹ä»¥æ§åˆ¶éŸ³é‡
      const gainNode = mAudioContext.createGain()
      gainNode.gain.value = volume
      node.connect(gainNode)
      gainNode.connect(mGainNode)

      const startTimestamp = mAudioContextStartTime! + wrapped.timestamp - mPlaybackTimeAtStart
      const curTime = mAudioContext.currentTime
      if (startTimestamp >= curTime) {
        node.start(startTimestamp)
      } else {
        node.start(curTime, curTime - startTimestamp)
      }
      mQueuedAudioNodes.add(node)
      node.onended = () => {
        mQueuedAudioNodes.delete(node)
      }

      // âœ… ä¸éœ€è¦ close()ï¼ŒAudioBuffer ç”±æµè§ˆå™¨è‡ªåŠ¨ç®¡ç†
    }
  }

  /**
   * åœæ­¢æ‰€æœ‰éŸ³é¢‘èŠ‚ç‚¹
   */
  function stopAllAudioNodes(): void {
    for (const node of mQueuedAudioNodes) {
      try {
        node.stop()
      } catch (err) {
        // å¿½ç•¥å·²åœæ­¢çš„èŠ‚ç‚¹
      }
    }
    mQueuedAudioNodes.clear()
  }

  // ==================== æ’­æ”¾æ§åˆ¶ ====================

  /**
   * å¯åŠ¨ MediaBunny æ¸²æŸ“å¾ªç¯
   * ç”± UnifiedPlaybackModule è°ƒç”¨
   */
  async function startPlayback(): Promise<void> {
    if (!mAudioContext) {
      console.error('æœªåˆå§‹åŒ– AudioContext')
      return
    }

    if (mAudioContext && mAudioContext.state === 'suspended') {
      await mAudioContext.resume()
    }

    // è®¾ç½®éŸ³é¢‘æ—¶é—´é”šç‚¹
    mAudioContextStartTime = mAudioContext!.currentTime
    mPlaybackTimeAtStart = playbackModule.currentFrame.value / RENDERER_FPS

    console.log('â–¶ï¸ MediaBunny å¼€å§‹æ’­æ”¾')
  }

  /**
   * åœæ­¢ MediaBunny æ¸²æŸ“å¾ªç¯
   * ç”± UnifiedPlaybackModule è°ƒç”¨
   */
  async function stopPlayback(): Promise<void> {
    // åœæ­¢æ‰€æœ‰éŸ³é¢‘
    stopAllAudioNodes()

    // æ›´æ–°æ’­æ”¾æ—¶é—´é”šç‚¹
    mPlaybackTimeAtStart = playbackModule.currentFrame.value / RENDERER_FPS
  }

  /**
   * è·³è½¬åˆ°æŒ‡å®šå¸§
   * ç”± UnifiedPlaybackModule è°ƒç”¨
   */
  function seekToFrame(frames: number): void {
    stopAllAudioNodes()

    // âœ¨ Seek æ—¶æ¸…ç©ºæ‰€æœ‰ç¼“å†²
    if (mBufferManager) {
      mBufferManager.clearBuffers()
    }

    // seekåªéœ€è¦æ›´æ–° mPlaybackTimeAtStart å³å¯
    // æ¸²æŸ“å¾ªç¯ä¼šä¸æ–­ä»¥ mPlaybackTimeAtStart ä¸ºåŸºå‡†ç‚¹æ¥æ¸²æŸ“
    const clampedFrames = Math.max(0, Math.min(mTimelineDuration, frames))
    mPlaybackTimeAtStart = clampedFrames / RENDERER_FPS
  }

  /**
   * æ›´æ–°é¡¹ç›®æ—¶é•¿
   * @param newDurationN é¡¹ç›®æ—¶é•¿ï¼ˆå¸§æ•°ï¼Œnumberç±»å‹ï¼‰
   */
  function updateTimelineDuration(newDurationN: number): void {
    mTimelineDuration = newDurationN
    const durationSeconds = newDurationN / RENDERER_FPS
    console.log(`ğŸ¯ æ›´æ–°é¡¹ç›®æ—¶é•¿: ${durationSeconds.toFixed(2)}s ${newDurationN}å¸§`)
  }

  // ==================== äº‹ä»¶ç›‘å¬ ====================

  // åˆ›å»ºèŠ‚æµå‡½æ•°ï¼Œ100mså†…åªæ‰§è¡Œä¸€æ¬¡
  const throttledSeekToFrame = throttle(async (frame: number) => {
    seekToFrame(frame)
  }, 100)
  /**
   * è®¾ç½®æ’­æ”¾ç›‘å¬å™¨
   * ç›‘å¬ UnifiedPlaybackModule çš„çŠ¶æ€å˜åŒ–
   */
  function setupPlaybackListeners(): void {
    // ç›‘å¬å¸§æ•°å˜åŒ–ï¼ˆç”¨äº seekï¼‰
    watch([playbackModule.currentFrame, mCurrentBunnyFrame], ([new_cf, new_cbf]) => {
      if (new_cf != new_cbf && !playbackModule.isPlaying.value) {
        throttledSeekToFrame(new_cf)
      }
    })

    // ç›‘å¬æ—¶é—´è½´æ—¶é•¿å˜åŒ–ï¼Œè‡ªåŠ¨æ›´æ–° MediaBunny æ’­æ”¾å™¨æ—¶é•¿
    watch(
      contentEndTimeFrames,
      (newDurationFrames) => {
        updateTimelineDuration(newDurationFrames)
        console.log(`ğŸ¯ [MediaBunny] æ—¶é—´è½´æ—¶é•¿å˜åŒ–ï¼Œå·²æ›´æ–°æ’­æ”¾å™¨æ—¶é•¿: ${newDurationFrames}å¸§`)
      },
      { immediate: true },
    )

    console.log('âœ… MediaBunny æ’­æ”¾ç›‘å¬å™¨å·²è®¾ç½®')
  }

  // ==================== å·¥å…·æ–¹æ³• ====================

  /**
   * æ£€æŸ¥ MediaBunny æ˜¯å¦å¯ç”¨
   * @returns æ˜¯å¦å¯ç”¨
   */
  function isMediaBunnyAvailable(): boolean {
    return !!(mCanvas && mCtx && isMediaBunnyReady.value && !mediaBunnyError.value)
  }

  /**
   * é‡ç½® MediaBunny çŠ¶æ€ä¸ºé»˜è®¤å€¼
   */
  function resetToDefaults(): Promise<void> {
    return destroy()
  }

  // ==================== æˆªå¸§åŠŸèƒ½ ====================

  /**
   * æˆªå–å½“å‰ç”»å¸ƒç”»é¢å¹¶ä¸‹è½½
   * @param filename ä¸‹è½½æ–‡ä»¶åï¼ˆå¯é€‰ï¼Œé»˜è®¤ä¸º 'screenshot-æ—¶é—´æˆ³.png'ï¼‰
   * @returns Promise<Blob> è¿”å›æˆªå–çš„ Blob å¯¹è±¡
   */
  async function captureCanvasFrame(filename?: string): Promise<Blob> {
    if (!mCanvas || !mCtx) {
      throw new Error('Canvas æœªåˆå§‹åŒ–ï¼Œæ— æ³•æˆªå¸§')
    }

    try {
      // å°† Canvas å†…å®¹è½¬æ¢ä¸º Blob
      const blob = await new Promise<Blob>((resolve, reject) => {
        mCanvas!.toBlob(
          (blob) => {
            if (blob) {
              resolve(blob)
            } else {
              reject(new Error('Canvas è½¬æ¢ä¸º Blob å¤±è´¥'))
            }
          },
          'image/png',
          1.0, // æœ€é«˜è´¨é‡
        )
      })

      // ç”Ÿæˆæ–‡ä»¶å
      const timestamp = new Date().toISOString().replace(/[:.]/g, '-').slice(0, -5)
      const defaultFilename = `screenshot-${timestamp}.png`
      const finalFilename = filename || defaultFilename

      // åˆ›å»ºä¸‹è½½é“¾æ¥å¹¶è§¦å‘ä¸‹è½½
      const url = URL.createObjectURL(blob)
      const link = document.createElement('a')
      link.href = url
      link.download = finalFilename
      document.body.appendChild(link)
      link.click()
      document.body.removeChild(link)
      URL.revokeObjectURL(url)

      console.log(`ğŸ“¸ ç”»å¸ƒæˆªå¸§æˆåŠŸ: ${finalFilename}`)
      return blob
    } catch (error) {
      const errorMessage = error instanceof Error ? error.message : String(error)
      console.error('âŒ ç”»å¸ƒæˆªå¸§å¤±è´¥:', errorMessage)
      throw error
    }
  }

  // ==================== å¯¼å‡ºæ¥å£ ====================

  return {
    // çŠ¶æ€
    isMediaBunnyReady,
    mediaBunnyError,
    currentBunnyFrame: mCurrentBunnyFrame,

    // ç”»å¸ƒç®¡ç†
    setCanvas,
    destroy,

    // æ’­æ”¾æ§åˆ¶
    startPlayback,
    stopPlayback,
    seekToFrame,
    updateTimelineDuration,

    // æˆªå¸§åŠŸèƒ½
    captureCanvasFrame,

    // å·¥å…·æ–¹æ³•
    isMediaBunnyAvailable,
    resetToDefaults,
  }
}

// å¯¼å‡ºç±»å‹å®šä¹‰
export type UnifiedMediaBunnyModule = ReturnType<typeof createUnifiedMediaBunnyModule>
