/**
 * UnifiedMediaBunnyModule - MediaBunny æ¸²æŸ“ç³»ç»Ÿæ¨¡å—
 *
 * å®Œå…¨æ›¿ä»£ WebAV çš„æ¸²æŸ“ç³»ç»Ÿï¼Œä½¿ç”¨ MediaBunny å®ç°è‡ªå®šä¹‰æ¸²æŸ“å¾ªç¯
 *
 * æ ¸å¿ƒç‰¹ç‚¹ï¼š
 * - å®Œå…¨æ›¿ä»£ WebAV æ¸²æŸ“
 * - è‡ªå®ç°æ¸²æŸ“å¾ªç¯ï¼ˆä¸ä¾èµ– WebAV çš„ AVCanvasï¼‰
 * - Canvas ç”± Vue ç»„ä»¶ç®¡ç†ï¼Œé€šè¿‡ setCanvas() ä¼ å…¥
 * - ä½¿ç”¨ runtime.bunnyClip (è§†é¢‘/éŸ³é¢‘)ã€runtime.textBitmap (æ–‡æœ¬)ã€runtime.bunny.imageClip (å›¾ç‰‡)
 * - æš‚ä¸æ”¯æŒå¯¼å‡ºåŠŸèƒ½ï¼ˆæœªæ¥å¯æ‰©å±•ï¼‰
 * - ä¼˜å…ˆé¢„è§ˆæ€§èƒ½
 *
 * æ¶æ„è¯´æ˜ï¼š
 * - UnifiedPlaybackModule ä½œä¸ºä¸»æ§ï¼Œç®¡ç†æ‰€æœ‰æ’­æ”¾çŠ¶æ€
 * - UnifiedMediaBunnyModule åªè´Ÿè´£æ¸²æŸ“ï¼Œä¸ç»´æŠ¤ç‹¬ç«‹æ’­æ”¾çŠ¶æ€
 * - é€šè¿‡ç›‘å¬ playbackModule çš„çŠ¶æ€å˜åŒ–æ¥æ§åˆ¶æ¸²æŸ“å¾ªç¯
 */

import { ref, markRaw, watch, type Ref } from 'vue'
import { workerTimer } from '@/core/mediabunny/worker-timer'
import { RENDERER_FPS, AUDIO_DEFAULT_SAMPLE_RATE } from '@/core/mediabunny/constant'
import { throttle } from 'lodash'
import type { VideoSample } from 'mediabunny'
import { ModuleRegistry, MODULE_NAMES } from './ModuleRegistry'
import type { UnifiedTimelineModule } from './UnifiedTimelineModule'
import type { UnifiedMediaModule } from './UnifiedMediaModule'
import type { UnifiedPlaybackModule } from './UnifiedPlaybackModule'
import type { UnifiedConfigModule } from './UnifiedConfigModule'
import type { UnifiedTrackModule } from './UnifiedTrackModule'
import type { UnifiedTimelineItemData } from '@/core/timelineitem/type'
import type { MediaType } from '@/core/mediaitem/types'
import type { AudioSample } from 'mediabunny'
import { applyAnimationToConfig } from '@/core/utils/animationInterpolation'
import type { GetConfigs, VisualProps } from '@/core/timelineitem/bunnytype'
import { TimelineItemQueries } from '@/core/timelineitem/queries'

/**
 * å¸§æ•°æ®æ¥å£
 * åŒ…å«å¸§æ•°å’Œå¯¹åº”çš„ VideoSample
 */
export interface FrameData {
  frameNumber: number
  videoSample: VideoSample
}

export function createUnifiedMediaBunnyModule(
  registry: ModuleRegistry,
  totalDurationFrames: Ref<number>,
) {
  const playbackModule = registry.get<UnifiedPlaybackModule>(MODULE_NAMES.PLAYBACK)
  const timelineModule = registry.get<UnifiedTimelineModule>(MODULE_NAMES.TIMELINE)
  const mediaModule = registry.get<UnifiedMediaModule>(MODULE_NAMES.MEDIA)
  const trackModule = registry.get<UnifiedTrackModule>(MODULE_NAMES.TRACK)

  // ==================== çŠ¶æ€å®šä¹‰ ====================

  // æ¨¡å—å°±ç»ªçŠ¶æ€
  const isMediaBunnyReady = ref(false)
  const mediaBunnyError = ref<string | null>(null)

  // Canvas ç›¸å…³ï¼ˆç”±å¤–éƒ¨ä¼ å…¥ï¼‰
  let mCanvas: HTMLCanvasElement | null = null
  let mCtx: CanvasRenderingContext2D | null = null

  // æ¸²æŸ“å¾ªç¯ç›¸å…³
  let mRenderLoopCleanup: (() => void) | null = null
  const mExpectFrameTime: number = 1000 / RENDERER_FPS
  let mUpdatingClip: boolean = false

  // Web Audio API ç›¸å…³
  let mAudioContext: AudioContext | null = null
  let mGainNode: GainNode | null = null

  // éŸ³é¢‘è°ƒåº¦ç›¸å…³
  const mQueuedAudioNodes = new Set<AudioBufferSourceNode>()

  // æ—¶é—´åŒæ­¥é”šç‚¹ï¼ˆç”¨äºéŸ³é¢‘è°ƒåº¦ï¼‰
  let mAudioContextStartTime: number | null = null
  let mPlaybackTimeAtStart: number = 0

  // å½“å‰bunnyæ’­æ”¾å¸§æ•°ï¼ˆæ•´æ•°ï¼‰
  const mCurrentBunnyFrame = ref(0)
  // é¡¹ç›®æ—¶é•¿ï¼ˆå¸§æ•°ï¼‰
  let mTimelineDuration: number = 0

  // bunnyCurFrame æ˜ å°„è¡¨ï¼ˆkey: timelineItemId, value: FrameDataï¼‰
  const mBunnyCurFrameMap = new Map<string, FrameData>()

  // ==================== ç”»å¸ƒç®¡ç† ====================

  /**
   * è®¾ç½® Canvas å…ƒç´ å¹¶åˆå§‹åŒ–æ¸²æŸ“ç³»ç»Ÿ
   * @param canvasElement Canvas å…ƒç´ å¼•ç”¨ï¼ˆä» BunnyRender.vue ä¼ å…¥ï¼‰
   */
  async function setCanvas(canvasElement: HTMLCanvasElement): Promise<void> {
    try {
      if (!canvasElement) {
        throw new Error('Canvas å…ƒç´ ä¸èƒ½ä¸ºç©º')
      }

      // è®¾ç½® Canvas å¼•ç”¨
      mCanvas = canvasElement
      mCtx = mCanvas.getContext('2d')

      if (!mCtx) {
        throw new Error('æ— æ³•è·å– Canvas 2D ä¸Šä¸‹æ–‡')
      }

      console.log('âœ… Canvas å…ƒç´ å·²è®¾ç½®', {
        width: mCanvas.width,
        height: mCanvas.height,
      })

      // åˆå§‹åŒ–éŸ³é¢‘ç³»ç»Ÿ
      initializeAudioSystem()
      // è®¾ç½®æ’­æ”¾ç›‘å¬å™¨
      setupPlaybackListeners()
      // åˆå§‹åŒ–å°±å¯åŠ¨æ¸²æŸ“å¾ªç¯
      startRenderLoop()

      // æ ‡è®°ä¸ºå°±ç»ª
      isMediaBunnyReady.value = true
      mediaBunnyError.value = null

      console.log('âœ… MediaBunny æ¸²æŸ“ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ')
    } catch (error) {
      const errorMessage = error instanceof Error ? error.message : String(error)
      mediaBunnyError.value = `MediaBunny åˆå§‹åŒ–å¤±è´¥: ${errorMessage}`
      isMediaBunnyReady.value = false
      throw error
    }
  }

  /**
   * é”€æ¯ MediaBunny æ¸²æŸ“ç³»ç»Ÿ
   */
  async function destroy(): Promise<void> {
    console.log('ğŸ§¹ æ¸…ç† MediaBunny æ¸²æŸ“ç³»ç»Ÿèµ„æº')

    // åœæ­¢æ¸²æŸ“å¾ªç¯
    stopRenderLoop()

    // åœæ­¢æ‰€æœ‰éŸ³é¢‘
    stopAllAudioNodes()

    // æ¸…ç©º Canvasï¼ˆå¦‚æœå­˜åœ¨ï¼‰
    if (mCanvas && mCtx) {
      mCtx.clearRect(0, 0, mCanvas.width, mCanvas.height)
    }

    // å…³é—­ AudioContext
    if (mAudioContext) {
      await mAudioContext.close()
      mAudioContext = null
    }

    // æ¸…ç† bunnyCurFrameMap ä¸­çš„æ‰€æœ‰ VideoSample
    for (const [itemId, frameData] of mBunnyCurFrameMap) {
      frameData.videoSample.close()
    }
    mBunnyCurFrameMap.clear()

    // æ¸…ç†å¼•ç”¨ï¼ˆä¸åˆ é™¤ canvas å…ƒç´ ï¼Œç”± Vue ç»„ä»¶ç®¡ç†ï¼‰
    mCanvas = null
    mCtx = null
    mGainNode = null

    // æ¸…ç†çŠ¶æ€
    isMediaBunnyReady.value = false

    console.log('âœ… MediaBunny æ¸²æŸ“ç³»ç»Ÿèµ„æºæ¸…ç†å®Œæˆ')
  }

  // ==================== æ¸²æŸ“å¾ªç¯ ====================

  /**
   * å¯åŠ¨æ¸²æŸ“å¾ªç¯
   */
  function startRenderLoop(): void {
    if (mRenderLoopCleanup) {
      console.warn('âš ï¸ æ¸²æŸ“å¾ªç¯å·²åœ¨è¿è¡Œ')
      return
    }

    const renderStart = performance.now()
    let renderRunCnt = 0
    mRenderLoopCleanup = workerTimer(() => {
      // ä½¿ç”¨çœŸå®æ—¶é—´ä½œä¸ºåŸºå‡†ï¼Œé¿å…éŸ³ç”»ä¸åŒæ­¥
      if ((performance.now() - renderStart) / (mExpectFrameTime * renderRunCnt) < 1) {
        return
      }

      // æ’­æ”¾çš„æƒ…å†µä¸‹ï¼Œä¼šåŸºäºçœŸå®æ—¶é—´å•è°ƒå¢é•¿è·å–å½“å‰æ’­æ”¾æ—¶é—´ï¼ˆç§’ï¼‰
      // æš‚åœçš„æƒ…å†µä¸‹ï¼Œä¼šä½¿ç”¨mPlaybackTimeAtStartä½œä¸ºåŸºå‡†ï¼Œå³seekçš„æ—¶å€™åªéœ€è¦æ›´æ–°mPlaybackTimeAtStartå°±è¡Œäº†
      // ç„¶åå†æ¥è®¡ç®—å½“å‰æ’­æ”¾å¸§æ•°
      let currentTime = Math.floor(getCurrentPlaybackTime() * RENDERER_FPS)

      // æ£€æŸ¥æ˜¯å¦æ’­æ”¾ç»“æŸ
      if (playbackModule.isPlaying.value && currentTime >= mTimelineDuration) {
        playbackModule.setPlaying(false)
        playbackModule.setCurrentFrame(mTimelineDuration)
        console.log('âœ… æ’­æ”¾ç»“æŸ')
        return
      }

      // ä¸æ–­æ›´æ–°clipå¸§æ•°æ®,å¦‚æœæ˜¯æ’­æ”¾åˆ™éœ€è¦è§£ç éŸ³é¢‘
      updateClips(timelineModule.timelineItems.value, currentTime, playbackModule.isPlaying.value)
      if (playbackModule.isPlaying.value) {
        playbackModule.setCurrentFrame(currentTime)
      }

      // æ¸²æŸ“åˆ° Canvasï¼ˆä½¿ç”¨ bunnyCurFrameMap å’Œ runtime ä¸­çš„æ•°æ®ï¼‰
      renderToCanvas(timelineModule.timelineItems.value, currentTime)

      renderRunCnt++
    }, mExpectFrameTime)

    console.log('ğŸ¬ MediaBunny æ¸²æŸ“å¾ªç¯å·²å¯åŠ¨')
  }

  /**
   * åœæ­¢æ¸²æŸ“å¾ªç¯
   */
  function stopRenderLoop(): void {
    if (mRenderLoopCleanup) {
      mRenderLoopCleanup()
      mRenderLoopCleanup = null
      console.log('â¸ï¸ MediaBunny æ¸²æŸ“å¾ªç¯å·²åœæ­¢')
    }
  }

  /**
   * è·å–å½“å‰æ’­æ”¾æ—¶é—´
   * ä½¿ç”¨ AudioContext æ—¶é’Ÿä½œä¸ºåŸºå‡†ï¼Œç¡®ä¿ç²¾ç¡®åŒæ­¥
   */
  function getCurrentPlaybackTime(): number {
    if (!playbackModule.isPlaying.value || !mAudioContext || mAudioContextStartTime === null) {
      return mPlaybackTimeAtStart
    }

    return mAudioContext.currentTime - mAudioContextStartTime + mPlaybackTimeAtStart
  }

  /**
   * æ›´æ–°å•ä¸ª clip çš„å¸§æ•°æ®
   * å¼‚æ­¥è°ƒç”¨ bunnyClip.tickN() æ›´æ–° bunnyCurFrameMap å’Œå¤„ç†éŸ³é¢‘
   * @param item æ—¶é—´è½´é¡¹ç›®
   * @param currentTime å½“å‰æ—¶é—´ï¼ˆå¸§æ•°ï¼‰
   * @param shouldPlayAudio æ˜¯å¦åº”è¯¥æ’­æ”¾éŸ³é¢‘ï¼ˆè€ƒè™‘è½¨é“å’Œé¡¹ç›®é™éŸ³çŠ¶æ€ï¼‰
   */
  async function updateClipFrame(
    item: UnifiedTimelineItemData<MediaType>,
    currentTime: number,
    shouldPlayAudio: boolean,
    volume: number,
  ): Promise<void> {
    const bunnyClip = item.runtime.bunnyClip
    if (!bunnyClip) return

    // æ£€æŸ¥å½“å‰å¸§æ•°æ˜¯å¦éœ€è¦æ›´æ–°
    const frameData = mBunnyCurFrameMap.get(item.id)
    if (frameData?.frameNumber === currentTime) {
      // å¸§æ•°ç›¸åŒï¼Œè·³è¿‡æ›´æ–°
      return
    }

    // å¼‚æ­¥æ›´æ–°å¸§æ•°æ®
    // tickN å†…éƒ¨é™åˆ¶å¿…é¡»è§£ç å®Œæ‰èƒ½è§£ç ä¸‹ä¸€ä¸ª
    // æœªè§£ç å®Œå°±å†æ¬¡æ‰§è¡Œ tickN ä¼šè¿”å› â€˜skipâ€™
    // è¿™æ˜¯ç¬¬äºŒå±‚é¢‘ç‡é™åˆ¶
    const { audio, video, state } = await bunnyClip.tickN(
      BigInt(currentTime),
      shouldPlayAudio, //æ ¹æ®è½¨é“å’Œé¡¹ç›®é™éŸ³çŠ¶æ€å†³å®šæ˜¯å¦è¯·æ±‚éŸ³é¢‘
      true, //æ€»æ˜¯è¯·æ±‚è§†é¢‘å¸§
    )
    if (state === 'skip') {
      // ä»€ä¹ˆéƒ½ä¸åšï¼Œè°ƒç”¨ tickN å¤ªé¢‘ç¹äº†
    } else if (state === 'success') {
      // æ›´æ–° bunnyCurFrameMap
      if (video) {
        const oldFrame = mBunnyCurFrameMap.get(item.id)
        oldFrame?.videoSample.close()
        mBunnyCurFrameMap.set(item.id, {
          frameNumber: currentTime,
          videoSample: video,
        })
      }

      // è°ƒåº¦éŸ³é¢‘ï¼ˆåªåœ¨éœ€è¦æ’­æ”¾éŸ³é¢‘æ—¶ï¼‰
      if (shouldPlayAudio && audio) {
        scheduleAudioBuffers(audio, bunnyClip.getPlaybackRate(), volume)
      }
    } else {
      // æ¸…ç†æ— æ•ˆå¸§
      const oldFrame = mBunnyCurFrameMap.get(item.id)
      oldFrame?.videoSample.close()
      mBunnyCurFrameMap.delete(item.id)
    }
  }

  /**
   * æ›´æ–°æ‰€æœ‰ clips
   * è°ƒç”¨ bunnyClip.tickN() æ›´æ–° bunnyCurFrameMap å’Œå¤„ç†éŸ³é¢‘
   */
  function updateClips(
    timelineItems: UnifiedTimelineItemData<MediaType>[],
    currentTime: number,
    playAudio: boolean,
  ): void {
    // mUpdatingClip å¯ä»¥é˜²æ­¢è¿‡åº¦æ›´æ–°
    // è¿™æ˜¯ç¬¬ä¸€å±‚é˜²å¾¡ï¼Œç¬¬äºŒå±‚åœ¨clipå†…éƒ¨æ¥é™åˆ¶è¿‡åº¦æ›´æ–°
    if (mUpdatingClip) return
    mUpdatingClip = true

    for (const item of timelineItems) {
      // åº”ç”¨åŠ¨ç”»æ’å€¼åˆ° config
      applyAnimationToConfig(item, currentTime)

      // å¤„ç†è§†é¢‘/éŸ³é¢‘
      if (
        TimelineItemQueries.isVideoTimelineItem(item) ||
        TimelineItemQueries.isAudioTimelineItem(item)
      ) {
        const track = trackModule.getTrack(item.trackId || '')
        const isTrackMuted = track?.isMuted ?? false
        const isItemMuted = item.config.isMuted ?? false
        const itemVolume = item.config.volume ?? 1.0
        const shouldPlayAudio = playAudio && !isTrackMuted && !isItemMuted

        // æ›´æ–° clip å¸§æ•°æ®ï¼ˆä¸ç­‰å¾…å®Œæˆï¼Œä½¿ç”¨ voidï¼‰
        // è¿™é‡Œä¸ç­‰å¾…ï¼Œå› æ­¤ä¼šåå°æ‰§è¡Œï¼Œé£å¿«åœ°è·³è¿‡è¿™é‡Œï¼Œå¯¼è‡´æ•´ä¸ª updateClips éƒ½ä¼šå¿«é€Ÿæ‰§è¡Œä¸€é
        // æŒ‰ç…§ workerTimer é¢‘ç‡æ¥æ‰§è¡Œï¼Œå¯èƒ½ä¼šåœ¨è§£ç æ…¢è·Ÿä¸ä¸Šçš„æ—¶å€™å¤šæ¬¡é‡å¤æ‰§è¡Œ
        // å› æ­¤å†…éƒ¨ä¹Ÿéœ€è¦ä¸€äº›ç­–ç•¥æ¥é™åˆ¶é¢‘ç‡
        void updateClipFrame(item, currentTime, shouldPlayAudio, itemVolume)
      }
    }

    mCurrentBunnyFrame.value = currentTime
    mUpdatingClip = false
  }

  /**
   * æ£€æŸ¥å…ƒç´ æ˜¯å¦åœ¨ç”»å¸ƒè¾¹ç•Œå†…
   * ç”¨äºæ€§èƒ½ä¼˜åŒ–ï¼Œè·³è¿‡å®Œå…¨åœ¨ç”»å¸ƒå¤–çš„å…ƒç´ 
   * æ³¨æ„ï¼šconfig.x, config.y æ˜¯ç›¸å¯¹äºç”»å¸ƒä¸­å¿ƒçš„åæ ‡
   * @param config è§†è§‰å±æ€§é…ç½®
   * @returns æ˜¯å¦åœ¨è¾¹ç•Œå†…
   */
  function isInBounds(config: VisualProps): boolean {
    const halfW = config.width / 2
    const halfH = config.height / 2
    const canvasHalfWidth = mCanvas!.width / 2
    const canvasHalfHeight = mCanvas!.height / 2

    return (
      config.x + halfW >= -canvasHalfWidth &&
      config.x - halfW <= canvasHalfWidth &&
      config.y + halfH >= -canvasHalfHeight &&
      config.y - halfH <= canvasHalfHeight
    )
  }

  /**
   * æ¸²æŸ“åˆ° Canvasï¼ˆä¸“ä¸šè§†é¢‘ç¼–è¾‘å™¨æ¨¡å¼ï¼‰
   * ä½¿ç”¨ item.config ä¸­çš„æ‰€æœ‰å˜æ¢å±æ€§è¿›è¡Œç²¾ç¡®æ¸²æŸ“
   *
   * åæ ‡ç³»ç»Ÿè¯´æ˜ï¼š
   * - ç”»å¸ƒåŸç‚¹åœ¨ç”»å¸ƒä¸­å¿ƒ (canvasWidth/2, canvasHeight/2)
   * - config.x, config.y æ˜¯ç›¸å¯¹äºç”»å¸ƒä¸­å¿ƒçš„åæ ‡
   * - å…ƒç´ åŸç‚¹åœ¨å…ƒç´ ä¸­å¿ƒ
   *
   * @param timelineItems æ—¶é—´è½´é¡¹ç›®åˆ—è¡¨
   * @param currentTimeN å½“å‰æ’­æ”¾æ—¶é—´ï¼ˆå¸§æ•°ï¼‰
   */
  function renderToCanvas(
    timelineItems: UnifiedTimelineItemData<MediaType>[],
    currentTimeN: number,
  ): void {
    if (!mCanvas || !mCtx) return

    // 1. æ¸…ç©ºç”»å¸ƒ
    mCtx.clearRect(0, 0, mCanvas.width, mCanvas.height)

    // 2. å°†ç”»å¸ƒåŸç‚¹ç§»åŠ¨åˆ°ç”»å¸ƒä¸­å¿ƒ
    // è¿™æ ·æ‰€æœ‰çš„ç»˜åˆ¶éƒ½åŸºäºä¸­å¿ƒåæ ‡ç³»
    mCtx.save()
    mCtx.translate(mCanvas.width / 2, mCanvas.height / 2)

    // 3. æ”¶é›†å¯æ¸²æŸ“é¡¹ç›®
    const renderableItems = timelineItems.filter((item) => {
      // æ£€æŸ¥æ˜¯å¦åœ¨å½“å‰æ’­æ”¾æ—¶é—´èŒƒå›´å†…
      if (
        currentTimeN < item.timeRange.timelineStartTime ||
        currentTimeN > item.timeRange.timelineEndTime
      ) {
        return false
      }

      // æ£€æŸ¥è½¨é“æ˜¯å¦å¯è§
      const track = item.trackId ? trackModule.getTrack(item.trackId) : null
      if (track && !track.isVisible) return false

      // æ£€æŸ¥æ˜¯å¦æœ‰å¯æ¸²æŸ“å†…å®¹
      if (TimelineItemQueries.isVideoTimelineItem(item)) {
        return mBunnyCurFrameMap.has(item.id)
      } else if (TimelineItemQueries.isTextTimelineItem(item)) {
        return item.runtime.textBitmap !== undefined
      } else if (TimelineItemQueries.isImageTimelineItem(item)) {
        const mediaItem = mediaModule.getMediaItem(item.mediaItemId)
        return mediaItem?.runtime.bunny?.imageClip !== undefined
      }
      return false
    })

    // 4. æŒ‰è½¨é“é¡ºåºæ’åºï¼ˆä½¿ç”¨è®¡ç®—å±æ€§ä¼˜åŒ–æ€§èƒ½ï¼‰
    // ç´¢å¼•å°çš„å…ˆæ¸²æŸ“ï¼ˆåœ¨ä¸‹å±‚ï¼‰ï¼Œç´¢å¼•å¤§çš„åæ¸²æŸ“ï¼ˆåœ¨ä¸Šå±‚ï¼‰
    const sortedItems = renderableItems.sort((a, b) => {
      // è·å–è½¨é“ç´¢å¼•ï¼Œå¦‚æœæ²¡æœ‰ trackId æˆ–æ‰¾ä¸åˆ°åˆ™è¿”å› -Infinityï¼ˆæ’åœ¨æœ€å‰é¢ï¼‰
      const getTrackIndex = (trackId: string | undefined): number => {
        if (!trackId) return -Infinity
        return trackModule.trackIndexMap.value.get(trackId) ?? -Infinity
      }

      return getTrackIndex(a.trackId) - getTrackIndex(b.trackId)
    })

    // 5. æ¸²æŸ“æ¯ä¸ªé¡¹ç›®
    for (const item of sortedItems) {
      // æ€§èƒ½ä¼˜åŒ–ï¼šè·³è¿‡å®Œå…¨åœ¨ç”»å¸ƒå¤–çš„å…ƒç´ 
      if (TimelineItemQueries.hasVisualProperties(item)) {
        if (!isInBounds(item.config)) {
          continue
        }
      }
      renderItem(item)
    }

    // 6. æ¢å¤ç”»å¸ƒåŸç‚¹åˆ°å·¦ä¸Šè§’
    mCtx.restore()
  }

  /**
   * æ¸²æŸ“å•ä¸ªé¡¹ç›®
   * åº”ç”¨æ‰€æœ‰ config ä¸­çš„å˜æ¢å±æ€§
   *
   * åæ ‡ç³»ç»Ÿè¯´æ˜ï¼š
   * - ç”»å¸ƒåŸç‚¹å·²åœ¨ renderToCanvas ä¸­ç§»åŠ¨åˆ°ç”»å¸ƒä¸­å¿ƒ
   * - config.x, config.y æ˜¯ç›¸å¯¹äºç”»å¸ƒä¸­å¿ƒçš„åæ ‡
   * - å…ƒç´ åŸç‚¹åœ¨å…ƒç´ ä¸­å¿ƒ
   *
   * @param item æ—¶é—´è½´é¡¹ç›®
   */
  function renderItem(item: UnifiedTimelineItemData<MediaType>): void {
    if (!mCtx) return

    // æ£€æŸ¥æ˜¯å¦æœ‰è§†è§‰å±æ€§ï¼ˆçº¯éŸ³é¢‘é¡¹ç›®æ— éœ€æ¸²æŸ“ï¼‰
    if (!TimelineItemQueries.hasVisualProperties(item)) {
      return
    }

    const visualConfig = item.config

    // æ€§èƒ½ä¼˜åŒ–ï¼šå¦‚æœæ²¡æœ‰æ—‹è½¬å’Œä¸é€æ˜åº¦å˜åŒ–ï¼Œç›´æ¥ç»˜åˆ¶
    const needsTransform = visualConfig.rotation !== 0 || visualConfig.opacity !== 1

    if (!needsTransform) {
      // ç›´æ¥ç»˜åˆ¶ï¼Œä¸éœ€è¦ save/restore
      const width = visualConfig.width
      const height = visualConfig.height
      // config.x, config.y å·²ç»æ˜¯ç›¸å¯¹äºç”»å¸ƒä¸­å¿ƒçš„åæ ‡
      // ç»˜åˆ¶æ—¶éœ€è¦åç§» -width/2, -height/2ï¼Œä½¿å…ƒç´ ä¸­å¿ƒåœ¨ (config.x, config.y)
      const x = visualConfig.x - width / 2
      const y = visualConfig.y - height / 2

      if (TimelineItemQueries.isVideoTimelineItem(item)) {
        const frameData = mBunnyCurFrameMap.get(item.id)
        if (frameData) {
          const videoFrame = frameData.videoSample.toVideoFrame()
          mCtx.drawImage(videoFrame, x, y, width, height)
          videoFrame.close()
        }
      } else if (TimelineItemQueries.isTextTimelineItem(item) && item.runtime.textBitmap) {
        mCtx.drawImage(item.runtime.textBitmap, x, y, width, height)
      } else if (TimelineItemQueries.isImageTimelineItem(item)) {
        const mediaItem = mediaModule.getMediaItem(item.mediaItemId)
        const imageClip = mediaItem?.runtime.bunny?.imageClip
        if (imageClip) {
          mCtx.drawImage(imageClip, x, y, width, height)
        }
      }

      return
    }

    // éœ€è¦å˜æ¢æ—¶ä½¿ç”¨ save/restore
    mCtx.save()

    try {
      // === åº”ç”¨å˜æ¢ï¼ˆé¡ºåºå¾ˆé‡è¦ï¼ï¼‰===

      // 1. ç§»åŠ¨åˆ°ç›®æ ‡ä½ç½®ï¼ˆç›¸å¯¹äºç”»å¸ƒä¸­å¿ƒï¼‰
      // æ³¨æ„ï¼šç”»å¸ƒåŸç‚¹å·²ç»åœ¨ç”»å¸ƒä¸­å¿ƒï¼Œæ‰€ä»¥ config.x, config.y ç›´æ¥ä½¿ç”¨
      mCtx.translate(visualConfig.x, visualConfig.y)

      // 2. åº”ç”¨æ—‹è½¬ï¼ˆå›´ç»•ä¸­å¿ƒç‚¹æ—‹è½¬ï¼‰
      if (visualConfig.rotation !== 0) {
        // å·²ç»æ˜¯å¼§åº¦äº†
        mCtx.rotate(visualConfig.rotation)
      }

      // 3. åº”ç”¨ä¸é€æ˜åº¦
      if (visualConfig.opacity !== undefined && visualConfig.opacity !== 1) {
        mCtx.globalAlpha = visualConfig.opacity
      }

      // 4. è·å–å°ºå¯¸
      const width = visualConfig.width
      const height = visualConfig.height

      // === ç»˜åˆ¶å†…å®¹ ===
      // æ³¨æ„ï¼šå› ä¸ºå·²ç» translate åˆ°ä¸­å¿ƒç‚¹ï¼Œæ‰€ä»¥ç»˜åˆ¶æ—¶è¦åç§» -width/2, -height/2

      if (TimelineItemQueries.isVideoTimelineItem(item)) {
        const frameData = mBunnyCurFrameMap.get(item.id)
        if (frameData) {
          const videoFrame = frameData.videoSample.toVideoFrame()
          // ä»¥ä¸­å¿ƒç‚¹ä¸ºåŸç‚¹ç»˜åˆ¶
          mCtx.drawImage(videoFrame, -width / 2, -height / 2, width, height)
          videoFrame.close()
        }
      } else if (TimelineItemQueries.isTextTimelineItem(item) && item.runtime.textBitmap) {
        // ç»˜åˆ¶æ–‡æœ¬ä½å›¾
        mCtx.drawImage(item.runtime.textBitmap, -width / 2, -height / 2, width, height)
      } else if (TimelineItemQueries.isImageTimelineItem(item)) {
        const mediaItem = mediaModule.getMediaItem(item.mediaItemId)
        const imageClip = mediaItem?.runtime.bunny?.imageClip
        if (imageClip) {
          // ç»˜åˆ¶å›¾ç‰‡
          mCtx.drawImage(imageClip, -width / 2, -height / 2, width, height)
        }
      }
    } catch (error) {
      console.error(`âŒ æ¸²æŸ“é¡¹ç›®å¤±è´¥: ${item.id}`, error)
    } finally {
      // æ¢å¤ç”»å¸ƒçŠ¶æ€ï¼ˆé‡è¦ï¼é¿å…å½±å“åç»­æ¸²æŸ“ï¼‰
      mCtx.restore()
    }
  }

  // ==================== éŸ³é¢‘ç³»ç»Ÿ ====================

  /**
   * åˆå§‹åŒ–éŸ³é¢‘ç³»ç»Ÿ
   */
  function initializeAudioSystem(): void {
    mAudioContext = new AudioContext({
      sampleRate: AUDIO_DEFAULT_SAMPLE_RATE,
    })
    mGainNode = mAudioContext.createGain()
    mGainNode.connect(mAudioContext.destination)
    console.log(`ğŸ§ AudioContext å·²åˆ›å»ºï¼Œé‡‡æ ·ç‡: ${mAudioContext.sampleRate}Hz`)
  }

  /**
   * è°ƒåº¦éŸ³é¢‘ç¼“å†²
   */
  function scheduleAudioBuffers(audioSamples: AudioSample[], rate: number, volume: number): void {
    if (!mAudioContext || !mGainNode) return

    for (const sample of audioSamples) {
      const node = mAudioContext.createBufferSource()
      node.buffer = sample.toAudioBuffer()
      node.playbackRate.value = rate

      // ä¸ºæ¯ä¸ªéŸ³é¢‘èŠ‚ç‚¹åˆ›å»ºç‹¬ç«‹çš„å¢ç›ŠèŠ‚ç‚¹ä»¥æ§åˆ¶éŸ³é‡
      const gainNode = mAudioContext.createGain()
      gainNode.gain.value = volume
      node.connect(gainNode)
      gainNode.connect(mGainNode)

      const startTimestamp = mAudioContextStartTime! + sample.timestamp - mPlaybackTimeAtStart
      const curTime = mAudioContext.currentTime
      if (startTimestamp >= curTime) {
        node.start(startTimestamp)
      } else {
        node.start(curTime, curTime - startTimestamp)
      }
      mQueuedAudioNodes.add(node)
      node.onended = () => {
        mQueuedAudioNodes.delete(node)
      }

      sample.close()
    }
  }

  /**
   * åœæ­¢æ‰€æœ‰éŸ³é¢‘èŠ‚ç‚¹
   */
  function stopAllAudioNodes(): void {
    for (const node of mQueuedAudioNodes) {
      try {
        node.stop()
      } catch (err) {
        // å¿½ç•¥å·²åœæ­¢çš„èŠ‚ç‚¹
      }
    }
    mQueuedAudioNodes.clear()
  }

  // ==================== æ’­æ”¾æ§åˆ¶ ====================

  /**
   * å¯åŠ¨ MediaBunny æ¸²æŸ“å¾ªç¯
   * ç”± UnifiedPlaybackModule è°ƒç”¨
   */
  async function startPlayback(): Promise<void> {
    if (!mAudioContext) {
      console.error('æœªåˆå§‹åŒ– AudioContext')
      return
    }

    if (mAudioContext && mAudioContext.state === 'suspended') {
      await mAudioContext.resume()
    }

    // è®¾ç½®éŸ³é¢‘æ—¶é—´é”šç‚¹
    mAudioContextStartTime = mAudioContext!.currentTime
    mPlaybackTimeAtStart = playbackModule.currentFrame.value / RENDERER_FPS

    console.log('â–¶ï¸ MediaBunny å¼€å§‹æ’­æ”¾')
  }

  /**
   * åœæ­¢ MediaBunny æ¸²æŸ“å¾ªç¯
   * ç”± UnifiedPlaybackModule è°ƒç”¨
   */
  async function stopPlayback(): Promise<void> {
    // åœæ­¢æ‰€æœ‰éŸ³é¢‘
    stopAllAudioNodes()

    // æ›´æ–°æ’­æ”¾æ—¶é—´é”šç‚¹
    mPlaybackTimeAtStart = playbackModule.currentFrame.value / RENDERER_FPS
  }

  /**
   * è·³è½¬åˆ°æŒ‡å®šå¸§
   * ç”± UnifiedPlaybackModule è°ƒç”¨
   */
  function seekToFrame(frames: number): void {
    stopAllAudioNodes()

    // seekåªéœ€è¦æ›´æ–° mPlaybackTimeAtStart å³å¯
    // æ¸²æŸ“å¾ªç¯ä¼šä¸æ–­ä»¥ mPlaybackTimeAtStart ä¸ºåŸºå‡†ç‚¹æ¥æ¸²æŸ“
    const clampedFrames = Math.max(0, Math.min(mTimelineDuration, frames))
    mPlaybackTimeAtStart = clampedFrames / RENDERER_FPS
  }

  /**
   * æ›´æ–°é¡¹ç›®æ—¶é•¿
   * @param newDurationN é¡¹ç›®æ—¶é•¿ï¼ˆå¸§æ•°ï¼Œnumberç±»å‹ï¼‰
   */
  function updateTimelineDuration(newDurationN: number): void {
    mTimelineDuration = newDurationN
    const durationSeconds = newDurationN / RENDERER_FPS
    console.log(`ğŸ¯ æ›´æ–°é¡¹ç›®æ—¶é•¿: ${durationSeconds.toFixed(2)}s ${newDurationN}å¸§`)
  }

  // ==================== äº‹ä»¶ç›‘å¬ ====================

  // åˆ›å»ºèŠ‚æµå‡½æ•°ï¼Œ100mså†…åªæ‰§è¡Œä¸€æ¬¡
  const throttledSeekToFrame = throttle(async (frame: number) => {
    seekToFrame(frame)
  }, 100)
  /**
   * è®¾ç½®æ’­æ”¾ç›‘å¬å™¨
   * ç›‘å¬ UnifiedPlaybackModule çš„çŠ¶æ€å˜åŒ–
   */
  function setupPlaybackListeners(): void {
    // ç›‘å¬å¸§æ•°å˜åŒ–ï¼ˆç”¨äº seekï¼‰
    watch([playbackModule.currentFrame, mCurrentBunnyFrame], ([new_cf, new_cbf]) => {
      if (new_cf != new_cbf && !playbackModule.isPlaying.value) {
        throttledSeekToFrame(new_cf)
      }
    })

    // ç›‘å¬æ—¶é—´è½´æ—¶é•¿å˜åŒ–ï¼Œè‡ªåŠ¨æ›´æ–° MediaBunny æ’­æ”¾å™¨æ—¶é•¿
    watch(
      totalDurationFrames,
      (newDurationFrames) => {
        updateTimelineDuration(newDurationFrames)
        console.log(`ğŸ¯ [MediaBunny] æ—¶é—´è½´æ—¶é•¿å˜åŒ–ï¼Œå·²æ›´æ–°æ’­æ”¾å™¨æ—¶é•¿: ${newDurationFrames}å¸§`)
      },
      { immediate: true },
    )

    console.log('âœ… MediaBunny æ’­æ”¾ç›‘å¬å™¨å·²è®¾ç½®')
  }

  // ==================== å·¥å…·æ–¹æ³• ====================

  /**
   * æ£€æŸ¥ MediaBunny æ˜¯å¦å¯ç”¨
   * @returns æ˜¯å¦å¯ç”¨
   */
  function isMediaBunnyAvailable(): boolean {
    return !!(mCanvas && mCtx && isMediaBunnyReady.value && !mediaBunnyError.value)
  }

  /**
   * é‡ç½® MediaBunny çŠ¶æ€ä¸ºé»˜è®¤å€¼
   */
  function resetToDefaults(): Promise<void> {
    return destroy()
  }

  // ==================== å¯¼å‡ºæ¥å£ ====================

  return {
    // çŠ¶æ€
    isMediaBunnyReady,
    mediaBunnyError,
    currentBunnyFrame: mCurrentBunnyFrame,

    // ç”»å¸ƒç®¡ç†
    setCanvas,
    destroy,

    // æ’­æ”¾æ§åˆ¶
    startPlayback,
    stopPlayback,
    seekToFrame,
    updateTimelineDuration,

    // å·¥å…·æ–¹æ³•
    isMediaBunnyAvailable,
    resetToDefaults,
  }
}

// å¯¼å‡ºç±»å‹å®šä¹‰
export type UnifiedMediaBunnyModule = ReturnType<typeof createUnifiedMediaBunnyModule>
