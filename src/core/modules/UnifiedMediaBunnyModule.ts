/**
 * UnifiedMediaBunnyModule - MediaBunny æ¸²æŸ“ç³»ç»Ÿæ¨¡å—
 *
 * å®Œå…¨æ›¿ä»£ WebAV çš„æ¸²æŸ“ç³»ç»Ÿï¼Œä½¿ç”¨ MediaBunny å®ç°è‡ªå®šä¹‰æ¸²æŸ“å¾ªç¯
 *
 * æ ¸å¿ƒç‰¹ç‚¹ï¼š
 * - å®Œå…¨æ›¿ä»£ WebAV æ¸²æŸ“
 * - è‡ªå®ç°æ¸²æŸ“å¾ªç¯ï¼ˆä¸ä¾èµ– WebAV çš„ AVCanvasï¼‰
 * - Canvas ç”± Vue ç»„ä»¶ç®¡ç†ï¼Œé€šè¿‡ setCanvas() ä¼ å…¥
 * - ä½¿ç”¨ runtime.bunnyClip (è§†é¢‘/éŸ³é¢‘)ã€runtime.textBitmap (æ–‡æœ¬)ã€runtime.bunny.imageClip (å›¾ç‰‡)
 * - æš‚ä¸æ”¯æŒå¯¼å‡ºåŠŸèƒ½ï¼ˆæœªæ¥å¯æ‰©å±•ï¼‰
 * - ä¼˜å…ˆé¢„è§ˆæ€§èƒ½
 *
 * æ¶æ„è¯´æ˜ï¼š
 * - UnifiedPlaybackModule ä½œä¸ºä¸»æ§ï¼Œç®¡ç†æ‰€æœ‰æ’­æ”¾çŠ¶æ€
 * - UnifiedMediaBunnyModule åªè´Ÿè´£æ¸²æŸ“ï¼Œä¸ç»´æŠ¤ç‹¬ç«‹æ’­æ”¾çŠ¶æ€
 * - é€šè¿‡ç›‘å¬ playbackModule çš„çŠ¶æ€å˜åŒ–æ¥æ§åˆ¶æ¸²æŸ“å¾ªç¯
 */

import { ref, markRaw, watch, type Ref } from 'vue'
import { workerTimer } from '@/core/mediabunny/worker-timer'
import { RENDERER_FPS, AUDIO_DEFAULT_SAMPLE_RATE } from '@/core/mediabunny/constant'
import { throttle } from 'lodash'
import type { VideoSample } from 'mediabunny'
import { ModuleRegistry, MODULE_NAMES } from './ModuleRegistry'
import type { UnifiedTimelineModule } from './UnifiedTimelineModule'
import type { UnifiedMediaModule } from './UnifiedMediaModule'
import type { UnifiedPlaybackModule } from './UnifiedPlaybackModule'
import type { UnifiedConfigModule } from './UnifiedConfigModule'
import type { UnifiedTimelineItemData } from '@/core/timelineitem/TimelineItemData'
import type { MediaType } from '@/core/mediaitem/types'
import type { AudioSample } from 'mediabunny'

/**
 * å¸§æ•°æ®æ¥å£
 * åŒ…å«å¸§æ•°å’Œå¯¹åº”çš„ VideoSample
 */
export interface FrameData {
  frameNumber: number
  videoSample: VideoSample
}

export function createUnifiedMediaBunnyModule(
  registry: ModuleRegistry,
  totalDurationFrames: Ref<number>,
) {
  const playbackModule = registry.get<UnifiedPlaybackModule>(MODULE_NAMES.PLAYBACK)
  const timelineModule = registry.get<UnifiedTimelineModule>(MODULE_NAMES.TIMELINE)
  const mediaModule = registry.get<UnifiedMediaModule>(MODULE_NAMES.MEDIA)

  // ==================== çŠ¶æ€å®šä¹‰ ====================

  // æ¨¡å—å°±ç»ªçŠ¶æ€
  const isMediaBunnyReady = ref(false)
  const mediaBunnyError = ref<string | null>(null)

  // Canvas ç›¸å…³ï¼ˆç”±å¤–éƒ¨ä¼ å…¥ï¼‰
  let mCanvas: HTMLCanvasElement | null = null
  let mCtx: CanvasRenderingContext2D | null = null

  // æ¸²æŸ“å¾ªç¯ç›¸å…³
  let mRenderLoopCleanup: (() => void) | null = null
  const mExpectFrameTime: number = 1000 / RENDERER_FPS
  let mUpdatingClip: boolean = false

  // Web Audio API ç›¸å…³
  let mAudioContext: AudioContext | null = null
  let mGainNode: GainNode | null = null

  // éŸ³é¢‘è°ƒåº¦ç›¸å…³
  const mQueuedAudioNodes = new Set<AudioBufferSourceNode>()

  // æ—¶é—´åŒæ­¥é”šç‚¹ï¼ˆç”¨äºéŸ³é¢‘è°ƒåº¦ï¼‰
  let mAudioContextStartTime: number | null = null
  let mPlaybackTimeAtStart: number = 0

  // å½“å‰bunnyæ’­æ”¾å¸§æ•°ï¼ˆæ•´æ•°ï¼‰
  const mCurrentBunnyFrame = ref(0)
  // é¡¹ç›®æ—¶é•¿ï¼ˆå¸§æ•°ï¼‰
  let mTimelineDuration: number = 0

  // bunnyCurFrame æ˜ å°„è¡¨ï¼ˆkey: timelineItemId, value: FrameDataï¼‰
  const mBunnyCurFrameMap = new Map<string, FrameData>()

  // ==================== ç”»å¸ƒç®¡ç† ====================

  /**
   * è®¾ç½® Canvas å…ƒç´ å¹¶åˆå§‹åŒ–æ¸²æŸ“ç³»ç»Ÿ
   * @param canvasElement Canvas å…ƒç´ å¼•ç”¨ï¼ˆä» BunnyRender.vue ä¼ å…¥ï¼‰
   */
  async function setCanvas(canvasElement: HTMLCanvasElement): Promise<void> {
    try {
      if (!canvasElement) {
        throw new Error('Canvas å…ƒç´ ä¸èƒ½ä¸ºç©º')
      }

      // è®¾ç½® Canvas å¼•ç”¨
      mCanvas = canvasElement
      mCtx = mCanvas.getContext('2d')

      if (!mCtx) {
        throw new Error('æ— æ³•è·å– Canvas 2D ä¸Šä¸‹æ–‡')
      }

      console.log('âœ… Canvas å…ƒç´ å·²è®¾ç½®', {
        width: mCanvas.width,
        height: mCanvas.height,
      })

      // åˆå§‹åŒ–éŸ³é¢‘ç³»ç»Ÿ
      initializeAudioSystem()
      // è®¾ç½®æ’­æ”¾ç›‘å¬å™¨
      setupPlaybackListeners()
      // åˆå§‹åŒ–å°±å¯åŠ¨æ¸²æŸ“å¾ªç¯
      startRenderLoop()

      // æ ‡è®°ä¸ºå°±ç»ª
      isMediaBunnyReady.value = true
      mediaBunnyError.value = null

      console.log('âœ… MediaBunny æ¸²æŸ“ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ')
    } catch (error) {
      const errorMessage = error instanceof Error ? error.message : String(error)
      mediaBunnyError.value = `MediaBunny åˆå§‹åŒ–å¤±è´¥: ${errorMessage}`
      isMediaBunnyReady.value = false
      throw error
    }
  }

  /**
   * é”€æ¯ MediaBunny æ¸²æŸ“ç³»ç»Ÿ
   */
  async function destroy(): Promise<void> {
    console.log('ğŸ§¹ æ¸…ç† MediaBunny æ¸²æŸ“ç³»ç»Ÿèµ„æº')

    // åœæ­¢æ¸²æŸ“å¾ªç¯
    stopRenderLoop()

    // åœæ­¢æ‰€æœ‰éŸ³é¢‘
    stopAllAudioNodes()

    // æ¸…ç©º Canvasï¼ˆå¦‚æœå­˜åœ¨ï¼‰
    if (mCanvas && mCtx) {
      mCtx.clearRect(0, 0, mCanvas.width, mCanvas.height)
    }

    // å…³é—­ AudioContext
    if (mAudioContext) {
      await mAudioContext.close()
      mAudioContext = null
    }

    // æ¸…ç† bunnyCurFrameMap ä¸­çš„æ‰€æœ‰ VideoSample
    for (const [itemId, frameData] of mBunnyCurFrameMap) {
      frameData.videoSample.close()
    }
    mBunnyCurFrameMap.clear()

    // æ¸…ç†å¼•ç”¨ï¼ˆä¸åˆ é™¤ canvas å…ƒç´ ï¼Œç”± Vue ç»„ä»¶ç®¡ç†ï¼‰
    mCanvas = null
    mCtx = null
    mGainNode = null

    // æ¸…ç†çŠ¶æ€
    isMediaBunnyReady.value = false

    console.log('âœ… MediaBunny æ¸²æŸ“ç³»ç»Ÿèµ„æºæ¸…ç†å®Œæˆ')
  }

  // ==================== æ¸²æŸ“å¾ªç¯ ====================

  /**
   * å¯åŠ¨æ¸²æŸ“å¾ªç¯
   */
  function startRenderLoop(): void {
    if (mRenderLoopCleanup) {
      console.warn('âš ï¸ æ¸²æŸ“å¾ªç¯å·²åœ¨è¿è¡Œ')
      return
    }

    const renderStart = performance.now()
    let renderRunCnt = 0
    mRenderLoopCleanup = workerTimer(() => {
      // ä½¿ç”¨çœŸå®æ—¶é—´ä½œä¸ºåŸºå‡†ï¼Œé¿å…éŸ³ç”»ä¸åŒæ­¥
      if ((performance.now() - renderStart) / (mExpectFrameTime * renderRunCnt) < 1) {
        return
      }

      // æ’­æ”¾çš„æƒ…å†µä¸‹ï¼Œä¼šåŸºäºçœŸå®æ—¶é—´å•è°ƒå¢é•¿è·å–å½“å‰æ’­æ”¾æ—¶é—´ï¼ˆç§’ï¼‰
      // æš‚åœçš„æƒ…å†µä¸‹ï¼Œä¼šä½¿ç”¨mPlaybackTimeAtStartä½œä¸ºåŸºå‡†ï¼Œå³seekçš„æ—¶å€™åªéœ€è¦æ›´æ–°mPlaybackTimeAtStartå°±è¡Œäº†
      // ç„¶åå†æ¥è®¡ç®—å½“å‰æ’­æ”¾å¸§æ•°
      let currentTime = Math.floor(getCurrentPlaybackTime() * RENDERER_FPS)

      // æ£€æŸ¥æ˜¯å¦æ’­æ”¾ç»“æŸ
      if (playbackModule.isPlaying.value && currentTime >= mTimelineDuration) {
        playbackModule.setPlaying(false)
        playbackModule.setCurrentFrame(mTimelineDuration)
        console.log('âœ… æ’­æ”¾ç»“æŸ')
        return
      }

      // ä¸æ–­æ›´æ–°clipå¸§æ•°æ®,å¦‚æœæ˜¯æ’­æ”¾åˆ™éœ€è¦è§£ç éŸ³é¢‘
      void updateClips(
        timelineModule.timelineItems.value,
        currentTime,
        playbackModule.isPlaying.value,
      )
      if (playbackModule.isPlaying.value) {
        playbackModule.setCurrentFrame(currentTime)
      }

      // æ¸²æŸ“åˆ° Canvasï¼ˆä½¿ç”¨ bunnyCurFrameMap å’Œ runtime ä¸­çš„æ•°æ®ï¼‰
      renderToCanvas(timelineModule.timelineItems.value, currentTime)

      renderRunCnt++
    }, mExpectFrameTime)

    console.log('ğŸ¬ MediaBunny æ¸²æŸ“å¾ªç¯å·²å¯åŠ¨')
  }

  /**
   * åœæ­¢æ¸²æŸ“å¾ªç¯
   */
  function stopRenderLoop(): void {
    if (mRenderLoopCleanup) {
      mRenderLoopCleanup()
      mRenderLoopCleanup = null
      console.log('â¸ï¸ MediaBunny æ¸²æŸ“å¾ªç¯å·²åœæ­¢')
    }
  }

  /**
   * è·å–å½“å‰æ’­æ”¾æ—¶é—´
   * ä½¿ç”¨ AudioContext æ—¶é’Ÿä½œä¸ºåŸºå‡†ï¼Œç¡®ä¿ç²¾ç¡®åŒæ­¥
   */
  function getCurrentPlaybackTime(): number {
    if (!playbackModule.isPlaying.value || !mAudioContext || mAudioContextStartTime === null) {
      return mPlaybackTimeAtStart
    }

    return mAudioContext.currentTime - mAudioContextStartTime + mPlaybackTimeAtStart
  }

  /**
   * æ›´æ–°æ‰€æœ‰ clips
   * è°ƒç”¨ bunnyClip.tickN() æ›´æ–° bunnyCurFrameMap å’Œå¤„ç†éŸ³é¢‘
   */
  async function updateClips(
    timelineItems: UnifiedTimelineItemData<MediaType>[],
    currentTime: number,
    playAudio: boolean,
  ): Promise<void> {
    if (mUpdatingClip) return
    mUpdatingClip = true

    await Promise.all(
      timelineItems.map(async (item) => {
        // å¤„ç†è§†é¢‘/éŸ³é¢‘
        if (item.mediaType === 'video' || item.mediaType === 'audio') {
          const bunnyClip = item.runtime.bunnyClip
          if (bunnyClip) {
            // æ£€æŸ¥å½“å‰å¸§æ•°æ˜¯å¦éœ€è¦æ›´æ–°
            const frameData = mBunnyCurFrameMap.get(item.id)
            if (frameData?.frameNumber === currentTime) {
              // å¸§æ•°ç›¸åŒï¼Œæ— éœ€æ›´æ–°
              return
            }

            const { audio, video, state } = await bunnyClip.tickN(
              BigInt(currentTime),
              playAudio, //æŒ‰éœ€è¯·æ±‚éŸ³é¢‘
              true, //æ€»æ˜¯è¯·æ±‚è§†é¢‘å¸§
            )

            if (state === 'success') {
              // æ›´æ–° bunnyCurFrameMap
              if (video) {
                const oldFrame = mBunnyCurFrameMap.get(item.id)
                oldFrame?.videoSample.close()
                mBunnyCurFrameMap.set(item.id, {
                  frameNumber: currentTime,
                  videoSample: video,
                })
              }

              // è°ƒåº¦éŸ³é¢‘
              if (playAudio) scheduleAudioBuffers(audio, bunnyClip.getPlaybackRate())
            } else {
              // æ¸…ç†æ— æ•ˆå¸§
              const oldFrame = mBunnyCurFrameMap.get(item.id)
              oldFrame?.videoSample.close()
              mBunnyCurFrameMap.delete(item.id)
            }
          }
        }
      }),
    )

    mCurrentBunnyFrame.value = currentTime
    mUpdatingClip = false
  }

  /**
   * æ¸²æŸ“åˆ° Canvasï¼ˆç½‘æ ¼å¸ƒå±€ï¼‰
   * ä½¿ç”¨ bunnyCurFrameMap å’Œ timelineItem.runtime ä¸­çš„æ•°æ®ï¼š
   * - bunnyCurFrameMap.get(item.id) (è§†é¢‘)
   * - runtime.textBitmap (æ–‡æœ¬)
   * - mediaItem.runtime.bunny.imageClip (å›¾ç‰‡)
   * @param timelineItems æ—¶é—´è½´é¡¹ç›®åˆ—è¡¨
   * @param currentTimeN å½“å‰æ’­æ”¾æ—¶é—´ï¼ˆå¸§æ•°ï¼Œbigintç±»å‹ï¼‰
   */
  function renderToCanvas(
    timelineItems: UnifiedTimelineItemData<MediaType>[],
    currentTimeN: number,
  ): void {
    if (!mCanvas || !mCtx) return

    // æ¸…ç©ºç”»å¸ƒ
    mCtx.clearRect(0, 0, mCanvas.width, mCanvas.height)

    // æ”¶é›†æ‰€æœ‰å¯æ¸²æŸ“çš„é¡¹ç›®ï¼ˆéœ€è¦åŒæ—¶æ»¡è¶³ï¼šå¯æ¸²æŸ“ + åœ¨å½“å‰æ—¶é—´èŒƒå›´å†…ï¼‰
    const renderableItems = timelineItems.filter((item) => {
      // æ£€æŸ¥æ˜¯å¦åœ¨å½“å‰æ’­æ”¾æ—¶é—´èŒƒå›´å†…
      const isInTimeRange =
        currentTimeN >= item.timeRange.timelineStartTime &&
        currentTimeN <= item.timeRange.timelineEndTime

      if (!isInTimeRange) {
        return false
      }

      // æ£€æŸ¥æ˜¯å¦å¯æ¸²æŸ“
      if (item.mediaType === 'video') {
        return mBunnyCurFrameMap.has(item.id)
      } else if (item.mediaType === 'text') {
        return item.runtime.textBitmap !== undefined
      } else if (item.mediaType === 'image') {
        const mediaItem = mediaModule.getMediaItem(item.mediaItemId)
        return mediaItem?.runtime.bunny?.imageClip !== undefined
      }
      return false
    })

    const itemCount = renderableItems.length
    if (itemCount === 0) return

    // è®¡ç®—ç½‘æ ¼è¡Œåˆ—æ•°ï¼ˆå°½é‡æ¥è¿‘æ­£æ–¹å½¢ï¼‰
    const cols = Math.ceil(Math.sqrt(itemCount))
    const rows = Math.ceil(itemCount / cols)

    // è®¡ç®—æ¯ä¸ªå•å…ƒæ ¼çš„å®½é«˜
    const cellWidth = mCanvas.width / cols
    const cellHeight = mCanvas.height / rows

    // ç»˜åˆ¶æ‰€æœ‰é¡¹ç›®
    renderableItems.forEach((item, index) => {
      const col = index % cols
      const row = Math.floor(index / cols)
      const x = col * cellWidth
      const y = row * cellHeight

      try {
        if (item.mediaType === 'video') {
          const frameData = mBunnyCurFrameMap.get(item.id)
          if (frameData) {
            const videoFrame = frameData.videoSample.toVideoFrame()
            mCtx!.drawImage(videoFrame, x, y, cellWidth, cellHeight)
            videoFrame.close()
          }
        } else if (item.mediaType === 'text' && item.runtime.textBitmap) {
          mCtx!.drawImage(item.runtime.textBitmap, x, y, cellWidth, cellHeight)
        } else if (item.mediaType === 'image') {
          const mediaItem = mediaModule.getMediaItem(item.mediaItemId)
          const imageClip = mediaItem?.runtime.bunny?.imageClip
          if (imageClip) {
            mCtx!.drawImage(imageClip, x, y, cellWidth, cellHeight)
          }
        }
      } catch (error) {
        console.error(`âŒ æ¸²æŸ“é¡¹ç›®å¤±è´¥: ${item.id}`, error)
      }
    })
  }

  // ==================== éŸ³é¢‘ç³»ç»Ÿ ====================

  /**
   * åˆå§‹åŒ–éŸ³é¢‘ç³»ç»Ÿ
   */
  function initializeAudioSystem(): void {
    mAudioContext = new AudioContext({
      sampleRate: AUDIO_DEFAULT_SAMPLE_RATE,
    })
    mGainNode = mAudioContext.createGain()
    mGainNode.connect(mAudioContext.destination)
    console.log(`ğŸ§ AudioContext å·²åˆ›å»ºï¼Œé‡‡æ ·ç‡: ${mAudioContext.sampleRate}Hz`)
  }

  /**
   * è°ƒåº¦éŸ³é¢‘ç¼“å†²
   */
  function scheduleAudioBuffers(audioSamples: AudioSample[], rate: number): void {
    if (!mAudioContext || !mGainNode) return

    for (const sample of audioSamples) {
      const node = mAudioContext.createBufferSource()
      node.buffer = sample.toAudioBuffer()
      node.playbackRate.value = rate
      node.connect(mGainNode)

      const startTimestamp = mAudioContextStartTime! + sample.timestamp - mPlaybackTimeAtStart
      const curTime = mAudioContext.currentTime
      if (startTimestamp >= curTime) {
        node.start(startTimestamp)
      } else {
        node.start(curTime, curTime - startTimestamp)
      }
      mQueuedAudioNodes.add(node)
      node.onended = () => {
        mQueuedAudioNodes.delete(node)
      }

      sample.close()
    }
  }

  /**
   * åœæ­¢æ‰€æœ‰éŸ³é¢‘èŠ‚ç‚¹
   */
  function stopAllAudioNodes(): void {
    for (const node of mQueuedAudioNodes) {
      try {
        node.stop()
      } catch (err) {
        // å¿½ç•¥å·²åœæ­¢çš„èŠ‚ç‚¹
      }
    }
    mQueuedAudioNodes.clear()
  }

  // ==================== æ’­æ”¾æ§åˆ¶ ====================

  /**
   * å¯åŠ¨ MediaBunny æ¸²æŸ“å¾ªç¯
   * ç”± UnifiedPlaybackModule è°ƒç”¨
   */
  async function startPlayback(): Promise<void> {
    if (!mAudioContext) {
      console.error('æœªåˆå§‹åŒ– AudioContext')
      return
    }

    if (mAudioContext && mAudioContext.state === 'suspended') {
      await mAudioContext.resume()
    }

    // è®¾ç½®éŸ³é¢‘æ—¶é—´é”šç‚¹
    mAudioContextStartTime = mAudioContext!.currentTime
    mPlaybackTimeAtStart = playbackModule.currentFrame.value / RENDERER_FPS

    console.log('â–¶ï¸ MediaBunny å¼€å§‹æ’­æ”¾')
  }

  /**
   * åœæ­¢ MediaBunny æ¸²æŸ“å¾ªç¯
   * ç”± UnifiedPlaybackModule è°ƒç”¨
   */
  async function stopPlayback(): Promise<void> {
    // åœæ­¢æ‰€æœ‰éŸ³é¢‘
    stopAllAudioNodes()

    // æ›´æ–°æ’­æ”¾æ—¶é—´é”šç‚¹
    mPlaybackTimeAtStart = playbackModule.currentFrame.value / RENDERER_FPS

    console.log('â¸ï¸ MediaBunny åœæ­¢æ’­æ”¾')
  }

  /**
   * è·³è½¬åˆ°æŒ‡å®šå¸§
   * ç”± UnifiedPlaybackModule è°ƒç”¨
   */
  function seekToFrame(frames: number): void {
    stopAllAudioNodes()

    // seekåªéœ€è¦æ›´æ–° mPlaybackTimeAtStart å³å¯
    // æ¸²æŸ“å¾ªç¯ä¼šä¸æ–­ä»¥ mPlaybackTimeAtStart ä¸ºåŸºå‡†ç‚¹æ¥æ¸²æŸ“
    const clampedFrames = Math.max(0, Math.min(mTimelineDuration, frames))
    mPlaybackTimeAtStart = clampedFrames / RENDERER_FPS

    console.log(`â© MediaBunny Seek åˆ°: ${clampedFrames}å¸§`)
  }

  /**
   * æ›´æ–°é¡¹ç›®æ—¶é•¿
   * @param newDurationN é¡¹ç›®æ—¶é•¿ï¼ˆå¸§æ•°ï¼Œnumberç±»å‹ï¼‰
   */
  function updateTimelineDuration(newDurationN: number): void {
    mTimelineDuration = newDurationN
    const durationSeconds = newDurationN / RENDERER_FPS
    console.log(`ğŸ¯ æ›´æ–°é¡¹ç›®æ—¶é•¿: ${durationSeconds.toFixed(2)}s ${newDurationN}å¸§`)
  }

  // ==================== äº‹ä»¶ç›‘å¬ ====================

  // åˆ›å»ºèŠ‚æµå‡½æ•°ï¼Œ100mså†…åªæ‰§è¡Œä¸€æ¬¡
  const throttledSeekToFrame = throttle(async (frame: number) => {
    console.log(`ğŸ¯ [MediaBunny] å¸§æ•°å˜åŒ–ï¼Œå·²è§¦å‘å¸§åŒæ­¥: ${mCurrentBunnyFrame} -> ${frame}`)
    seekToFrame(frame)
  }, 100)
  /**
   * è®¾ç½®æ’­æ”¾ç›‘å¬å™¨
   * ç›‘å¬ UnifiedPlaybackModule çš„çŠ¶æ€å˜åŒ–
   */
  function setupPlaybackListeners(): void {
    // ç›‘å¬å¸§æ•°å˜åŒ–ï¼ˆç”¨äº seekï¼‰
    watch([playbackModule.currentFrame, mCurrentBunnyFrame], ([new_cf, new_cbf]) => {
      if (new_cf != new_cbf && !playbackModule.isPlaying.value) {
        throttledSeekToFrame(new_cf)
      }
    })

    // ç›‘å¬æ—¶é—´è½´æ—¶é•¿å˜åŒ–ï¼Œè‡ªåŠ¨æ›´æ–° MediaBunny æ’­æ”¾å™¨æ—¶é•¿
    watch(
      totalDurationFrames,
      (newDurationFrames) => {
        updateTimelineDuration(newDurationFrames)
        console.log(`ğŸ¯ [MediaBunny] æ—¶é—´è½´æ—¶é•¿å˜åŒ–ï¼Œå·²æ›´æ–°æ’­æ”¾å™¨æ—¶é•¿: ${newDurationFrames}å¸§`)
      },
      { immediate: true },
    )

    console.log('âœ… MediaBunny æ’­æ”¾ç›‘å¬å™¨å·²è®¾ç½®')
  }

  // ==================== å·¥å…·æ–¹æ³• ====================

  /**
   * æ£€æŸ¥ MediaBunny æ˜¯å¦å¯ç”¨
   * @returns æ˜¯å¦å¯ç”¨
   */
  function isMediaBunnyAvailable(): boolean {
    return !!(mCanvas && mCtx && isMediaBunnyReady.value && !mediaBunnyError.value)
  }

  /**
   * é‡ç½® MediaBunny çŠ¶æ€ä¸ºé»˜è®¤å€¼
   */
  function resetToDefaults(): Promise<void> {
    return destroy()
  }

  // ==================== å¯¼å‡ºæ¥å£ ====================

  return {
    // çŠ¶æ€
    isMediaBunnyReady,
    mediaBunnyError,
    currentBunnyFrame: mCurrentBunnyFrame,

    // ç”»å¸ƒç®¡ç†
    setCanvas,
    destroy,

    // æ’­æ”¾æ§åˆ¶
    startPlayback,
    stopPlayback,
    seekToFrame,
    updateTimelineDuration,

    // å·¥å…·æ–¹æ³•
    isMediaBunnyAvailable,
    resetToDefaults,
  }
}

// å¯¼å‡ºç±»å‹å®šä¹‰
export type UnifiedMediaBunnyModule = ReturnType<typeof createUnifiedMediaBunnyModule>
