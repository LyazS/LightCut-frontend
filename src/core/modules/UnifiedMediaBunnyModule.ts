/**
 * UnifiedMediaBunnyModule - MediaBunny æ¸²æŸ“ç³»ç»Ÿæ¨¡å—
 * 
 * å®Œå…¨æ›¿ä»£ WebAV çš„æ¸²æŸ“ç³»ç»Ÿï¼Œä½¿ç”¨ MediaBunny å®ç°è‡ªå®šä¹‰æ¸²æŸ“å¾ªç¯
 * 
 * æ ¸å¿ƒç‰¹ç‚¹ï¼š
 * - å®Œå…¨æ›¿ä»£ WebAV æ¸²æŸ“
 * - è‡ªå®ç°æ¸²æŸ“å¾ªç¯ï¼ˆä¸ä¾èµ– WebAV çš„ AVCanvasï¼‰
 * - Canvas ç”± Vue ç»„ä»¶ç®¡ç†ï¼Œé€šè¿‡ setCanvas() ä¼ å…¥
 * - ä½¿ç”¨ runtime.bunnyClip (è§†é¢‘/éŸ³é¢‘)ã€runtime.textBitmap (æ–‡æœ¬)ã€runtime.bunny.imageClip (å›¾ç‰‡)
 * - æš‚ä¸æ”¯æŒå¯¼å‡ºåŠŸèƒ½ï¼ˆæœªæ¥å¯æ‰©å±•ï¼‰
 * - ä¼˜å…ˆé¢„è§ˆæ€§èƒ½
 */

import { ref, markRaw, watch, type Ref } from 'vue'
import { workerTimer } from '@/core/mediabunny/worker-timer'
import { RENDERER_FPS, AUDIO_DEFAULT_SAMPLE_RATE } from '@/core/mediabunny/constant'
import type { PlaybackState } from '@/core/mediabunny/types'
import type { BunnyClip } from '@/core/mediabunny/bunny-clip'
import { ModuleRegistry, MODULE_NAMES } from './ModuleRegistry'
import type { UnifiedTimelineModule } from './UnifiedTimelineModule'
import type { UnifiedMediaModule } from './UnifiedMediaModule'
import type { UnifiedTimelineItemData } from '@/core/timelineitem/TimelineItemData'
import type { MediaType } from '@/core/mediaitem/types'
import type { AudioSample } from 'mediabunny'

export function createUnifiedMediaBunnyModule(registry: ModuleRegistry) {
  // ==================== çŠ¶æ€å®šä¹‰ ====================
  
  // æ’­æ”¾çŠ¶æ€
  const playbackState = ref<PlaybackState>({
    isPlaying: false,
    currentTime: 0,
    duration: 0,
    currentTimeN: 0n,
    durationN: 0n,
  })
  
  // æ¨¡å—å°±ç»ªçŠ¶æ€
  const isMediaBunnyReady = ref(false)
  const mediaBunnyError = ref<string | null>(null)
  
  // Canvas ç›¸å…³ï¼ˆç”±å¤–éƒ¨ä¼ å…¥ï¼‰
  let canvas: HTMLCanvasElement | null = null
  let ctx: CanvasRenderingContext2D | null = null
  
  // æ¸²æŸ“å¾ªç¯ç›¸å…³
  let renderLoopCleanup: (() => void) | null = null
  let renderStart: number = 0
  let renderRunCnt: number = 0
  const expectFrameTime: number = 1000 / RENDERER_FPS
  
  // Web Audio API ç›¸å…³
  let audioContext: AudioContext | null = null
  let gainNode: GainNode | null = null
  
  // æ—¶é—´åŒæ­¥é”šç‚¹
  let audioContextStartTime: number | null = null
  let playbackTimeAtStart: number = 0
  
  // éŸ³é¢‘è°ƒåº¦ç›¸å…³
  const queuedAudioNodes = new Set<AudioBufferSourceNode>()
  
  // ==================== ç”»å¸ƒç®¡ç† ====================
  
  /**
   * è®¾ç½® Canvas å…ƒç´ å¹¶åˆå§‹åŒ–æ¸²æŸ“ç³»ç»Ÿ
   * @param canvasElement Canvas å…ƒç´ å¼•ç”¨ï¼ˆä» BunnyRender.vue ä¼ å…¥ï¼‰
   */
  async function setCanvas(canvasElement: HTMLCanvasElement): Promise<void> {
    try {
      if (!canvasElement) {
        throw new Error('Canvas å…ƒç´ ä¸èƒ½ä¸ºç©º')
      }
      
      // è®¾ç½® Canvas å¼•ç”¨
      canvas = canvasElement
      ctx = canvas.getContext('2d')
      
      if (!ctx) {
        throw new Error('æ— æ³•è·å– Canvas 2D ä¸Šä¸‹æ–‡')
      }
      
      console.log('âœ… Canvas å…ƒç´ å·²è®¾ç½®', {
        width: canvas.width,
        height: canvas.height,
      })
      
      // åˆå§‹åŒ–éŸ³é¢‘ç³»ç»Ÿ
      initializeAudioSystem()
      
      // å¯åŠ¨æ¸²æŸ“å¾ªç¯
      startRenderLoop()
      
      // è®¾ç½®äº‹ä»¶ç›‘å¬å™¨
      setupEventListeners()
      
      // æ ‡è®°ä¸ºå°±ç»ª
      isMediaBunnyReady.value = true
      mediaBunnyError.value = null
      
      console.log('âœ… MediaBunny æ¸²æŸ“ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ')
    } catch (error) {
      const errorMessage = error instanceof Error ? error.message : String(error)
      mediaBunnyError.value = `MediaBunny åˆå§‹åŒ–å¤±è´¥: ${errorMessage}`
      isMediaBunnyReady.value = false
      throw error
    }
  }
  
  /**
   * é”€æ¯ MediaBunny æ¸²æŸ“ç³»ç»Ÿ
   */
  async function destroy(): Promise<void> {
    console.log('ğŸ§¹ æ¸…ç† MediaBunny æ¸²æŸ“ç³»ç»Ÿèµ„æº')
    
    // åœæ­¢æ¸²æŸ“å¾ªç¯
    if (renderLoopCleanup) {
      renderLoopCleanup()
      renderLoopCleanup = null
    }
    
    // åœæ­¢æ’­æ”¾
    playbackState.value.isPlaying = false
    
    // åœæ­¢æ‰€æœ‰éŸ³é¢‘
    stopAllAudioNodes()
    
    // æ¸…ç©º Canvasï¼ˆå¦‚æœå­˜åœ¨ï¼‰
    if (canvas && ctx) {
      ctx.clearRect(0, 0, canvas.width, canvas.height)
    }
    
    // å…³é—­ AudioContext
    if (audioContext) {
      await audioContext.close()
      audioContext = null
    }
    
    // æ¸…ç†å¼•ç”¨ï¼ˆä¸åˆ é™¤ canvas å…ƒç´ ï¼Œç”± Vue ç»„ä»¶ç®¡ç†ï¼‰
    canvas = null
    ctx = null
    gainNode = null
    
    // æ¸…ç†çŠ¶æ€
    isMediaBunnyReady.value = false
    
    console.log('âœ… MediaBunny æ¸²æŸ“ç³»ç»Ÿèµ„æºæ¸…ç†å®Œæˆ')
  }
  
  // ==================== æ¸²æŸ“å¾ªç¯ ====================
  
  /**
   * å¯åŠ¨æ¸²æŸ“å¾ªç¯
   */
  function startRenderLoop(): void {
    if (renderLoopCleanup) {
      console.warn('âš ï¸ æ¸²æŸ“å¾ªç¯å·²åœ¨è¿è¡Œ')
      return
    }
    
    renderStart = performance.now()
    renderRunCnt = 0
    
    renderLoopCleanup = workerTimer(() => {
      // ä½¿ç”¨çœŸå®æ—¶é—´ä½œä¸ºåŸºå‡†ï¼Œé¿å…éŸ³ç”»ä¸åŒæ­¥
      if ((performance.now() - renderStart) / (expectFrameTime * renderRunCnt) < 1) {
        return
      }
      
      // æ‰§è¡Œæ¸²æŸ“å¸§
      renderFrame()
      
      renderRunCnt++
    }, expectFrameTime)
    
    console.log('ğŸ¬ MediaBunny æ¸²æŸ“å¾ªç¯å·²å¯åŠ¨')
  }
  
  /**
   * æ¸²æŸ“å•å¸§ï¼ˆç½‘æ ¼å¼å¸ƒå±€ï¼‰
   * ç›´æ¥ä½¿ç”¨ timelineItem.runtime ä¸­çš„æ•°æ®è¿›è¡Œæ¸²æŸ“
   */
  async function renderFrame(): Promise<void> {
    if (!canvas || !ctx || !playbackState.value.isPlaying) {
      return
    }
    
    // è·å–ä¾èµ–æ¨¡å—
    const timelineModule = registry.get<UnifiedTimelineModule>(MODULE_NAMES.TIMELINE)
    const mediaModule = registry.get<UnifiedMediaModule>(MODULE_NAMES.MEDIA)
    
    // è®¡ç®—å½“å‰æ’­æ”¾æ—¶é—´
    const currentTime = getCurrentPlaybackTime()
    const currentTimeN = BigInt(Math.floor(currentTime * RENDERER_FPS))
    playbackState.value.currentTime = currentTime
    playbackState.value.currentTimeN = currentTimeN
    
    // æ£€æŸ¥æ˜¯å¦æ’­æ”¾ç»“æŸ
    if (currentTimeN >= playbackState.value.durationN) {
      playbackState.value.currentTimeN = playbackState.value.durationN
      playbackState.value.isPlaying = false
      console.log('âœ… æ’­æ”¾ç»“æŸ')
      return
    }
    
    // æ›´æ–°æ‰€æœ‰ clipsï¼ˆè°ƒç”¨ tickN æ›´æ–° runtime.bunnyCurFrameï¼‰
    await updateClips(timelineModule.timelineItems.value, currentTimeN)
    
    // æ¸²æŸ“åˆ° Canvasï¼ˆä½¿ç”¨ runtime ä¸­çš„æ•°æ®ï¼‰
    renderToCanvas(timelineModule.timelineItems.value, mediaModule)
  }
  
  /**
   * æ›´æ–°æ‰€æœ‰ clips
   * è°ƒç”¨ bunnyClip.tickN() æ›´æ–° runtime.bunnyCurFrame å’Œå¤„ç†éŸ³é¢‘
   */
  async function updateClips(
    timelineItems: UnifiedTimelineItemData<MediaType>[],
    currentTimeN: bigint
  ): Promise<void> {
    await Promise.all(
      timelineItems.map(async (item) => {
        // æ£€æŸ¥æ˜¯å¦åœ¨æ—¶é—´èŒƒå›´å†…
        if (
          currentTimeN < item.timeRange.timelineStartTime ||
          currentTimeN > item.timeRange.timelineEndTime
        ) {
          // æ¸…ç†è¿‡æœŸå¸§
          if (item.runtime.bunnyCurFrame) {
            item.runtime.bunnyCurFrame.close()
            item.runtime.bunnyCurFrame = undefined
          }
          return
        }
        
        // å¤„ç†è§†é¢‘/éŸ³é¢‘
        if (item.mediaType === 'video' || item.mediaType === 'audio') {
          const bunnyClip = item.runtime.bunnyClip
          if (bunnyClip) {
            const { audio, video, state } = await bunnyClip.tickN(currentTimeN)
            
            if (state === 'success') {
              // æ›´æ–° runtime.bunnyCurFrame
              if (video && item.mediaType === 'video') {
                // å…ˆå…³é—­æ—§å¸§
                if (item.runtime.bunnyCurFrame) {
                  item.runtime.bunnyCurFrame.close()
                }
                item.runtime.bunnyCurFrame = video
              }
              
              // è°ƒåº¦éŸ³é¢‘
              if (audio.length > 0) {
                scheduleAudioBuffers(audio, bunnyClip.getPlaybackRate())
              }
            } else {
              // æ¸…ç†æ— æ•ˆå¸§
              if (item.runtime.bunnyCurFrame) {
                item.runtime.bunnyCurFrame.close()
                item.runtime.bunnyCurFrame = undefined
              }
            }
          }
        }
      })
    )
  }
  
  /**
   * æ¸²æŸ“åˆ° Canvasï¼ˆç½‘æ ¼å¸ƒå±€ï¼‰
   * ä½¿ç”¨ timelineItem.runtime ä¸­çš„æ•°æ®ï¼š
   * - runtime.bunnyCurFrame (è§†é¢‘)
   * - runtime.textBitmap (æ–‡æœ¬)
   * - mediaItem.runtime.bunny.imageClip (å›¾ç‰‡)
   */
  function renderToCanvas(
    timelineItems: UnifiedTimelineItemData<MediaType>[],
    mediaModule: UnifiedMediaModule
  ): void {
    if (!canvas || !ctx) return
    
    // æ¸…ç©ºç”»å¸ƒ
    ctx.clearRect(0, 0, canvas.width, canvas.height)
    
    // æ”¶é›†æ‰€æœ‰å¯æ¸²æŸ“çš„é¡¹ç›®
    const renderableItems = timelineItems.filter((item) => {
      if (item.mediaType === 'video') {
        return item.runtime.bunnyCurFrame !== undefined
      } else if (item.mediaType === 'text') {
        return item.runtime.textBitmap !== undefined
      } else if (item.mediaType === 'image') {
        const mediaItem = mediaModule.getMediaItem(item.mediaItemId)
        return mediaItem?.runtime.bunny?.imageClip !== undefined
      }
      return false
    })
    
    const itemCount = renderableItems.length
    if (itemCount === 0) return
    
    // è®¡ç®—ç½‘æ ¼è¡Œåˆ—æ•°ï¼ˆå°½é‡æ¥è¿‘æ­£æ–¹å½¢ï¼‰
    const cols = Math.ceil(Math.sqrt(itemCount))
    const rows = Math.ceil(itemCount / cols)
    
    // è®¡ç®—æ¯ä¸ªå•å…ƒæ ¼çš„å®½é«˜
    const cellWidth = canvas.width / cols
    const cellHeight = canvas.height / rows
    
    // ç»˜åˆ¶æ‰€æœ‰é¡¹ç›®
    renderableItems.forEach((item, index) => {
      const col = index % cols
      const row = Math.floor(index / cols)
      const x = col * cellWidth
      const y = row * cellHeight
      
      try {
        if (item.mediaType === 'video' && item.runtime.bunnyCurFrame) {
          // æ¸²æŸ“è§†é¢‘å¸§
          const videoFrame = item.runtime.bunnyCurFrame.toVideoFrame()
          ctx!.drawImage(videoFrame, x, y, cellWidth, cellHeight)
          videoFrame.close()
        } else if (item.mediaType === 'text' && item.runtime.textBitmap) {
          // æ¸²æŸ“æ–‡æœ¬
          ctx!.drawImage(item.runtime.textBitmap, x, y, cellWidth, cellHeight)
        } else if (item.mediaType === 'image') {
          // æ¸²æŸ“å›¾ç‰‡
          const mediaItem = mediaModule.getMediaItem(item.mediaItemId)
          const imageClip = mediaItem?.runtime.bunny?.imageClip
          if (imageClip) {
            ctx!.drawImage(imageClip, x, y, cellWidth, cellHeight)
          }
        }
      } catch (error) {
        console.error(`âŒ æ¸²æŸ“é¡¹ç›®å¤±è´¥: ${item.id}`, error)
      }
    })
  }
  
  // ==================== éŸ³é¢‘ç³»ç»Ÿ ====================
  
  /**
   * åˆå§‹åŒ–éŸ³é¢‘ç³»ç»Ÿ
   */
  function initializeAudioSystem(): void {
    audioContext = new AudioContext({
      sampleRate: AUDIO_DEFAULT_SAMPLE_RATE,
    })
    gainNode = audioContext.createGain()
    gainNode.connect(audioContext.destination)
    console.log(`ğŸ§ AudioContext å·²åˆ›å»ºï¼Œé‡‡æ ·ç‡: ${audioContext.sampleRate}Hz`)
  }
  
  /**
   * è°ƒåº¦éŸ³é¢‘ç¼“å†²
   */
  function scheduleAudioBuffers(audioSamples: AudioSample[], rate: number): void {
    if (!audioContext || !gainNode) return
    
    for (const sample of audioSamples) {
      const node = audioContext.createBufferSource()
      node.buffer = sample.toAudioBuffer()
      node.playbackRate.value = rate
      node.connect(gainNode)
      
      const startTimestamp =
        audioContextStartTime! + sample.timestamp - playbackTimeAtStart
      
      const curTime = audioContext.currentTime
      if (startTimestamp >= curTime) {
        node.start(startTimestamp)
      } else {
        const offset = curTime - startTimestamp
        node.start(curTime, offset)
      }
      
      queuedAudioNodes.add(node)
      
      node.onended = () => {
        queuedAudioNodes.delete(node)
      }
      
      sample.close()
    }
  }
  
  /**
   * åœæ­¢æ‰€æœ‰éŸ³é¢‘èŠ‚ç‚¹
   */
  function stopAllAudioNodes(): void {
    for (const node of queuedAudioNodes) {
      try {
        node.stop()
      } catch (err) {
        // å¿½ç•¥å·²åœæ­¢çš„èŠ‚ç‚¹
      }
    }
    queuedAudioNodes.clear()
  }
  
  // ==================== æ’­æ”¾æ§åˆ¶ ====================
  
  /**
   * å¼€å§‹æ’­æ”¾
   */
  async function play(): Promise<void> {
    if (!audioContext) {
      initializeAudioSystem()
    }
    
    if (audioContext && audioContext.state === 'suspended') {
      await audioContext.resume()
    }
    
    audioContextStartTime = audioContext!.currentTime
    playbackState.value.isPlaying = true
    
    console.log('â–¶ï¸ MediaBunny å¼€å§‹æ’­æ”¾')
  }
  
  /**
   * æš‚åœæ’­æ”¾
   */
  function pause(): void {
    const currentTimeN = BigInt(Math.floor(getCurrentPlaybackTime() * RENDERER_FPS))
    playbackTimeAtStart = Number(currentTimeN) / RENDERER_FPS
    
    playbackState.value.isPlaying = false
    stopAllAudioNodes()
    
    console.log('â¸ï¸ MediaBunny æš‚åœæ’­æ”¾')
  }
  
  /**
   * è·³è½¬åˆ°æŒ‡å®šå¸§
   */
  async function seekTo(timestampN: bigint): Promise<void> {
    playbackState.value.isPlaying = false
    stopAllAudioNodes()
    
    const durationN = playbackState.value.durationN
    timestampN = timestampN < 0n ? 0n : timestampN
    timestampN = timestampN > durationN ? durationN : timestampN
    
    playbackTimeAtStart = Number(timestampN) / RENDERER_FPS
    playbackState.value.currentTimeN = timestampN
    
    console.log(`â© MediaBunny Seek åˆ°: ${timestampN}å¸§`)
  }
  
  /**
   * è·å–å½“å‰æ’­æ”¾æ—¶é—´
   */
  function getCurrentPlaybackTime(): number {
    if (!playbackState.value.isPlaying || !audioContext) {
      return playbackTimeAtStart
    }
    
    return audioContext.currentTime - audioContextStartTime! + playbackTimeAtStart
  }
  
  /**
   * æ›´æ–°é¡¹ç›®æ—¶é•¿
   * @param durationN é¡¹ç›®æ—¶é•¿ï¼ˆå¸§æ•°ï¼Œbigintç±»å‹ï¼‰
   */
  function updateTimelineDuration(durationN: bigint): void {
    const durationSeconds = Number(durationN) / RENDERER_FPS
    playbackState.value.duration = durationSeconds
    playbackState.value.durationN = durationN
    console.log(`ğŸ¯ æ›´æ–°é¡¹ç›®æ—¶é•¿: ${durationSeconds.toFixed(2)}s ${durationN}å¸§`)
  }
  
  // ==================== äº‹ä»¶ç›‘å¬ ====================
  
  /**
   * è®¾ç½®äº‹ä»¶ç›‘å¬å™¨
   */
  function setupEventListeners(): void {
    // å¯ä»¥åœ¨è¿™é‡Œæ·»åŠ å…¶ä»–äº‹ä»¶ç›‘å¬å™¨
    console.log('âœ… MediaBunny äº‹ä»¶ç›‘å¬å™¨å·²è®¾ç½®')
  }
  
  // ==================== å·¥å…·æ–¹æ³• ====================
  
  /**
   * æ£€æŸ¥ MediaBunny æ˜¯å¦å¯ç”¨
   * @returns æ˜¯å¦å¯ç”¨
   */
  function isMediaBunnyAvailable(): boolean {
    return !!(canvas && ctx && isMediaBunnyReady.value && !mediaBunnyError.value)
  }
  
  /**
   * è·å– MediaBunny çŠ¶æ€æ‘˜è¦
   * @returns MediaBunny çŠ¶æ€æ‘˜è¦å¯¹è±¡
   */
  function getMediaBunnySummary() {
    return {
      hasCanvas: !!canvas,
      isReady: isMediaBunnyReady.value,
      hasError: !!mediaBunnyError.value,
      error: mediaBunnyError.value,
      isAvailable: isMediaBunnyAvailable(),
      canvasInfo: canvas
        ? {
            width: canvas.width,
            height: canvas.height,
          }
        : null,
      playbackState: {
        isPlaying: playbackState.value.isPlaying,
        currentTime: playbackState.value.currentTime,
        duration: playbackState.value.duration,
        currentTimeN: playbackState.value.currentTimeN.toString(),
        durationN: playbackState.value.durationN.toString(),
      },
    }
  }
  
  /**
   * é‡ç½® MediaBunny çŠ¶æ€ä¸ºé»˜è®¤å€¼
   */
  function resetToDefaults(): Promise<void> {
    return destroy()
  }
  
  // ==================== å¯¼å‡ºæ¥å£ ====================
  
  return {
    // çŠ¶æ€
    playbackState,
    isMediaBunnyReady,
    mediaBunnyError,
    
    // ç”»å¸ƒç®¡ç†
    setCanvas,
    destroy,
    
    // æ’­æ”¾æ§åˆ¶
    play,
    pause,
    seekTo,
    updateTimelineDuration,
    
    // å·¥å…·æ–¹æ³•
    isMediaBunnyAvailable,
    getMediaBunnySummary,
    resetToDefaults,
  }
}

// å¯¼å‡ºç±»å‹å®šä¹‰
export type UnifiedMediaBunnyModule = ReturnType<typeof createUnifiedMediaBunnyModule>