/**
 * é¡¹ç›®å¯¼å‡ºå·¥å…·
 * æä¾›è§†é¢‘é¡¹ç›®å¯¼å‡ºä¸º MP4 æ–‡ä»¶çš„åŠŸèƒ½
 * ä»¥åŠå•ä¸ªç´ æå¯¼å‡ºåŠŸèƒ½
 */

import {
  Output,
  Mp4OutputFormat,
  BufferTarget,
  CanvasSource,
  AudioSampleSource,
  QUALITY_VERY_LOW,
  QUALITY_LOW,
  QUALITY_MEDIUM,
  QUALITY_HIGH,
  QUALITY_VERY_HIGH,
  type Quality,
  type WrappedAudioBuffer,
} from 'mediabunny'

/**
 * å¸¦éŸ³é‡ä¿¡æ¯çš„éŸ³é¢‘ç¼“å†²
 */
export interface AudioBufferWithVolume {
  /** éŸ³é¢‘ç¼“å†²æ•°ç»„ */
  buffers: WrappedAudioBuffer[]
  /** å¯¹åº”çš„éŸ³é‡å€¼ (0-1) */
  volume: number
}
import type { UnifiedTimelineItemData } from '@/core/timelineitem/type'
import type { MediaType } from '@/core/mediaitem'
import type { UnifiedMediaItemData } from '@/core/mediaitem/types'
import type { IClip } from '@/core/mediabunny/IClip'
import { TimelineItemFactory } from '@/core/timelineitem/factory'
import { TimelineItemQueries } from '@/core/timelineitem/queries'
import { AudioSegmentRenderer } from '@/core/mediabunny/audio-segment-renderer'
import { RENDERER_FPS, AUDIO_DEFAULT_SAMPLE_RATE } from '@/core/mediabunny/constant'
import { applyAnimationToConfig } from '@/core/utils/animationInterpolation'
import {
  renderToCanvas,
  type FrameData,
  type RenderContext,
} from '@/core/bunnyUtils/canvasRenderer'
import { setupTimelineItemBunny } from '@/core/bunnyUtils/timelineItemSetup'

/**
 * å¯¼å‡ºé¡¹ç›®å‚æ•°æ¥å£
 */
export interface ExportProjectOptions {
  /** è§†é¢‘åˆ†è¾¨ç‡å®½åº¦ */
  videoWidth: number
  /** è§†é¢‘åˆ†è¾¨ç‡é«˜åº¦ */
  videoHeight: number
  /** é¡¹ç›®åç§° */
  projectName: string
  /** æ—¶é—´è½´é¡¹ç›®åˆ—è¡¨ */
  timelineItems: UnifiedTimelineItemData<MediaType>[]
  /** è½¨é“åˆ—è¡¨ */
  tracks: { id: string; isVisible: boolean; isMuted: boolean }[]
  /** è·å–åª’ä½“é¡¹ç›®çš„å‡½æ•° */
  getMediaItem: (id: string) => UnifiedMediaItemData | undefined
  /** è¿›åº¦æ›´æ–°å›è°ƒå‡½æ•°ï¼ˆå¯é€‰ï¼‰ */
  onProgress?: (stage: string, progress: number, details?: string) => void
  /** è§†é¢‘è´¨é‡ */
  videoQuality: Quality
  /** éŸ³é¢‘è´¨é‡ */
  audioQuality: Quality
  /** å¯¼å‡ºå¸§ç‡ï¼ˆå¯é€‰ï¼Œé»˜è®¤ 30fpsï¼‰ */
  frameRate?: number
}

/**
 * å¯¼å‡ºå•ä¸ªåª’ä½“é¡¹ç›®å‚æ•°
 */
export interface ExportMediaItemOptions {
  /** åª’ä½“é¡¹ç›®æ•°æ® */
  mediaItem: UnifiedMediaItemData
  /** è¿›åº¦æ›´æ–°å›è°ƒï¼ˆå¯é€‰ï¼‰ */
  onProgress?: (progress: number) => void
}

/**
 * å¯¼å‡ºå•ä¸ªæ—¶é—´è½´é¡¹ç›®å‚æ•°
 */
export interface ExportTimelineItemOptions {
  /** æ—¶é—´è½´é¡¹ç›®æ•°æ® */
  timelineItem: UnifiedTimelineItemData
  /** è¿›åº¦æ›´æ–°å›è°ƒï¼ˆå¯é€‰ï¼‰ */
  onProgress?: (progress: number) => void
}

/**
 * å¯¼å‡ºç®¡ç†å™¨ç±»
 * å°è£…æ‰€æœ‰å¯¼å‡ºé€»è¾‘
 */
class ExportManager {
  // Canvas ç›¸å…³
  private canvas: HTMLCanvasElement | null = null
  private ctx: CanvasRenderingContext2D | null = null

  // MediaBunny ç»„ä»¶
  private output: Output | null = null
  private canvasSource: CanvasSource | null = null
  private audioSource: AudioSampleSource | null = null

  // éŸ³é¢‘æ¸²æŸ“å™¨
  private audioSegmentRenderer: AudioSegmentRenderer | null = null

  // å…‹éš†çš„æ—¶é—´è½´é¡¹ç›®
  private clonedTimelineItems: UnifiedTimelineItemData<MediaType>[] = []

  // Clip æ˜ å°„è¡¨ï¼ˆä½¿ç”¨ TimelineItem ID ä½œä¸ºé”®ï¼‰
  private clipsMap: Map<string, IClip> = new Map()

  // å¸§æ•°æ®æ˜ å°„ï¼ˆç±»ä¼¼ UnifiedMediaBunnyModule çš„ bunnyCurFrameMapï¼‰
  private bunnyCurFrameMap: Map<string, FrameData> = new Map()

  // å¯¼å‡ºé…ç½®
  private config: ExportProjectOptions

  // å¸§ç‡é…ç½®
  private frameRate: number

  // æ§åˆ¶æ ‡å¿—
  private isExporting: boolean = false
  private shouldCancel: boolean = false

  constructor(config: ExportProjectOptions) {
    this.config = config
    this.frameRate = config.frameRate ?? RENDERER_FPS
    console.log(`âœ… å¯¼å‡ºå¸§ç‡è®¾ç½®ä¸º: ${this.frameRate}fps`)
  }

  /**
   * åˆ›å»º Canvas
   */
  private createCanvas(width: number, height: number): void {
    // åˆ›å»ºç¦»å± Canvasï¼ˆä¸æ·»åŠ åˆ° DOMï¼‰
    this.canvas = document.createElement('canvas')
    this.canvas.width = width
    this.canvas.height = height

    const ctx = this.canvas.getContext('2d')
    if (!ctx) {
      throw new Error('æ— æ³•åˆ›å»º Canvas 2D ä¸Šä¸‹æ–‡')
    }
    this.ctx = ctx

    console.log(`âœ… åˆ›å»ºå¯¼å‡º Canvas: ${width}x${height}`)
  }

  /**
   * å…‹éš†å¹¶é‡å»ºæ—¶é—´è½´é¡¹ç›®
   */
  private async cloneAndRebuildTimelineItems(
    originalItems: UnifiedTimelineItemData<MediaType>[],
    getMediaItem: (id: string) => UnifiedMediaItemData | undefined,
  ): Promise<UnifiedTimelineItemData<MediaType>[]> {
    const clonedItems: UnifiedTimelineItemData<MediaType>[] = []
    this.clipsMap = new Map() // åˆå§‹åŒ– clipsMap

    for (const originalItem of originalItems) {
      // 1. ä½¿ç”¨ TimelineItemFactory.clone å…‹éš†é¡¹ç›®
      const clonedItem = TimelineItemFactory.clone(originalItem)

      // 2. è·å–å…³è”çš„åª’ä½“é¡¹ç›®ï¼ˆå¦‚æœéœ€è¦ï¼‰
      let mediaItem: UnifiedMediaItemData | undefined
      if (
        TimelineItemQueries.isVideoTimelineItem(clonedItem) ||
        TimelineItemQueries.isAudioTimelineItem(clonedItem) ||
        TimelineItemQueries.isImageTimelineItem(clonedItem)
      ) {
        mediaItem = getMediaItem(clonedItem.mediaItemId)
        if (!mediaItem) {
          throw new Error(`æ‰¾ä¸åˆ°åª’ä½“é¡¹ç›®: ${clonedItem.mediaItemId}`)
        }
      }

      // 3. ä½¿ç”¨ setupTimelineItemBunny é‡å»º runtime
      await setupTimelineItemBunny(clonedItem, mediaItem)

      // 4. å¦‚æœæ˜¯éŸ³è§†é¢‘é¡¹ç›®ï¼Œæ·»åŠ åˆ° clipsMap
      if (clonedItem.runtime.bunnyClip) {
        this.clipsMap.set(clonedItem.id, clonedItem.runtime.bunnyClip)
      }

      clonedItems.push(clonedItem)
    }

    return clonedItems
  }

  /**
   * æ¸²æŸ“å¸§å¹¶æ”¶é›†éŸ³é¢‘
   */
  private async renderFrameAndCollectAudio(
    currentTimeN: number,
  ): Promise<Map<string, AudioBufferWithVolume>> {
    const audioBuffersMap = new Map<string, AudioBufferWithVolume>()

    // ğŸ”´ å…³é”®è½¬æ¢ï¼šç›®æ ‡å¸§ç‡ â†’ 30fps
    const frameIn30fps = Math.round(currentTimeN * (RENDERER_FPS / this.frameRate))

    // 1. æ›´æ–°æ‰€æœ‰ clips çš„å¸§æ•°æ®
    await Promise.all(
      this.clonedTimelineItems.map(async (item) => {
        // åº”ç”¨åŠ¨ç”»æ’å€¼ï¼ˆä½¿ç”¨ 30fps çš„å¸§æ•°ï¼‰
        applyAnimationToConfig(item, frameIn30fps)

        // å¤„ç†è§†é¢‘/éŸ³é¢‘é¡¹ç›®
        if (
          TimelineItemQueries.isVideoTimelineItem(item) ||
          TimelineItemQueries.isAudioTimelineItem(item)
        ) {
          const bunnyClip = item.runtime.bunnyClip
          if (!bunnyClip) return

          // æ£€æŸ¥æ˜¯å¦åœ¨æ—¶é—´èŒƒå›´å†…ï¼ˆä½¿ç”¨ 30fps çš„å¸§æ•°ï¼‰
          if (
            frameIn30fps < item.timeRange.timelineStartTime ||
            frameIn30fps > item.timeRange.timelineEndTime
          ) {
            return
          }

          // è·å–è½¨é“é™éŸ³çŠ¶æ€
          const track = this.config.tracks.find((t) => t.id === item.trackId)
          const isTrackMuted = track?.isMuted ?? false
          const isItemMuted = item.config.isMuted ?? false
          const shouldRequestAudio = !isTrackMuted && !isItemMuted

          // è°ƒç”¨ tickN è·å–éŸ³è§†é¢‘æ•°æ®ï¼ˆä½¿ç”¨ 30fps çš„å¸§æ•°ï¼‰
          const { audio, video, state } = await bunnyClip.tickN(
            BigInt(frameIn30fps),
            true,
            true,
            0n,
          )

          if (state === 'success') {
            // æ›´æ–°è§†é¢‘å¸§
            if (video) {
              const oldFrame = this.bunnyCurFrameMap.get(item.id)
              oldFrame?.videoSample.close()
              this.bunnyCurFrameMap.set(item.id, {
                frameNumber: frameIn30fps,
                videoSample: video,
              })
            }

            // æ”¶é›†éŸ³é¢‘ç¼“å†²ï¼ˆä½¿ç”¨ item.id ä½œä¸ºé”®ï¼‰
            if (shouldRequestAudio && audio && audio.length > 0) {
              // è·å–å½“å‰å¸§çš„éŸ³é‡å€¼ï¼ˆå·²ç»é€šè¿‡ applyAnimationToConfig åº”ç”¨äº†åŠ¨ç”»æ’å€¼ï¼‰
              const currentVolume = item.config.volume ?? 1.0
              audioBuffersMap.set(item.id, {
                buffers: audio,
                volume: currentVolume,
              })
            }
          } else {
            // æ¸…ç†æ— æ•ˆå¸§
            const oldFrame = this.bunnyCurFrameMap.get(item.id)
            oldFrame?.videoSample.close()
            this.bunnyCurFrameMap.delete(item.id)
          }
        }
      }),
    )

    // 2. æ¸²æŸ“åˆ° Canvas
    if (!this.canvas || !this.ctx) {
      throw new Error('Canvas æœªåˆå§‹åŒ–')
    }

    const renderContext: RenderContext = {
      canvas: this.canvas,
      ctx: this.ctx,
      bunnyCurFrameMap: this.bunnyCurFrameMap,
      getTrack: (trackId: string) => {
        const track = this.config.tracks.find((t) => t.id === trackId)
        return track ? { isVisible: track.isVisible } : undefined
      },
      getMediaItem: this.config.getMediaItem,
      trackIndexMap: new Map(this.config.tracks.map((track, index) => [track.id, index])),
    }

    renderToCanvas(renderContext, this.clonedTimelineItems, frameIn30fps)

    return audioBuffersMap
  }

  /**
   * åˆå§‹åŒ–éŸ³é¢‘æ¸²æŸ“å™¨
   */
  private async initializeAudioRenderer(): Promise<void> {
    // åˆå§‹åŒ– AudioSegmentRendererï¼ˆä¼ å…¥ clipsMapï¼‰
    this.audioSegmentRenderer = new AudioSegmentRenderer({
      clips: this.clipsMap,
      segmentDuration: 1.0, // 1 ç§’åˆ†æ®µ
      overlapDuration: 0.1, // 0.1 ç§’é‡å 
      sampleRate: AUDIO_DEFAULT_SAMPLE_RATE,
      numberOfChannels: 2,
    })

    // è®¾ç½® AudioSource
    if (this.audioSource) {
      this.audioSegmentRenderer.setAudioSource(this.audioSource)
    }
  }

  /**
   * è®¡ç®—æ€»å¸§æ•°
   */
  private calculateTotalFrames(): number {
    let maxEndTimeIn30fps = 0
    for (const item of this.clonedTimelineItems) {
      if (item.timeRange.timelineEndTime > maxEndTimeIn30fps) {
        maxEndTimeIn30fps = item.timeRange.timelineEndTime
      }
    }
    
    // å¦‚æœç›®æ ‡å¸§ç‡å°±æ˜¯30fpsï¼Œç›´æ¥è¿”å›ï¼Œæ— éœ€è½¬æ¢
    if (this.frameRate === RENDERER_FPS) {
      console.log(`ğŸ“Š å¸§æ•°è®¡ç®—: ${maxEndTimeIn30fps}å¸§@${this.frameRate}fps (æ— éœ€è½¬æ¢)`)
      return maxEndTimeIn30fps
    }
    
    // è½¬æ¢ï¼š30fpså¸§æ•° â†’ æ—¶é•¿ â†’ ç›®æ ‡å¸§ç‡å¸§æ•°
    const durationInSeconds = maxEndTimeIn30fps / RENDERER_FPS
    const totalFrames = Math.ceil(durationInSeconds * this.frameRate)
    
    console.log(`ğŸ“Š å¸§æ•°è½¬æ¢: ${maxEndTimeIn30fps}å¸§@30fps â†’ ${durationInSeconds}ç§’ â†’ ${totalFrames}å¸§@${this.frameRate}fps`)
    
    return totalFrames
  }

  /**
   * æŠ¥å‘Šè¿›åº¦
   */
  private reportProgress(stage: string, progress: number, details?: string): void {
    this.config.onProgress?.(stage, progress, details)
  }

  /**
   * ä¸»å¯¼å‡ºæµç¨‹
   */
  async export(): Promise<Uint8Array> {
    try {
      this.isExporting = true
      this.shouldCancel = false

      // é˜¶æ®µ 1: åˆå§‹åŒ–
      this.reportProgress('åˆå§‹åŒ–', 0, 'åˆ›å»º Canvas...')
      this.createCanvas(this.config.videoWidth, this.config.videoHeight)

      // é˜¶æ®µ 2: å…‹éš†é¡¹ç›®
      this.reportProgress('å‡†å¤‡', 5, 'å…‹éš†æ—¶é—´è½´é¡¹ç›®...')
      this.clonedTimelineItems = await this.cloneAndRebuildTimelineItems(
        this.config.timelineItems,
        this.config.getMediaItem,
      )

      // é˜¶æ®µ 3: åˆ›å»º MediaBunny ç»„ä»¶
      this.reportProgress('å‡†å¤‡', 10, 'åˆå§‹åŒ–ç¼–ç å™¨...')

      this.output = new Output({
        format: new Mp4OutputFormat(),
        target: new BufferTarget(),
      })

      this.canvasSource = new CanvasSource(this.canvas!, {
        codec: 'avc',
        bitrate: this.config.videoQuality,
      })

      this.audioSource = new AudioSampleSource({
        codec: 'mp3',
        bitrate: this.config.audioQuality,
      })

      // é˜¶æ®µ 4: åˆå§‹åŒ–éŸ³é¢‘æ¸²æŸ“å™¨
      await this.initializeAudioRenderer()

      // é˜¶æ®µ 5: æ·»åŠ è½¨é“å¹¶å¯åŠ¨
      this.output.addVideoTrack(this.canvasSource, {
        frameRate: this.frameRate,
      })
      this.output.addAudioTrack(this.audioSource)

      await this.output.start()

      // é˜¶æ®µ 6: æ¸²æŸ“å¾ªç¯
      const totalFrames = this.calculateTotalFrames()
      const frameDuration = 1 / this.frameRate
      let lastTriggerFrame = -1 // è®°å½•æœ€åä¸€æ¬¡è§¦å‘éŸ³é¢‘æ¸²æŸ“çš„å¸§å·

      for (let frameN = 0; frameN < totalFrames; frameN++) {
        // æ£€æŸ¥å–æ¶ˆ
        if (this.shouldCancel) {
          await this.output.cancel()
          throw new Error('å¯¼å‡ºå·²å–æ¶ˆ')
        }

        // æ¸²æŸ“å½“å‰å¸§å¹¶æ”¶é›†éŸ³é¢‘
        const audioBuffersMap = await this.renderFrameAndCollectAudio(frameN)

        // æ·»åŠ è§†é¢‘å¸§
        const timestamp = frameN / this.frameRate
        await this.canvasSource.add(timestamp, frameDuration)

        // æ”¶é›†éŸ³é¢‘ç¼“å†²åˆ°ç¼“å†²åŒº
        for (const [itemId, audioBufferWithVolume] of audioBuffersMap.entries()) {
          await this.audioSegmentRenderer!.collectAudioBuffers(
            audioBufferWithVolume.buffers,
            itemId,
            audioBufferWithVolume.volume,
          )
        }

        // åŠ¨æ€è®¡ç®—éŸ³é¢‘æ¸²æŸ“è§¦å‘ç‚¹ï¼ˆåŸºäºç›®æ ‡å¸§ç‡ï¼‰
        const framesPerSecond = this.frameRate
        const bufferFrames = Math.round(framesPerSecond * 2) // 2ç§’ç¼“å†²
        const triggerInterval = Math.round(framesPerSecond) // æ¯ç§’è§¦å‘ä¸€æ¬¡
        
        if (frameN >= bufferFrames - 1 && (frameN + 1 - bufferFrames) % triggerInterval === 0) {
          const segmentStartTime = Math.floor((frameN - bufferFrames + 1) / triggerInterval) * 1.0
          await this.audioSegmentRenderer!.renderFixedSegment(segmentStartTime)
          lastTriggerFrame = frameN
        }
        /**
         * è®¡ç®—æ¨¡æ‹ŸéŸ³é¢‘æ¸²æŸ“è¿›åº¦
         * [0-170]å¸§
         * 0-59  ï¼š frameN=59, segmentStartTime=0
         * 60-89 : frameN=89, segmentStartTime=1
         * 90-119: frameN=119, segmentStartTime=2
         * 120-149: frameN=149, segmentStartTime=3
         * 150-170: ä¸è§¦å‘
         */

        // æ›´æ–°è¿›åº¦ï¼ˆ10% - 95%ï¼‰
        const progress = 10 + ((frameN + 1) / totalFrames) * 85
        this.reportProgress('æ¸²æŸ“', progress, `${frameN + 1}/${totalFrames} å¸§`)
      }

      // å¤„ç†æœ€åéƒ¨åˆ†
      const bufferFrames = Math.round(this.frameRate * 2)
      const triggerInterval = Math.round(this.frameRate)
      
      if (lastTriggerFrame >= 0 && totalFrames > lastTriggerFrame + 1) {
        // æœ‰è§¦å‘è¿‡éŸ³é¢‘æ¸²æŸ“ï¼Œä¸”è¿˜æœ‰å‰©ä½™å¸§
        const lastRenderedSegmentIndex = Math.floor((lastTriggerFrame - bufferFrames + 1) / triggerInterval)
        const finalSegmentStartTime = (lastRenderedSegmentIndex + 1) * 1.0
        const totalDuration = totalFrames / this.frameRate
        await this.audioSegmentRenderer!.finalize(finalSegmentStartTime, totalDuration)
      } else if (lastTriggerFrame < 0) {
        // æ€»å¸§æ•°å°äºç¼“å†²å¸§æ•°ï¼Œæ²¡æœ‰è§¦å‘è¿‡ä»»ä½•æ®µï¼Œéœ€è¦ä»å¤´å¤„ç†
        const totalDuration = totalFrames / this.frameRate
        await this.audioSegmentRenderer!.finalize(0, totalDuration)
      }

      // é˜¶æ®µ 7: å®ŒæˆéŸ³é¢‘æ¸²æŸ“
      this.reportProgress('å®Œæˆ', 95, 'å¤„ç†éŸ³é¢‘...')
      // éŸ³é¢‘æ¸²æŸ“å·²ç»åœ¨ä¸»å¾ªç¯ä¸­å¤„ç†å®Œæˆ

      // é˜¶æ®µ 8: å…³é—­å¹¶å®Œæˆ
      this.canvasSource.close()
      this.audioSource.close()
      await this.output.finalize()

      // é˜¶æ®µ 9: è·å–ç»“æœ
      this.reportProgress('å®Œæˆ', 100, 'å¯¼å‡ºå®Œæˆ')
      const target = this.output.target as BufferTarget
      const buffer = target.buffer
      if (!buffer) {
        throw new Error('å¯¼å‡ºå¤±è´¥ï¼šæœªç”Ÿæˆç¼“å†²åŒº')
      }

      return new Uint8Array(buffer)
    } catch (error) {
      console.error('âŒ å¯¼å‡ºå¤±è´¥:', error)
      throw error
    } finally {
      await this.cleanup()
    }
  }

  /**
   * å–æ¶ˆå¯¼å‡º
   */
  cancel(): void {
    this.shouldCancel = true
  }

  /**
   * æ¸…ç†èµ„æº
   */
  private async cleanup(): Promise<void> {
    console.log('ğŸ§¹ æ¸…ç†å¯¼å‡ºèµ„æº...')

    // æ¸…ç†å¸§æ•°æ®
    for (const frameData of this.bunnyCurFrameMap.values()) {
      frameData.videoSample.close()
    }
    this.bunnyCurFrameMap.clear()

    // æ¸…ç†éŸ³é¢‘æ¸²æŸ“å™¨
    this.audioSegmentRenderer?.dispose()

    // æ¸…ç†å…‹éš†çš„ BunnyClips
    for (const clip of this.clipsMap.values()) {
      await clip.dispose()
    }
    this.clipsMap.clear()

    // æ¸…ç† textBitmap
    for (const item of this.clonedTimelineItems) {
      if (item.runtime.textBitmap) {
        item.runtime.textBitmap.close()
      }
    }

    // Canvas ä¼šè¢«åƒåœ¾å›æ”¶ï¼Œæ— éœ€æ‰‹åŠ¨æ¸…ç†

    this.isExporting = false
    console.log('âœ… å¯¼å‡ºèµ„æºæ¸…ç†å®Œæˆ')
  }
}

/**
 * å¯¼å‡ºé¡¹ç›®ä¸º MP4 æ–‡ä»¶
 * @param options å¯¼å‡ºé¡¹ç›®å‚æ•°
 */
export async function exportProject(options: ExportProjectOptions): Promise<void> {
  // åˆ›å»ºå¯¼å‡ºç®¡ç†å™¨
  const manager = new ExportManager(options)

  try {
    // æ‰§è¡Œå¯¼å‡º
    const videoData = await manager.export()

    // ä¿å­˜æ–‡ä»¶
    const blob = new Blob([videoData.buffer as ArrayBuffer], { type: 'video/mp4' })

    // ä½¿ç”¨ File System Access API è®©ç”¨æˆ·é€‰æ‹©ä¿å­˜ä½ç½®
    if ('showSaveFilePicker' in window) {
      try {
        // å¼¹å‡ºä¿å­˜å¯¹è¯æ¡†
        const fileHandle = await window.showSaveFilePicker({
          suggestedName: `${options.projectName}.mp4`,
          types: [
            {
              description: 'MP4 è§†é¢‘æ–‡ä»¶',
              accept: {
                'video/mp4': ['.mp4'],
              },
            },
          ],
        })

        // å†™å…¥æ–‡ä»¶
        const writable = await fileHandle.createWritable()
        await writable.write(blob)
        await writable.close()

        console.log('âœ… é¡¹ç›®å¯¼å‡ºæˆåŠŸ')
      } catch (error) {
        // ç”¨æˆ·å–æ¶ˆäº†ä¿å­˜æ“ä½œ
        if ((error as Error).name === 'AbortError') {
          console.log('âš ï¸ ç”¨æˆ·å–æ¶ˆäº†ä¿å­˜æ“ä½œ')
          throw new Error('ç”¨æˆ·å–æ¶ˆäº†ä¿å­˜æ“ä½œ')
        }
        throw error
      }
    } else {
      // é™çº§æ–¹æ¡ˆï¼šä½¿ç”¨ä¼ ç»Ÿçš„ä¸‹è½½æ–¹å¼ï¼ˆä¸æ”¯æŒ File System Access API çš„æµè§ˆå™¨ï¼‰
      console.warn('âš ï¸ æµè§ˆå™¨ä¸æ”¯æŒ File System Access APIï¼Œä½¿ç”¨ä¼ ç»Ÿä¸‹è½½æ–¹å¼')
      const url = URL.createObjectURL(blob)
      const a = document.createElement('a')
      a.href = url
      a.download = `${options.projectName}.mp4`
      a.click()
      URL.revokeObjectURL(url)

      console.log('âœ… é¡¹ç›®å¯¼å‡ºæˆåŠŸï¼ˆä¼ ç»Ÿæ–¹å¼ï¼‰')
    }
  } catch (error) {
    console.error('âŒ é¡¹ç›®å¯¼å‡ºå¤±è´¥:', error)
    throw error
  }
}

/**
 * å¯¼å‡ºå•ä¸ªåª’ä½“é¡¹ç›®ä¸º Blobï¼ˆä½¿ç”¨åŸå§‹å°ºå¯¸ï¼‰
 */
export async function exportMediaItem(options: ExportMediaItemOptions): Promise<Blob> {
  throw new Error('TODO: å•ä¸ªåª’ä½“é¡¹ç›®å¯¼å‡ºåŠŸèƒ½å¾…å®ç°')
}

/**
 * å¯¼å‡ºå•ä¸ªæ—¶é—´è½´é¡¹ç›®ä¸º Blobï¼ˆä½¿ç”¨åŸå§‹å°ºå¯¸ï¼‰
 */
export async function exportTimelineItem(options: ExportTimelineItemOptions): Promise<Blob> {
  throw new Error('TODO: å•ä¸ªæ—¶é—´è½´é¡¹ç›®å¯¼å‡ºåŠŸèƒ½å¾…å®ç°')
}
