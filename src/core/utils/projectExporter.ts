/**
 * é¡¹ç›®å¯¼å‡ºå·¥å…·
 * æä¾›è§†é¢‘é¡¹ç›®å¯¼å‡ºä¸º MP4 æ–‡ä»¶çš„åŠŸèƒ½
 * ä»¥åŠå•ä¸ªç´ æå¯¼å‡ºåŠŸèƒ½
 */

import {
  Output,
  Mp4OutputFormat,
  Mp3OutputFormat,
  BufferTarget,
  CanvasSource,
  AudioSampleSource,
  QUALITY_VERY_LOW,
  QUALITY_LOW,
  QUALITY_MEDIUM,
  QUALITY_HIGH,
  QUALITY_VERY_HIGH,
  type Quality,
  type WrappedAudioBuffer,
} from 'mediabunny'

/**
 * å¸¦éŸ³é‡ä¿¡æ¯çš„éŸ³é¢‘ç¼“å†²
 */
export interface AudioBufferWithVolume {
  /** éŸ³é¢‘ç¼“å†²æ•°ç»„ */
  buffers: WrappedAudioBuffer[]
  /** å¯¹åº”çš„éŸ³é‡å€¼ (0-1) */
  volume: number
}
import type { UnifiedTimelineItemData } from '@/core/timelineitem/type'
import type { MediaType } from '@/core/mediaitem'
import type { UnifiedMediaItemData } from '@/core/mediaitem/types'
import type { IClip } from '@/core/mediabunny/IClip'
import { TimelineItemFactory } from '@/core/timelineitem/factory'
import { TimelineItemQueries } from '@/core/timelineitem/queries'
import { AudioSegmentRenderer } from '@/core/mediabunny/audio-segment-renderer'
import { RENDERER_FPS, AUDIO_DEFAULT_SAMPLE_RATE } from '@/core/mediabunny/constant'
import { applyAnimationToConfig } from '@/core/utils/animationInterpolation'
import {
  renderToCanvas,
  type FrameData,
  type RenderContext,
} from '@/core/bunnyUtils/canvasRenderer'
import { setupTimelineItemBunny } from '@/core/bunnyUtils/timelineItemSetup'

/**
 * å¯¼å‡ºç±»å‹
 */
export type ExportType = 'video' | 'audio'

/**
 * å¯¼å‡ºé¡¹ç›®å‚æ•°æ¥å£
 */
export interface ExportProjectOptions {
  /** å¯¼å‡ºç±»å‹ï¼ˆè§†é¢‘æˆ–ä»…éŸ³é¢‘ï¼‰ */
  exportType: ExportType
  /** è§†é¢‘åˆ†è¾¨ç‡å®½åº¦ */
  videoWidth: number
  /** è§†é¢‘åˆ†è¾¨ç‡é«˜åº¦ */
  videoHeight: number
  /** é¡¹ç›®åç§° */
  projectName: string
  /** æ—¶é—´è½´é¡¹ç›®åˆ—è¡¨ */
  timelineItems: UnifiedTimelineItemData<MediaType>[]
  /** è½¨é“åˆ—è¡¨ */
  tracks: { id: string; isVisible: boolean; isMuted: boolean }[]
  /** è·å–åª’ä½“é¡¹ç›®çš„å‡½æ•° */
  getMediaItem: (id: string) => UnifiedMediaItemData | undefined
  /** è¿›åº¦æ›´æ–°å›è°ƒå‡½æ•°ï¼ˆå¯é€‰ï¼‰ */
  onProgress?: (stage: string, progress: number, details?: string) => void
  /** è§†é¢‘è´¨é‡ */
  videoQuality: Quality
  /** éŸ³é¢‘è´¨é‡ */
  audioQuality: Quality
  /** å¯¼å‡ºå¸§ç‡ï¼ˆå¯é€‰ï¼Œé»˜è®¤ 30fpsï¼‰ */
  frameRate?: number
}

/**
 * å¯¼å‡ºå•ä¸ªåª’ä½“é¡¹ç›®å‚æ•°
 */
export interface ExportMediaItemOptions {
  /** åª’ä½“é¡¹ç›®æ•°æ® */
  mediaItem: UnifiedMediaItemData
  /** è¿›åº¦æ›´æ–°å›è°ƒï¼ˆå¯é€‰ï¼‰ */
  onProgress?: (progress: number) => void
  /** å¯¼å‡ºå¸§ç‡ï¼ˆå¯é€‰ï¼Œé»˜è®¤ 30fpsï¼Œä»…è§†é¢‘æœ‰æ•ˆï¼‰ */
  frameRate?: number
}

/**
 * å¯¼å‡ºå•ä¸ªæ—¶é—´è½´é¡¹ç›®å‚æ•°
 */
export interface ExportTimelineItemOptions {
  /** æ—¶é—´è½´é¡¹ç›®æ•°æ® */
  timelineItem: UnifiedTimelineItemData
  /** è·å–åª’ä½“é¡¹ç›®çš„å‡½æ•° */
  getMediaItem: (id: string) => UnifiedMediaItemData | undefined
  /** è¿›åº¦æ›´æ–°å›è°ƒï¼ˆå¯é€‰ï¼‰ */
  onProgress?: (progress: number) => void
  /** å¯¼å‡ºç±»å‹ï¼ˆå¯é€‰ï¼Œä»…è§†é¢‘æ—¶é—´è½´é¡¹ç›®æ”¯æŒéŸ³é¢‘å¯¼å‡ºï¼‰ */
  exportType?: ExportType
  /** å¯¼å‡ºå¸§ç‡ï¼ˆå¯é€‰ï¼Œé»˜è®¤ 30fpsï¼Œä»…è§†é¢‘æœ‰æ•ˆï¼‰ */
  frameRate?: number
}

/**
 * å¯¼å‡ºå–æ¶ˆé”™è¯¯ç±»
 * ç”¨äºåŒºåˆ†å–æ¶ˆæ“ä½œå’Œå…¶ä»–é”™è¯¯
 */
export class ExportCancelledError extends Error {
  constructor() {
    super('å¯¼å‡ºå·²å–æ¶ˆ')
    this.name = 'ExportCancelledError'
  }
}

/**
 * å¯¼å‡ºç®¡ç†å™¨ç±»
 * å°è£…æ‰€æœ‰å¯¼å‡ºé€»è¾‘
 */
export class ExportManager {
  // Canvas ç›¸å…³
  private canvas: HTMLCanvasElement | null = null
  private ctx: CanvasRenderingContext2D | null = null

  // MediaBunny ç»„ä»¶
  private output: Output | null = null
  private canvasSource: CanvasSource | null = null
  private audioSource: AudioSampleSource | null = null

  // éŸ³é¢‘æ¸²æŸ“å™¨
  private audioSegmentRenderer: AudioSegmentRenderer | null = null

  // å…‹éš†çš„æ—¶é—´è½´é¡¹ç›®
  private clonedTimelineItems: UnifiedTimelineItemData<MediaType>[] = []

  // Clip æ˜ å°„è¡¨ï¼ˆä½¿ç”¨ TimelineItem ID ä½œä¸ºé”®ï¼‰
  private clipsMap: Map<string, IClip> = new Map()

  // å¸§æ•°æ®æ˜ å°„ï¼ˆç±»ä¼¼ UnifiedMediaBunnyModule çš„ bunnyCurFrameMapï¼‰
  private bunnyCurFrameMap: Map<string, FrameData> = new Map()

  // å¯¼å‡ºé…ç½®
  private config: ExportProjectOptions

  // å¸§ç‡é…ç½®
  private frameRate: number

  // æ§åˆ¶æ ‡å¿—
  private isExporting: boolean = false
  private shouldCancel: boolean = false

  constructor(config: ExportProjectOptions) {
    this.config = config
    this.frameRate = config.frameRate ?? RENDERER_FPS
    console.log(`âœ… å¯¼å‡ºå¸§ç‡è®¾ç½®ä¸º: ${this.frameRate}fps`)
  }

  /**
   * åˆ›å»º Canvas
   */
  private createCanvas(width: number, height: number): void {
    // åˆ›å»ºç¦»å± Canvasï¼ˆä¸æ·»åŠ åˆ° DOMï¼‰
    this.canvas = document.createElement('canvas')
    this.canvas.width = width
    this.canvas.height = height

    const ctx = this.canvas.getContext('2d')
    if (!ctx) {
      throw new Error('æ— æ³•åˆ›å»º Canvas 2D ä¸Šä¸‹æ–‡')
    }
    this.ctx = ctx

    console.log(`âœ… åˆ›å»ºå¯¼å‡º Canvas: ${width}x${height}`)
  }

  /**
   * å…‹éš†å¹¶é‡å»ºæ—¶é—´è½´é¡¹ç›®
   */
  private async cloneAndRebuildTimelineItems(
    originalItems: UnifiedTimelineItemData<MediaType>[],
    getMediaItem: (id: string) => UnifiedMediaItemData | undefined,
  ): Promise<UnifiedTimelineItemData<MediaType>[]> {
    const clonedItems: UnifiedTimelineItemData<MediaType>[] = []
    this.clipsMap = new Map() // åˆå§‹åŒ– clipsMap

    for (const originalItem of originalItems) {
      // 1. ä½¿ç”¨ TimelineItemFactory.clone å…‹éš†é¡¹ç›®
      const clonedItem = TimelineItemFactory.clone(originalItem)

      // 2. è·å–å…³è”çš„åª’ä½“é¡¹ç›®ï¼ˆå¦‚æœéœ€è¦ï¼‰
      let mediaItem: UnifiedMediaItemData | undefined
      if (
        TimelineItemQueries.isVideoTimelineItem(clonedItem) ||
        TimelineItemQueries.isAudioTimelineItem(clonedItem) ||
        TimelineItemQueries.isImageTimelineItem(clonedItem)
      ) {
        mediaItem = getMediaItem(clonedItem.mediaItemId)
        if (!mediaItem) {
          throw new Error(`æ‰¾ä¸åˆ°åª’ä½“é¡¹ç›®: ${clonedItem.mediaItemId}`)
        }
      }

      // 3. ä½¿ç”¨ setupTimelineItemBunny é‡å»º runtime
      await setupTimelineItemBunny(clonedItem, mediaItem)

      // 4. å¦‚æœæ˜¯éŸ³è§†é¢‘é¡¹ç›®ï¼Œæ·»åŠ åˆ° clipsMap
      if (clonedItem.runtime.bunnyClip) {
        this.clipsMap.set(clonedItem.id, clonedItem.runtime.bunnyClip)
      }

      clonedItems.push(clonedItem)
    }

    return clonedItems
  }

  /**
   * æ¸²æŸ“å¸§å¹¶æ”¶é›†éŸ³é¢‘
   */
  private async renderFrameAndCollectAudio(
    currentTimeN: number,
  ): Promise<Map<string, AudioBufferWithVolume>> {
    const audioBuffersMap = new Map<string, AudioBufferWithVolume>()

    // ğŸ”´ å…³é”®è½¬æ¢ï¼šç›®æ ‡å¸§ç‡ â†’ 30fps
    const frameIn30fps = Math.round(currentTimeN * (RENDERER_FPS / this.frameRate))

    // 1. æ›´æ–°æ‰€æœ‰ clips çš„å¸§æ•°æ®
    await Promise.all(
      this.clonedTimelineItems.map(async (item) => {
        // åº”ç”¨åŠ¨ç”»æ’å€¼ï¼ˆä½¿ç”¨ 30fps çš„å¸§æ•°ï¼‰
        applyAnimationToConfig(item, frameIn30fps)

        // å¤„ç†è§†é¢‘/éŸ³é¢‘é¡¹ç›®
        if (
          TimelineItemQueries.isVideoTimelineItem(item) ||
          TimelineItemQueries.isAudioTimelineItem(item)
        ) {
          const bunnyClip = item.runtime.bunnyClip
          if (!bunnyClip) return

          // æ£€æŸ¥æ˜¯å¦åœ¨æ—¶é—´èŒƒå›´å†…ï¼ˆä½¿ç”¨ 30fps çš„å¸§æ•°ï¼‰
          if (
            frameIn30fps < item.timeRange.timelineStartTime ||
            frameIn30fps > item.timeRange.timelineEndTime
          ) {
            return
          }

          // è·å–è½¨é“é™éŸ³çŠ¶æ€
          const track = this.config.tracks.find((t) => t.id === item.trackId)
          const isTrackMuted = track?.isMuted ?? false
          const isItemMuted = item.config.isMuted ?? false
          const shouldRequestAudio = !isTrackMuted && !isItemMuted

          // è°ƒç”¨ tickN è·å–éŸ³è§†é¢‘æ•°æ®ï¼ˆä½¿ç”¨ 30fps çš„å¸§æ•°ï¼‰
          const { audio, video, state } = await bunnyClip.tickN(
            BigInt(frameIn30fps),
            true,
            true,
            0n,
          )

          if (state === 'success') {
            // æ›´æ–°è§†é¢‘å¸§
            if (video) {
              const oldFrame = this.bunnyCurFrameMap.get(item.id)
              oldFrame?.videoSample.close()
              this.bunnyCurFrameMap.set(item.id, {
                frameNumber: frameIn30fps,
                clockwiseRotation: bunnyClip.clockwiseRotation,
                videoSample: video,
              })
            }

            // æ”¶é›†éŸ³é¢‘ç¼“å†²ï¼ˆä½¿ç”¨ item.id ä½œä¸ºé”®ï¼‰
            if (shouldRequestAudio && audio && audio.length > 0) {
              // âœ… ä½¿ç”¨è¾…åŠ©å‡½æ•°è·å–å½“å‰éŸ³é‡å€¼ï¼ˆåº”ç”¨äº†åŠ¨ç”»æ’å€¼ï¼‰
              const config = TimelineItemQueries.getRenderConfig(item)
              const currentVolume = config.volume ?? 1.0
              audioBuffersMap.set(item.id, {
                buffers: audio,
                volume: currentVolume,
              })
            }
          } else {
            // æ¸…ç†æ— æ•ˆå¸§
            const oldFrame = this.bunnyCurFrameMap.get(item.id)
            oldFrame?.videoSample.close()
            this.bunnyCurFrameMap.delete(item.id)
          }
        }
      }),
    )

    // 2. æ¸²æŸ“åˆ° Canvas
    if (!this.canvas || !this.ctx) {
      throw new Error('Canvas æœªåˆå§‹åŒ–')
    }

    const renderContext: RenderContext = {
      canvas: this.canvas,
      ctx: this.ctx,
      bunnyCurFrameMap: this.bunnyCurFrameMap,
      getTrack: (trackId: string) => {
        const track = this.config.tracks.find((t) => t.id === trackId)
        return track ? { isVisible: track.isVisible } : undefined
      },
      getMediaItem: this.config.getMediaItem,
      trackIndexMap: new Map(this.config.tracks.map((track, index) => [track.id, index])),
    }

    renderToCanvas(renderContext, this.clonedTimelineItems, frameIn30fps)

    return audioBuffersMap
  }

  /**
   * ä»…æ”¶é›†éŸ³é¢‘ï¼ˆä¸æ¸²æŸ“ Canvasï¼‰
   * ç”¨äºéŸ³é¢‘å¯¼å‡ºæ¨¡å¼
   */
  private async collectAudioOnly(
    currentTimeN: number,
  ): Promise<Map<string, AudioBufferWithVolume>> {
    const audioBuffersMap = new Map<string, AudioBufferWithVolume>()

    // ğŸ”´ å…³é”®è½¬æ¢ï¼šç›®æ ‡å¸§ç‡ â†’ 30fps
    const frameIn30fps = Math.round(currentTimeN * (RENDERER_FPS / this.frameRate))

    // æ›´æ–°æ‰€æœ‰ clips çš„å¸§æ•°æ®å¹¶æ”¶é›†éŸ³é¢‘
    await Promise.all(
      this.clonedTimelineItems.map(async (item) => {
        // åº”ç”¨åŠ¨ç”»æ’å€¼ï¼ˆä½¿ç”¨ 30fps çš„å¸§æ•°ï¼‰
        applyAnimationToConfig(item, frameIn30fps)

        // å¤„ç†è§†é¢‘/éŸ³é¢‘é¡¹ç›®
        if (
          TimelineItemQueries.isVideoTimelineItem(item) ||
          TimelineItemQueries.isAudioTimelineItem(item)
        ) {
          const bunnyClip = item.runtime.bunnyClip
          if (!bunnyClip) return

          // æ£€æŸ¥æ˜¯å¦åœ¨æ—¶é—´èŒƒå›´å†…ï¼ˆä½¿ç”¨ 30fps çš„å¸§æ•°ï¼‰
          if (
            frameIn30fps < item.timeRange.timelineStartTime ||
            frameIn30fps > item.timeRange.timelineEndTime
          ) {
            return
          }

          // è·å–è½¨é“é™éŸ³çŠ¶æ€
          const track = this.config.tracks.find((t) => t.id === item.trackId)
          const isTrackMuted = track?.isMuted ?? false
          const isItemMuted = item.config.isMuted ?? false
          const shouldRequestAudio = !isTrackMuted && !isItemMuted

          // è°ƒç”¨ tickN è·å–éŸ³é¢‘æ•°æ®ï¼ˆä¸è¯·æ±‚è§†é¢‘ï¼‰
          const { audio, state } = await bunnyClip.tickN(
            BigInt(frameIn30fps),
            true,  // éœ€è¦éŸ³é¢‘
            false, // ä¸éœ€è¦è§†é¢‘
            0n,
          )

          if (state === 'success' && shouldRequestAudio && audio && audio.length > 0) {
            // è·å–å½“å‰éŸ³é‡å€¼ï¼ˆåº”ç”¨äº†åŠ¨ç”»æ’å€¼ï¼‰
            const config = TimelineItemQueries.getRenderConfig(item)
            const currentVolume = config.volume ?? 1.0
            audioBuffersMap.set(item.id, {
              buffers: audio,
              volume: currentVolume,
            })
          }
        }
      }),
    )

    return audioBuffersMap
  }

  /**
   * åˆå§‹åŒ–éŸ³é¢‘æ¸²æŸ“å™¨
   */
  private async initializeAudioRenderer(): Promise<void> {
    // åˆå§‹åŒ– AudioSegmentRendererï¼ˆä¼ å…¥ clipsMapï¼‰
    this.audioSegmentRenderer = new AudioSegmentRenderer({
      clips: this.clipsMap,
      segmentDuration: 1.0, // 1 ç§’åˆ†æ®µ
      overlapDuration: 0.1, // 0.1 ç§’é‡å 
      sampleRate: AUDIO_DEFAULT_SAMPLE_RATE,
      numberOfChannels: 2,
    })

    // è®¾ç½® AudioSource
    if (this.audioSource) {
      this.audioSegmentRenderer.setAudioSource(this.audioSource)
    }
  }

  /**
   * è®¡ç®—æ€»å¸§æ•°
   */
  private calculateTotalFrames(): number {
    let maxEndTimeIn30fps = 0
    for (const item of this.clonedTimelineItems) {
      if (item.timeRange.timelineEndTime > maxEndTimeIn30fps) {
        maxEndTimeIn30fps = item.timeRange.timelineEndTime
      }
    }

    // å¦‚æœç›®æ ‡å¸§ç‡å°±æ˜¯30fpsï¼Œç›´æ¥è¿”å›ï¼Œæ— éœ€è½¬æ¢
    if (this.frameRate === RENDERER_FPS) {
      console.log(`ğŸ“Š å¸§æ•°è®¡ç®—: ${maxEndTimeIn30fps}å¸§@${this.frameRate}fps (æ— éœ€è½¬æ¢)`)
      return maxEndTimeIn30fps
    }

    // è½¬æ¢ï¼š30fpså¸§æ•° â†’ æ—¶é•¿ â†’ ç›®æ ‡å¸§ç‡å¸§æ•°
    const durationInSeconds = maxEndTimeIn30fps / RENDERER_FPS
    const totalFrames = Math.ceil(durationInSeconds * this.frameRate)

    console.log(
      `ğŸ“Š å¸§æ•°è½¬æ¢: ${maxEndTimeIn30fps}å¸§@30fps â†’ ${durationInSeconds}ç§’ â†’ ${totalFrames}å¸§@${this.frameRate}fps`,
    )

    return totalFrames
  }

  /**
   * æŠ¥å‘Šè¿›åº¦
   */
  private reportProgress(stage: string, progress: number, details?: string): void {
    this.config.onProgress?.(stage, progress, details)
  }

  /**
   * ä¸»å¯¼å‡ºæµç¨‹
   */
  async export(): Promise<Uint8Array> {
    try {
      this.isExporting = true
      this.shouldCancel = false

      const exportType = this.config.exportType
      const isAudioOnly = exportType === 'audio'

      // é˜¶æ®µ 1: åˆå§‹åŒ–
      if (isAudioOnly) {
        this.reportProgress('åˆå§‹åŒ–', 0, 'å‡†å¤‡éŸ³é¢‘å¯¼å‡º...')
        // éŸ³é¢‘å¯¼å‡ºä¸éœ€è¦ Canvas
      } else {
        this.reportProgress('åˆå§‹åŒ–', 0, 'åˆ›å»º Canvas...')
        this.createCanvas(this.config.videoWidth, this.config.videoHeight)
      }

      // é˜¶æ®µ 2: å…‹éš†é¡¹ç›®
      this.reportProgress('å‡†å¤‡', 5, 'å…‹éš†æ—¶é—´è½´é¡¹ç›®...')
      this.clonedTimelineItems = await this.cloneAndRebuildTimelineItems(
        this.config.timelineItems,
        this.config.getMediaItem,
      )

      // é˜¶æ®µ 3: åˆ›å»º MediaBunny ç»„ä»¶
      this.reportProgress('å‡†å¤‡', 10, 'åˆå§‹åŒ–ç¼–ç å™¨...')

      // æ ¹æ®å¯¼å‡ºç±»å‹é€‰æ‹©æ ¼å¼
      const outputFormat = isAudioOnly
        ? new Mp3OutputFormat()
        : new Mp4OutputFormat()

      this.output = new Output({
        format: outputFormat,
        target: new BufferTarget(),
      })

      // åªåœ¨è§†é¢‘å¯¼å‡ºæ—¶åˆ›å»º CanvasSource
      if (!isAudioOnly) {
        this.canvasSource = new CanvasSource(this.canvas!, {
          codec: 'avc',
          bitrate: this.config.videoQuality,
        })
      }

      this.audioSource = new AudioSampleSource({
        codec: 'mp3',
        bitrate: this.config.audioQuality,
      })

      // é˜¶æ®µ 4: åˆå§‹åŒ–éŸ³é¢‘æ¸²æŸ“å™¨
      await this.initializeAudioRenderer()

      // é˜¶æ®µ 5: æ·»åŠ è½¨é“å¹¶å¯åŠ¨
      if (!isAudioOnly && this.canvasSource) {
        this.output.addVideoTrack(this.canvasSource, {
          frameRate: this.frameRate,
        })
      }
      this.output.addAudioTrack(this.audioSource)

      await this.output.start()

      // é˜¶æ®µ 6: æ¸²æŸ“å¾ªç¯
      const totalFrames = this.calculateTotalFrames()
      const frameDuration = 1 / this.frameRate
      let lastTriggerFrame = -1 // è®°å½•æœ€åä¸€æ¬¡è§¦å‘éŸ³é¢‘æ¸²æŸ“çš„å¸§å·

      for (let frameN = 0; frameN < totalFrames; frameN++) {
        // æ£€æŸ¥å–æ¶ˆ
        if (this.shouldCancel) {
          await this.output.cancel()
          throw new ExportCancelledError()
        }

        // æ¸²æŸ“å½“å‰å¸§å¹¶æ”¶é›†éŸ³é¢‘ï¼ˆéŸ³é¢‘å¯¼å‡ºæ—¶è·³è¿‡æ¸²æŸ“ï¼Œåªæ”¶é›†éŸ³é¢‘ï¼‰
        const audioBuffersMap = isAudioOnly
          ? await this.collectAudioOnly(frameN)
          : await this.renderFrameAndCollectAudio(frameN)

        // æ·»åŠ è§†é¢‘å¸§ï¼ˆä»…åœ¨è§†é¢‘å¯¼å‡ºæ—¶ï¼‰
        if (!isAudioOnly && this.canvasSource) {
          const timestamp = frameN / this.frameRate
          await this.canvasSource.add(timestamp, frameDuration)
        }

        // æ”¶é›†éŸ³é¢‘ç¼“å†²åˆ°ç¼“å†²åŒº
        for (const [itemId, audioBufferWithVolume] of audioBuffersMap.entries()) {
          await this.audioSegmentRenderer!.collectAudioBuffers(
            audioBufferWithVolume.buffers,
            itemId,
            audioBufferWithVolume.volume,
          )
        }

        // åŠ¨æ€è®¡ç®—éŸ³é¢‘æ¸²æŸ“è§¦å‘ç‚¹ï¼ˆåŸºäºç›®æ ‡å¸§ç‡ï¼‰
        const framesPerSecond = this.frameRate
        const bufferFrames = Math.round(framesPerSecond * 2) // 2ç§’ç¼“å†²
        const triggerInterval = Math.round(framesPerSecond) // æ¯ç§’è§¦å‘ä¸€æ¬¡

        if (frameN >= bufferFrames - 1 && (frameN + 1 - bufferFrames) % triggerInterval === 0) {
          const segmentStartTime = Math.floor((frameN - bufferFrames + 1) / triggerInterval) * 1.0
          await this.audioSegmentRenderer!.renderFixedSegment(segmentStartTime)
          lastTriggerFrame = frameN
        }
        /**
         * è®¡ç®—æ¨¡æ‹ŸéŸ³é¢‘æ¸²æŸ“è¿›åº¦
         * [0-170]å¸§
         * 0-59  ï¼š frameN=59, segmentStartTime=0
         * 60-89 : frameN=89, segmentStartTime=1
         * 90-119: frameN=119, segmentStartTime=2
         * 120-149: frameN=149, segmentStartTime=3
         * 150-170: ä¸è§¦å‘
         */

        // æ›´æ–°è¿›åº¦ï¼ˆ10% - 95%ï¼‰
        const progress = 10 + ((frameN + 1) / totalFrames) * 85
        this.reportProgress('æ¸²æŸ“', progress, `${frameN + 1}/${totalFrames}`)
      }

      // å¤„ç†æœ€åéƒ¨åˆ†
      const bufferFrames = Math.round(this.frameRate * 2)
      const triggerInterval = Math.round(this.frameRate)

      if (lastTriggerFrame >= 0) {
        // æœ‰è§¦å‘è¿‡éŸ³é¢‘æ¸²æŸ“ï¼Œä¸”è¿˜æœ‰å‰©ä½™å¸§
        const lastRenderedSegmentIndex = Math.floor(
          (lastTriggerFrame - bufferFrames + 1) / triggerInterval,
        )
        const finalSegmentStartTime = (lastRenderedSegmentIndex + 1) * 1.0
        const totalDuration = totalFrames / this.frameRate
        await this.audioSegmentRenderer!.finalize(finalSegmentStartTime, totalDuration)
      } else if (lastTriggerFrame < 0) {
        // æ€»å¸§æ•°å°äºç¼“å†²å¸§æ•°ï¼Œæ²¡æœ‰è§¦å‘è¿‡ä»»ä½•æ®µï¼Œéœ€è¦ä»å¤´å¤„ç†
        const totalDuration = totalFrames / this.frameRate
        await this.audioSegmentRenderer!.finalize(0, totalDuration)
      }

      // é˜¶æ®µ 7: å®ŒæˆéŸ³é¢‘æ¸²æŸ“
      this.reportProgress('å®Œæˆ', 95, 'å¤„ç†éŸ³é¢‘...')
      // éŸ³é¢‘æ¸²æŸ“å·²ç»åœ¨ä¸»å¾ªç¯ä¸­å¤„ç†å®Œæˆ

      // é˜¶æ®µ 8: å…³é—­å¹¶å®Œæˆ
      if (this.canvasSource) {
        this.canvasSource.close()
      }
      this.audioSource.close()
      await this.output.finalize()

      // é˜¶æ®µ 9: è·å–ç»“æœ
      this.reportProgress('å®Œæˆ', 100, 'å¯¼å‡ºå®Œæˆ')
      const target = this.output.target as BufferTarget
      const buffer = target.buffer
      if (!buffer) {
        throw new Error('å¯¼å‡ºå¤±è´¥ï¼šæœªç”Ÿæˆç¼“å†²åŒº')
      }

      return new Uint8Array(buffer)
    } catch (error) {
      // åŒºåˆ†å–æ¶ˆæ“ä½œå’Œå…¶ä»–é”™è¯¯
      if (error instanceof ExportCancelledError) {
        console.log('âš ï¸ å¯¼å‡ºå·²å–æ¶ˆ')
      } else {
        console.error('âŒ å¯¼å‡ºå¤±è´¥:', error)
      }
      throw error
    } finally {
      await this.cleanup()
    }
  }

  /**
   * å–æ¶ˆå¯¼å‡º
   */
  cancel(): void {
    this.shouldCancel = true
  }

  /**
   * æ¸…ç†èµ„æº
   */
  private async cleanup(): Promise<void> {
    console.log('ğŸ§¹ æ¸…ç†å¯¼å‡ºèµ„æº...')

    // æ¸…ç†å¸§æ•°æ®
    for (const frameData of this.bunnyCurFrameMap.values()) {
      frameData.videoSample.close()
    }
    this.bunnyCurFrameMap.clear()

    // æ¸…ç†éŸ³é¢‘æ¸²æŸ“å™¨
    this.audioSegmentRenderer?.dispose()

    // æ¸…ç†å…‹éš†çš„ BunnyClips
    for (const clip of this.clipsMap.values()) {
      await clip.dispose()
    }
    this.clipsMap.clear()

    // æ¸…ç† textBitmap
    for (const item of this.clonedTimelineItems) {
      if (item.runtime.textBitmap) {
        item.runtime.textBitmap.close()
      }
    }

    // Canvas ä¼šè¢«åƒåœ¾å›æ”¶ï¼Œæ— éœ€æ‰‹åŠ¨æ¸…ç†

    this.isExporting = false
    console.log('âœ… å¯¼å‡ºèµ„æºæ¸…ç†å®Œæˆ')
  }
}

/**
 * å¯å–æ¶ˆçš„å¯¼å‡ºé¡¹ç›®ä¸º MP4 æ–‡ä»¶
 * è¿”å›å–æ¶ˆå‡½æ•°ï¼Œå…è®¸å¤–éƒ¨è°ƒç”¨å–æ¶ˆå¯¼å‡º
 * @param options å¯¼å‡ºé¡¹ç›®å‚æ•°
 * @param onSuccess å¯¼å‡ºæˆåŠŸå›è°ƒ
 * @param onError å¯¼å‡ºå¤±è´¥å›è°ƒ
 * @param onCancel å¯¼å‡ºå–æ¶ˆå›è°ƒ
 * @returns å–æ¶ˆå‡½æ•°
 */
export function exportProjectWithCancel(
  options: ExportProjectOptions,
  onSuccess?: () => void,
  onError?: (error: Error) => void,
  onCancel?: () => void,
): () => void {
  // åˆ›å»ºå¯¼å‡ºç®¡ç†å™¨å®ä¾‹
  const manager = new ExportManager(options)

  // æ‰§è¡Œå¯¼å‡ºå¹¶ä¿å­˜æ–‡ä»¶
  manager
    .export()
    .then(async (data) => {
      // æ ¹æ®å¯¼å‡ºç±»å‹ç¡®å®šæ–‡ä»¶æ‰©å±•åå’Œ MIME ç±»å‹
      const exportType = options.exportType
      const isAudioOnly = exportType === 'audio'

      const mimeType = isAudioOnly ? 'audio/mpeg' : 'video/mp4'
      const fileExtension = isAudioOnly ? 'mp3' : 'mp4'

      // ä¿å­˜æ–‡ä»¶
      const blob = new Blob([data.buffer as ArrayBuffer], { type: mimeType })
      const url = URL.createObjectURL(blob)
      const a = document.createElement('a')
      a.href = url
      a.download = `${options.projectName}.${fileExtension}`
      a.click()
      URL.revokeObjectURL(url)

      console.log(`âœ… é¡¹ç›®å¯¼å‡ºæˆåŠŸï¼ˆ${isAudioOnly ? 'éŸ³é¢‘' : 'è§†é¢‘'}ï¼‰`)
      onSuccess?.()
    })
    .catch((error) => {
      // åŒºåˆ†å–æ¶ˆæ“ä½œå’Œå…¶ä»–é”™è¯¯
      if (error instanceof ExportCancelledError) {
        console.log('âš ï¸ å¯¼å‡ºå·²å–æ¶ˆ')
        onCancel?.()
      } else {
        console.error('âŒ å¯¼å‡ºå¤±è´¥:', error)
        onError?.(error instanceof Error ? error : new Error(String(error)))
      }
    })

  // è¿”å›å–æ¶ˆå‡½æ•°
  return () => manager.cancel()
}

/**
 * å¯¼å‡ºå›¾ç‰‡åª’ä½“é¡¹ç›®ä¸º PNG Blob
 */
async function exportImageMediaItem(
  mediaItem: UnifiedMediaItemData,
  onProgress?: (progress: number) => void,
): Promise<Blob> {
  // 1. éªŒè¯ imageClip å­˜åœ¨
  const imageClip = mediaItem.runtime.bunny?.imageClip
  if (!imageClip) {
    throw new Error('åª’ä½“é¡¹ç›®æœªå°±ç»ªï¼šimageClip ä¸å­˜åœ¨')
  }

  onProgress?.(20)

  // 2. åˆ›å»ºä¸´æ—¶ Canvasï¼ˆä»…ç”¨äºæ ¼å¼è½¬æ¢ï¼‰
  const canvas = document.createElement('canvas')
  canvas.width = imageClip.width
  canvas.height = imageClip.height
  const ctx = canvas.getContext('2d')!

  // 3. ç»˜åˆ¶å›¾ç‰‡ï¼ˆæ— ä»»ä½•å˜æ¢ï¼Œä¿æŒåŸæ ·ï¼‰
  ctx.drawImage(imageClip, 0, 0)

  onProgress?.(60)

  // 4. è½¬æ¢ä¸º PNG Blob
  const blob = await new Promise<Blob>((resolve, reject) => {
    canvas.toBlob((blob) => {
      if (blob) {
        resolve(blob)
      } else {
        reject(new Error('å›¾ç‰‡è½¬æ¢å¤±è´¥'))
      }
    }, 'image/png')
  })

  onProgress?.(100)

  return blob
}

/**
 * å¯¼å‡ºè§†é¢‘åª’ä½“é¡¹ç›®ä¸º MP4 Blob
 */
async function exportVideoMediaItem(
  mediaItem: UnifiedMediaItemData,
  onProgress?: (progress: number) => void,
  frameRate?: number,
): Promise<Blob> {
  // 1. éªŒè¯åª’ä½“é¡¹ç›®çŠ¶æ€
  if (mediaItem.mediaStatus !== 'ready') {
    throw new Error('åª’ä½“é¡¹ç›®æœªå°±ç»ª')
  }

  const bunnyMedia = mediaItem.runtime.bunny?.bunnyMedia
  if (!bunnyMedia) {
    throw new Error('åª’ä½“é¡¹ç›®æœªå°±ç»ªï¼šbunnyMedia ä¸å­˜åœ¨')
  }
  await bunnyMedia.ready

  // 2. åˆ›å»ºä¸´æ—¶æ—¶é—´è½´é¡¹ç›®ï¼ˆè¦†ç›–æ•´ä¸ªåª’ä½“æ—¶é•¿ï¼‰
  const durationInFrames = Number(bunnyMedia.durationN)
  const tempTimelineItem: UnifiedTimelineItemData<'video'> = {
    id: 'temp-export-item',
    mediaType: 'video',
    mediaItemId: mediaItem.id,
    trackId: 'temp-track',
    timelineStatus: 'ready',
    timeRange: {
      timelineStartTime: 0,
      timelineEndTime: durationInFrames,
      clipStartTime: 0,
      clipEndTime: durationInFrames,
    },
    config: {
      // VideoMediaConfig = VisualProps & AudioProps
      x: 0,
      y: 0,
      width: bunnyMedia.width,
      height: bunnyMedia.height,
      rotation: 0,
      opacity: 1,
      proportionalScale: true,
      volume: 1,
      isMuted: false,
    },
    runtime: {
      isInitialized: true, // å¯¼å‡ºåœºæ™¯ï¼šä¸´æ—¶åˆ›å»ºçš„é¡¹ç›®ï¼Œå·²å®Œæˆåˆå§‹åŒ–
    },
  }

  // 3. æ„é€  ExportProjectOptions
  const exportOptions: ExportProjectOptions = {
    exportType: 'video',
    videoWidth: bunnyMedia.width,
    videoHeight: bunnyMedia.height,
    projectName: 'temp-export',
    timelineItems: [tempTimelineItem],
    tracks: [{ id: 'temp-track', isVisible: true, isMuted: false }],
    getMediaItem: (id: string) => (id === mediaItem.id ? mediaItem : undefined),
    onProgress: onProgress ? (stage, progress) => onProgress(progress) : undefined,
    videoQuality: QUALITY_MEDIUM,
    audioQuality: QUALITY_MEDIUM,
    frameRate: frameRate,
  }

  // 4. ä½¿ç”¨ ExportManager å¯¼å‡º
  const manager = new ExportManager(exportOptions)
  const videoData = await manager.export()

  // 5. è¿”å› Blob
  return new Blob([videoData.buffer as ArrayBuffer], { type: 'video/mp4' })
}

/**
 * å¯¼å‡ºéŸ³é¢‘åª’ä½“é¡¹ç›®ä¸º Blobï¼ˆç›´æ¥è¿”å›åŸå§‹æ–‡ä»¶ï¼‰
 */
async function exportAudioMediaItem(
  mediaItem: UnifiedMediaItemData,
  onProgress?: (progress: number) => void,
): Promise<Blob> {
  // ä» BunnyMedia è·å–åŸå§‹æ–‡ä»¶
  const bunnyMedia = mediaItem.runtime.bunny?.bunnyMedia
  if (!bunnyMedia) {
    throw new Error('åª’ä½“é¡¹ç›®æœªå°±ç»ªï¼šbunnyMedia ä¸å­˜åœ¨')
  }

  const oriFile = bunnyMedia.getOriFile()
  if (!oriFile) {
    throw new Error('æ— æ³•è·å–åŸå§‹éŸ³é¢‘æ–‡ä»¶')
  }

  onProgress?.(100)
  return new Blob([oriFile], { type: oriFile.type })
}

/**
 * å¯¼å‡ºå•ä¸ªåª’ä½“é¡¹ç›®ä¸º Blobï¼ˆä½¿ç”¨åŸå§‹å°ºå¯¸ï¼‰
 */
export async function exportMediaItem(options: ExportMediaItemOptions): Promise<Blob> {
  const { mediaItem, onProgress, frameRate } = options

  // 1. ç±»å‹æ£€æŸ¥
  if (mediaItem.mediaType === 'image') {
    return await exportImageMediaItem(mediaItem, onProgress)
  }

  if (mediaItem.mediaType === 'video') {
    return await exportVideoMediaItem(mediaItem, onProgress, frameRate)
  }

  if (mediaItem.mediaType === 'audio') {
    return await exportAudioMediaItem(mediaItem, onProgress)
  }

  throw new Error(`ä¸æ”¯æŒå¯¼å‡º ${mediaItem.mediaType} ç±»å‹çš„åª’ä½“é¡¹ç›®`)
}

/**
 * å¯¼å‡ºå›¾ç‰‡æ—¶é—´è½´é¡¹ç›®ä¸º PNG Blob
 */
async function exportImageTimelineItem(
  timelineItem: UnifiedTimelineItemData,
  getMediaItem: (id: string) => UnifiedMediaItemData | undefined,
  onProgress?: (progress: number) => void,
): Promise<Blob> {
  // 1. è·å–åª’ä½“é¡¹ç›®
  const mediaItem = getMediaItem(timelineItem.mediaItemId)
  if (!mediaItem) {
    throw new Error(`æ‰¾ä¸åˆ°åª’ä½“é¡¹ç›®: ${timelineItem.mediaItemId}`)
  }

  // 2. ç›´æ¥è°ƒç”¨ exportImageMediaItem
  return await exportImageMediaItem(mediaItem, onProgress)
}

/**
 * å¯¼å‡ºè§†é¢‘æ—¶é—´è½´é¡¹ç›®ä¸º MP4 Blob
 */
async function exportVideoTimelineItem(
  timelineItem: UnifiedTimelineItemData,
  getMediaItem: (id: string) => UnifiedMediaItemData | undefined,
  onProgress?: (progress: number) => void,
  frameRate?: number,
): Promise<Blob> {
  // 1. è·å–åª’ä½“é¡¹ç›®
  const mediaItem = getMediaItem(timelineItem.mediaItemId)
  if (!mediaItem) {
    throw new Error(`æ‰¾ä¸åˆ°åª’ä½“é¡¹ç›®: ${timelineItem.mediaItemId}`)
  }

  // 2. éªŒè¯åª’ä½“é¡¹ç›®çŠ¶æ€
  if (mediaItem.mediaStatus !== 'ready') {
    throw new Error('åª’ä½“é¡¹ç›®æœªå°±ç»ª')
  }

  const bunnyMedia = mediaItem.runtime.bunny?.bunnyMedia
  if (!bunnyMedia) {
    throw new Error('åª’ä½“é¡¹ç›®æœªå°±ç»ªï¼šbunnyMedia ä¸å­˜åœ¨')
  }
  await bunnyMedia.ready

  // 3. åˆ›å»ºæ–°çš„æ—¶é—´è½´é¡¹ç›®ï¼ˆåªä¿ç•™æ—¶é—´èŒƒå›´ï¼Œé‡ç½®å…¶ä»–é…ç½®ï¼‰
  const cleanTimelineItem: UnifiedTimelineItemData<'video'> = {
    id: 'temp-export-item',
    mediaType: 'video',
    mediaItemId: mediaItem.id,
    trackId: 'temp-track',
    timelineStatus: 'ready',
    timeRange: {
      // ä¿ç•™åŸå§‹æ—¶é—´èŒƒå›´
      timelineStartTime: 0,
      timelineEndTime:
        timelineItem.timeRange.timelineEndTime - timelineItem.timeRange.timelineStartTime,
      clipStartTime: timelineItem.timeRange.clipStartTime,
      clipEndTime: timelineItem.timeRange.clipEndTime,
    },
    config: {
      // é‡ç½®ä¸ºé»˜è®¤é…ç½®ï¼Œä¸åº”ç”¨ä»»ä½•æ•ˆæœ
      x: 0,
      y: 0,
      width: bunnyMedia.width,
      height: bunnyMedia.height,
      rotation: 0,
      opacity: 1,
      proportionalScale: true,
      volume: 1,
      isMuted: false,
    },
    runtime: {
      isInitialized: true, // å¯¼å‡ºåœºæ™¯ï¼šä¸´æ—¶åˆ›å»ºçš„é¡¹ç›®ï¼Œå·²å®Œæˆåˆå§‹åŒ–
    },
  }

  // 4. æ„é€  ExportProjectOptions
  const exportOptions: ExportProjectOptions = {
    exportType: 'video',
    videoWidth: bunnyMedia.width,
    videoHeight: bunnyMedia.height,
    projectName: 'temp-export',
    timelineItems: [cleanTimelineItem],
    tracks: [{ id: 'temp-track', isVisible: true, isMuted: false }],
    getMediaItem: (id: string) => (id === mediaItem.id ? mediaItem : undefined),
    onProgress: onProgress ? (stage, progress) => onProgress(progress) : undefined,
    videoQuality: QUALITY_MEDIUM,
    audioQuality: QUALITY_MEDIUM,
    frameRate: frameRate,
  }

  // 5. ä½¿ç”¨ ExportManager å¯¼å‡º
  const manager = new ExportManager(exportOptions)
  const videoData = await manager.export()

  // 6. è¿”å› Blob
  return new Blob([videoData.buffer as ArrayBuffer], { type: 'video/mp4' })
}

/**
 * å¯¼å‡ºè§†é¢‘/éŸ³é¢‘æ—¶é—´è½´é¡¹ç›®ä¸ºéŸ³é¢‘ MP3 Blob
 */
async function exportAudioTimelineItem(
  timelineItem: UnifiedTimelineItemData<'video' | 'audio'>,
  getMediaItem: (id: string) => UnifiedMediaItemData | undefined,
  onProgress?: (progress: number) => void,
): Promise<Blob> {
  // 1. è·å–åª’ä½“é¡¹ç›®
  const mediaItem = getMediaItem(timelineItem.mediaItemId)
  if (!mediaItem) {
    throw new Error(`æ‰¾ä¸åˆ°åª’ä½“é¡¹ç›®: ${timelineItem.mediaItemId}`)
  }

  // 2. éªŒè¯åª’ä½“é¡¹ç›®çŠ¶æ€
  if (mediaItem.mediaStatus !== 'ready') {
    throw new Error('åª’ä½“é¡¹ç›®æœªå°±ç»ª')
  }

  const bunnyMedia = mediaItem.runtime.bunny?.bunnyMedia
  if (!bunnyMedia) {
    throw new Error('åª’ä½“é¡¹ç›®æœªå°±ç»ªï¼šbunnyMedia ä¸å­˜åœ¨')
  }
  await bunnyMedia.ready

  // 3. åˆ›å»ºæ–°çš„æ—¶é—´è½´é¡¹ç›®ï¼ˆåªä¿ç•™æ—¶é—´èŒƒå›´ï¼Œé‡ç½®å…¶ä»–é…ç½®ï¼‰
  const cleanTimelineItem: UnifiedTimelineItemData<'video' | 'audio'> = {
    ...timelineItem,
    id: 'temp-export-item',
    trackId: 'temp-track',
    timelineStatus: 'ready',
    timeRange: {
      timelineStartTime: 0,
      timelineEndTime:
        timelineItem.timeRange.timelineEndTime - timelineItem.timeRange.timelineStartTime,
      clipStartTime: timelineItem.timeRange.clipStartTime,
      clipEndTime: timelineItem.timeRange.clipEndTime,
    },
    config: {
      // é‡ç½®ä¸ºé»˜è®¤é…ç½®
      x: 0,
      y: 0,
      width: timelineItem.mediaType === 'video' ? bunnyMedia.width : 0,
      height: timelineItem.mediaType === 'video' ? bunnyMedia.height : 0,
      rotation: 0,
      opacity: 1,
      proportionalScale: true,
      volume: 1,
      isMuted: false,
    },
    runtime: {
      isInitialized: true,
    },
  }

  // 4. æ„é€  ExportProjectOptions - ä½¿ç”¨éŸ³é¢‘å¯¼å‡º
  const exportOptions: ExportProjectOptions = {
    exportType: 'audio',
    videoWidth: timelineItem.mediaType === 'video' ? bunnyMedia.width : 1920,
    videoHeight: timelineItem.mediaType === 'video' ? bunnyMedia.height : 1080,
    projectName: 'temp-export',
    timelineItems: [cleanTimelineItem],
    tracks: [{ id: 'temp-track', isVisible: true, isMuted: false }],
    getMediaItem: (id: string) => (id === mediaItem.id ? mediaItem : undefined),
    onProgress: onProgress ? (stage, progress) => onProgress(progress) : undefined,
    videoQuality: QUALITY_MEDIUM,
    audioQuality: QUALITY_MEDIUM,
    frameRate: 30,
  }

  // 5. ä½¿ç”¨ ExportManager å¯¼å‡º
  const manager = new ExportManager(exportOptions)
  const audioData = await manager.export()

  // 6. è¿”å› Blob
  return new Blob([audioData.buffer as ArrayBuffer], { type: 'audio/mpeg' })
}

/**
 * å¯¼å‡ºå•ä¸ªæ—¶é—´è½´é¡¹ç›®ä¸º Blobï¼ˆä½¿ç”¨åŸå§‹å°ºå¯¸ï¼‰
 */
export async function exportTimelineItem(options: ExportTimelineItemOptions): Promise<Blob> {
  const { timelineItem, onProgress, getMediaItem, frameRate, exportType } = options

  // 1. ç±»å‹æ£€æŸ¥
  if (timelineItem.mediaType === 'image') {
    return await exportImageTimelineItem(timelineItem, getMediaItem, onProgress)
  }

  if (timelineItem.mediaType === 'video') {
    // å¦‚æœæŒ‡å®šäº†éŸ³é¢‘å¯¼å‡ºç±»å‹ï¼Œå¯¼å‡ºä¸ºéŸ³é¢‘
    if (exportType === 'audio') {
      return await exportAudioTimelineItem(timelineItem as UnifiedTimelineItemData<'video'>, getMediaItem, onProgress)
    }
    return await exportVideoTimelineItem(timelineItem, getMediaItem, onProgress, frameRate)
  }

  if (timelineItem.mediaType === 'audio') {
    // éŸ³é¢‘æ—¶é—´è½´é¡¹ç›®åªèƒ½å¯¼å‡ºä¸ºéŸ³é¢‘
    return await exportAudioTimelineItem(timelineItem as UnifiedTimelineItemData<'audio'>, getMediaItem, onProgress)
  }

  throw new Error(`ä¸æ”¯æŒå¯¼å‡º ${timelineItem.mediaType} ç±»å‹çš„æ—¶é—´è½´é¡¹ç›®`)
}
