import { ref, computed, type Ref, type Component } from 'vue'
import { useUnifiedStore } from '@/core/unifiedStore'
import { useAppI18n } from '@/core/composables/useI18n'
import {
  IconComponents,
  getTrackTypeIcon,
  getVisibilityIcon,
  getMuteIcon,
  getTrackTypeLabel,
} from '@/constants/iconComponents'
import type { UnifiedTrackType, UnifiedTrackData } from '@/core/track/TrackTypes'
import type { UnifiedTimelineItemData } from '@/core/timelineitem/type'
import { LayoutConstants } from '@/constants/LayoutConstants'
import { detectScene } from '@/core/utils/scene-detector'
import { detectSceneAdv } from '@/core/utils/scene-detector-adv'
import { detectSceneContent } from '@/core/utils/scene-detector-content'
import { exportTimelineItem } from '@/core/utils/projectExporter'
import { BizyairFileUploader } from '@/core/utils/bizyairFileUploader'
import { ASRSourceFactory, ASRTypeGuards, ASRTaskStatus } from '@/core/datasource/providers/asr'
import { ASRProcessor } from '@/core/datasource/providers/asr/ASRProcessor'
import { SourceOrigin } from '@/core/datasource/core/BaseDataSource'
import { generateMediaId } from '@/core/utils/idGenerator'
import type { FileData } from '@/core/datasource/providers/ai-generation/types'
import { RENDERER_FPS } from '@/core/mediabunny/constant'
import { createTextTimelineItem } from '@/core/utils/textTimelineUtils'
import { findOverlappingTimelineItemsOnTrack } from '@/core/utils/timelineSearchUtils'
import { setupTimelineItemBunny } from '@/core/bunnyUtils/timelineItemSetup'

/**
 * èœå•é¡¹ç±»å‹å®šä¹‰
 */
type MenuItem =
  | {
      label: string
      icon: Component
      onClick: () => void
    }
  | {
      label: string
      icon: Component
      children: MenuItem[]
    }
  | {
      type: 'separator'
    }

/**
 * æ—¶é—´è½´å³é”®èœå•æ¨¡å—
 * æä¾›æ—¶é—´è½´å³é”®èœå•ç›¸å…³çš„åŠŸèƒ½ï¼ŒåŒ…æ‹¬èœå•é¡¹ç”Ÿæˆå’Œèœå•æ“ä½œ
 */
export function useTimelineContextMenu(
  addNewTrack: (type: UnifiedTrackType, afterTrackId?: string) => Promise<void>,
  toggleVisibility: (trackId: string) => Promise<void>,
  toggleMute: (trackId: string) => Promise<void>,
  autoArrangeTrack: (trackId: string) => Promise<void>,
  startRename: (track: { id: string; name: string }) => Promise<void>,
  removeTrack: (trackId: string) => Promise<void>,
  handleTimelineItemRemove: (timelineItemId: string) => Promise<void>,
  createTextAtPosition: (trackId: string, timePosition: number) => Promise<void>,
  tracks: Ref<UnifiedTrackData[]>,
  getClipsForTrack: (trackId: string) => UnifiedTimelineItemData[],
  timelineBody: Ref<HTMLElement | undefined>,
) {
  const unifiedStore = useUnifiedStore()
  const { t } = useAppI18n()

  // å³é”®èœå•ç›¸å…³
  const showContextMenu = ref(false)
  const contextMenuType = ref<'clip' | 'track' | 'empty'>('empty')
  const contextMenuTarget = ref<{
    clipId?: string
    trackId?: string
    element?: HTMLElement
  }>({})

  const contextMenuOptions = ref({
    x: 0,
    y: 0,
    theme: 'mac dark',
    zIndex: 1000,
  })

  // è®¡ç®—å½“å‰èœå•é¡¹
  const currentMenuItems = computed(() => {
    switch (contextMenuType.value) {
      case 'clip':
        return getClipMenuItems()
      case 'track':
        return getTrackMenuItems()
      case 'empty':
      default:
        return getEmptyMenuItems()
    }
  })

  /**
   * è·å–ç©ºç™½åŒºåŸŸèœå•é¡¹
   */
  function getEmptyMenuItems(): MenuItem[] {
    return [
      {
        label: t('timeline.contextMenu.emptyArea.addVideoTrack'),
        icon: getTrackTypeIcon('video'),
        onClick: () => addNewTrack('video'),
      },
      {
        label: t('timeline.contextMenu.emptyArea.addAudioTrack'),
        icon: getTrackTypeIcon('audio'),
        onClick: () => addNewTrack('audio'),
      },
      {
        label: t('timeline.contextMenu.emptyArea.addTextTrack'),
        icon: getTrackTypeIcon('text'),
        onClick: () => addNewTrack('text'),
      },
    ]
  }

  /**
   * è·å–ç‰‡æ®µèœå•é¡¹
   */
  function getClipMenuItems(): MenuItem[] {
    const clipId = contextMenuTarget.value.clipId
    if (!clipId) return []

    const timelineItem = unifiedStore.getTimelineItem(clipId)
    if (!timelineItem) return []

    const menuItems: MenuItem[] = []

    // åªæœ‰ ready çŠ¶æ€çš„ timelineItem æ‰æœ‰å„ç§å³é”®é€‰é¡¹
    // é ready çŠ¶æ€ï¼ˆloading æˆ– errorï¼‰åªæœ‰åˆ é™¤é€‰é¡¹
    if (timelineItem.timelineStatus === 'ready') {
      // æ™ºèƒ½åˆ†é•œå¤´ - ä»…è§†é¢‘ç±»å‹æ”¯æŒ
      if (timelineItem.mediaType === 'video') {
        menuItems.push({
          label: t('timeline.contextMenu.clip.smartSceneDetection'),
          icon: IconComponents.LAYOUT,
          onClick: () => detectSceneBoundaries(),
        })

        // åˆ†éš”ç¬¦
        menuItems.push({ type: 'separator' } as MenuItem)
      }

      // è¯­éŸ³è¯†åˆ« - ä»…è§†é¢‘å’ŒéŸ³é¢‘ç±»å‹æ”¯æŒ
      if (timelineItem.mediaType === 'video' || timelineItem.mediaType === 'audio') {
        menuItems.push({
          label: t('timeline.contextMenu.clip.speechRecognition'),
          icon: IconComponents.MUSIC,
          onClick: () => startSpeechRecognition(),
        })

        // åˆ†éš”ç¬¦
        menuItems.push({ type: 'separator' } as MenuItem)
      }

      // å¤åˆ¶ç‰‡æ®µ - æ‰€æœ‰ç±»å‹éƒ½æ”¯æŒ
      menuItems.push({
        label: t('timeline.contextMenu.clip.duplicateClip'),
        icon: IconComponents.COPY,
        onClick: () => duplicateClip(),
      })

      // åˆ†éš”ç¬¦
      menuItems.push({ type: 'separator' } as MenuItem)
    }

    // åˆ é™¤ç‰‡æ®µ - æ‰€æœ‰çŠ¶æ€éƒ½æ”¯æŒ
    menuItems.push({
      label: t('timeline.contextMenu.clip.deleteClip'),
      icon: IconComponents.DELETE,
      onClick: () => removeClip(),
    })

    return menuItems
  }

  /**
   * è·å–è½¨é“èœå•é¡¹
   */
  function getTrackMenuItems(): MenuItem[] {
    const trackId = contextMenuTarget.value.trackId
    if (!trackId) return []

    const track = tracks.value.find((t) => t.id === trackId)
    if (!track) return []

    const hasClips = getClipsForTrack(trackId).length > 0
    const canDelete = tracks.value.length > 1

    const menuItems: MenuItem[] = []

    // æ–‡æœ¬è½¨é“ä¸“ç”¨èœå•é¡¹
    if (track.type === 'text') {
      menuItems.push({
        label: t('timeline.contextMenu.track.addText'),
        icon: IconComponents.TEXT_LINE,
        onClick: () => {
          const timePosition = getTimePositionFromContextMenu(contextMenuOptions.value)
          createTextAtPosition(trackId, timePosition)
        },
      })

      if (hasClips) {
        menuItems.push({ type: 'separator' } as MenuItem)
      }
    }

    // é€šç”¨èœå•é¡¹
    menuItems.push(
      {
        label: hasClips
          ? t('timeline.contextMenu.track.autoArrangeClips')
          : t('timeline.contextMenu.track.autoArrangeClipsEmpty'),
        icon: IconComponents.LAYOUT,
        onClick: hasClips ? () => autoArrangeTrack(trackId) : () => {},
      },
      {
        label: t('timeline.contextMenu.track.renameTrack'),
        icon: IconComponents.EDIT,
        onClick: () => renameTrack(),
      },
    )

    // å¯è§æ€§æ§åˆ¶ - éŸ³é¢‘è½¨é“ä¸æ˜¾ç¤º
    if (track.type !== 'audio') {
      menuItems.push({
        label: track.isVisible
          ? t('timeline.contextMenu.track.hideTrack')
          : t('timeline.contextMenu.track.showTrack'),
        icon: getVisibilityIcon(track.isVisible),
        onClick: () => toggleVisibility(trackId),
      })
    }

    // é™éŸ³æ§åˆ¶ - æ–‡æœ¬è½¨é“ä¸æ˜¾ç¤º
    if (track.type !== 'text') {
      menuItems.push({
        label: track.isMuted
          ? t('timeline.contextMenu.track.unmuteTrack')
          : t('timeline.contextMenu.track.muteTrack'),
        icon: getMuteIcon(track.isMuted),
        onClick: () => toggleMute(trackId),
      })
    }

    // æ·»åŠ æ–°è½¨é“å­èœå•
    menuItems.push({ type: 'separator' } as MenuItem, {
      label: t('timeline.contextMenu.track.addNewTrack'),
      icon: IconComponents.ADD,
      children: [
        {
          label: t('timeline.contextMenu.track.addVideoTrack'),
          icon: getTrackTypeIcon('video'),
          onClick: () => addNewTrack('video', trackId),
        },
        {
          label: t('timeline.contextMenu.track.addAudioTrack'),
          icon: getTrackTypeIcon('audio'),
          onClick: () => addNewTrack('audio', trackId),
        },
        {
          label: t('timeline.contextMenu.track.addTextTrack'),
          icon: getTrackTypeIcon('text'),
          onClick: () => addNewTrack('text', trackId),
        },
      ],
    })

    // åˆ é™¤è½¨é“é€‰é¡¹
    if (canDelete) {
      menuItems.push({
        label: t('timeline.contextMenu.track.deleteTrack'),
        icon: IconComponents.DELETE,
        onClick: () => removeTrack(trackId),
      })
    }

    return menuItems
  }

  /**
   * å¤„ç†å³é”®èœå•
   * @param event é¼ æ ‡äº‹ä»¶
   */
  function handleContextMenu(event: MouseEvent) {
    event.preventDefault()

    // æ›´æ–°èœå•ä½ç½®
    contextMenuOptions.value.x = event.clientX
    contextMenuOptions.value.y = event.clientY

    // åˆ¤æ–­å³é”®ç‚¹å‡»çš„ç›®æ ‡ç±»å‹
    const target = event.target as HTMLElement

    // æŸ¥æ‰¾æœ€è¿‘çš„ç‰‡æ®µå…ƒç´ 
    const clipElement = target.closest('[data-timeline-item-id]') as HTMLElement
    if (clipElement) {
      // ç‚¹å‡»åœ¨ç‰‡æ®µä¸Š
      const clipId = clipElement.getAttribute('data-timeline-item-id')
      if (clipId) {
        contextMenuType.value = 'clip'
        contextMenuTarget.value = { clipId, element: clipElement }
        showContextMenu.value = true
        return
      }
    }

    // æŸ¥æ‰¾æœ€è¿‘çš„è½¨é“æ§åˆ¶å…ƒç´ 
    const trackControlElement = target.closest('.track-controls') as HTMLElement
    if (trackControlElement) {
      // ç‚¹å‡»åœ¨è½¨é“æ§åˆ¶åŒºåŸŸ
      const trackRow = trackControlElement.closest('.track-row') as HTMLElement
      if (trackRow) {
        const trackIndex = Array.from(trackRow.parentElement?.children || []).indexOf(trackRow)
        const track = tracks.value[trackIndex]
        if (track) {
          contextMenuType.value = 'track'
          contextMenuTarget.value = { trackId: track.id, element: trackControlElement }
          showContextMenu.value = true
          return
        }
      }
    }

    // æŸ¥æ‰¾è½¨é“å†…å®¹åŒºåŸŸ
    const trackContentElement = target.closest('.track-content') as HTMLElement
    if (trackContentElement) {
      // ç‚¹å‡»åœ¨è½¨é“å†…å®¹åŒºåŸŸï¼ˆç©ºç™½å¤„ï¼‰
      const trackRow = trackContentElement.closest('.track-row') as HTMLElement
      if (trackRow) {
        const trackIndex = Array.from(trackRow.parentElement?.children || []).indexOf(trackRow)
        const track = tracks.value[trackIndex]
        if (track) {
          contextMenuType.value = 'track'
          contextMenuTarget.value = { trackId: track.id, element: trackContentElement }
          showContextMenu.value = true
          return
        }
      }
    }

    // é»˜è®¤æƒ…å†µï¼šç‚¹å‡»åœ¨ç©ºç™½åŒºåŸŸ
    contextMenuType.value = 'empty'
    contextMenuTarget.value = { element: target }
    showContextMenu.value = true
  }

  /**
   * å¤„ç†æ—¶é—´è½´é¡¹ç›®å³é”®èœå•
   * @param event é¼ æ ‡äº‹ä»¶
   * @param id æ—¶é—´è½´é¡¹ç›®ID
   */
  function handleTimelineItemContextMenu(event: MouseEvent, id: string) {
    // å¤„ç†æ—¶é—´è½´é¡¹ç›®å³é”®èœå•
    event.preventDefault()
    contextMenuOptions.value.x = event.clientX
    contextMenuOptions.value.y = event.clientY
    contextMenuType.value = 'clip'
    contextMenuTarget.value = { clipId: id }
    showContextMenu.value = true
  }

  /**
   * åˆ é™¤ç‰‡æ®µ
   */
  async function removeClip() {
    if (contextMenuTarget.value.clipId) {
      await handleTimelineItemRemove(contextMenuTarget.value.clipId)
      showContextMenu.value = false
    }
  }

  /**
   * å¤åˆ¶ç‰‡æ®µ
   */
  async function duplicateClip() {
    if (contextMenuTarget.value.clipId) {
      try {
        await unifiedStore.duplicateTimelineItemWithHistory(contextMenuTarget.value.clipId)
        console.log('âœ… æ—¶é—´è½´é¡¹ç›®å¤åˆ¶æˆåŠŸ')
      } catch (error) {
        console.error('âŒ å¤åˆ¶æ—¶é—´è½´é¡¹ç›®æ—¶å‡ºé”™:', error)
      }
      showContextMenu.value = false
    }
  }

  /**
   * æ™ºèƒ½åˆ†é•œå¤´æ£€æµ‹ï¼ˆä½¿ç”¨ createLoadingï¼‰
   */
  async function detectSceneBoundaries() {
    const clipId = contextMenuTarget.value.clipId
    if (!clipId) return

    const timelineItem = unifiedStore.getTimelineItem(clipId)
    if (!timelineItem) return

    console.log('ğŸ¬ å¼€å§‹æ™ºèƒ½åˆ†é•œå¤´æ£€æµ‹...')

    // æš‚åœæ’­æ”¾
    await unifiedStore.pause()

    // åˆ›å»º AbortController ç”¨äºå–æ¶ˆæ“ä½œ
    const abortController = new AbortController()

    // åˆ›å»º loading å®ä¾‹
    const loading = unifiedStore.createLoading({
      title: t('timeline.sceneDetection.title'),
      showProgress: true,
      showDetails: true,
      showTips: true,
      tipText: t('timeline.sceneDetection.tip'),
      showCancel: true,
      cancelText: t('common.cancel'),
      onCancel: () => {
        abortController.abort()
        console.log('âš ï¸ ç”¨æˆ·å–æ¶ˆåœºæ™¯æ£€æµ‹')
      }
    })

    try {
      // è°ƒç”¨ detectSceneAdvï¼Œä¼ å…¥è¿›åº¦å›è°ƒå’Œå–æ¶ˆä¿¡å·
      const boundaries = await detectSceneAdv(timelineItem, {
        peakDetection: {
          minProminence: 0.03,
          minHeight: 0.08,
          minDistance: 15,
        },
        maxSize: 600,
        signal: abortController.signal,
        onProgress: (current, total, message) => {
          // è®¡ç®—è¿›åº¦ç™¾åˆ†æ¯”
          const progress = total > 0 ? (current / total) * 100 : 0
          
          // æ›´æ–° loading çŠ¶æ€
          loading.update({
            progress: Math.min(100, Math.round(progress)),
            details: message
          })
        },
        enableChart: false,
      })

      // æ£€æŸ¥æ˜¯å¦è¢«å–æ¶ˆ
      if (abortController.signal.aborted) {
        loading.close()
        unifiedStore.messageInfo(t('timeline.sceneDetection.cancelled'))
        return
      }

      // å¤„ç†æ£€æµ‹ç»“æœ
      if (boundaries.length > 0) {
        console.log('âœ… æ£€æµ‹å®Œæˆï¼Œå…±å‘ç°', boundaries.length, 'ä¸ªåˆ†å‰²ç‚¹')
        
        loading.update({
          progress: 100,
          details: t('timeline.sceneDetection.splitting', { count: boundaries.length })
        })

        const splitPoints = boundaries.map((frame) => Number(frame))
        await unifiedStore.splitTimelineItemAtTimeWithHistory(clipId, splitPoints)
        
        loading.close()
        unifiedStore.messageSuccess(
          t('timeline.sceneDetection.success', { count: boundaries.length })
        )
        console.log('âœ… æ—¶é—´è½´é¡¹ç›®åˆ†å‰²æˆåŠŸ')
      } else {
        console.log('âš ï¸ æœªæ£€æµ‹åˆ°åœºæ™¯è¾¹ç•Œ')
        loading.close()
        unifiedStore.messageWarning(t('timeline.sceneDetection.noScenes'))
      }
    } catch (error) {
      loading.close()
      
      // åŒºåˆ†å–æ¶ˆå’Œé”™è¯¯
      if (error instanceof Error && error.name === 'AbortError') {
        unifiedStore.messageInfo(t('timeline.sceneDetection.cancelled'))
      } else {
        console.error('âŒ æ™ºèƒ½åˆ†é•œå¤´æ£€æµ‹å¤±è´¥:', error)
        unifiedStore.messageError(
          t('timeline.sceneDetection.error', {
            message: error instanceof Error ? error.message : String(error)
          })
        )
      }
    }

    showContextMenu.value = false
  }

  /**
   * æŸ¥æ‰¾æˆ–åˆ›å»ºå¯ç”¨çš„textè½¨é“
   * @param startTime å¼€å§‹æ—¶é—´ï¼ˆå¸§ï¼‰
   * @param endTime ç»“æŸæ—¶é—´ï¼ˆå¸§ï¼‰
   * @param sourceTrackId æºéŸ³è§†é¢‘æ‰€åœ¨è½¨é“ID
   * @returns å¯ç”¨çš„è½¨é“ID
   */
  async function findOrCreateAvailableTextTrack(
    startTime: number,
    endTime: number,
    sourceTrackId: string,
  ): Promise<string> {
    // 1. è·å–æ‰€æœ‰textè½¨é“
    const textTracks = tracks.value.filter(t => t.type === 'text')

    // 2. æŸ¥æ‰¾æºéŸ³è§†é¢‘è½¨é“ä¸‹æ–¹çš„ç¬¬ä¸€ä¸ªä¸å†²çªçš„textè½¨é“
    const sourceTrackIndex = tracks.value.findIndex(t => t.id === sourceTrackId)

    // æŒ‰è½¨é“ç´¢å¼•æ’åºï¼Œä¼˜å…ˆæŸ¥æ‰¾æºè½¨é“é™„è¿‘çš„è½¨é“
    const sortedTextTracks = [...textTracks].sort((a, b) => {
      const indexA = tracks.value.findIndex(t => t.id === a.id)
      const indexB = tracks.value.findIndex(t => t.id === b.id)
      return Math.abs(indexA - sourceTrackIndex) - Math.abs(indexB - sourceTrackIndex)
    })

    // 3. æ£€æŸ¥æ¯ä¸ªè½¨é“æ˜¯å¦æœ‰å†²çª
    for (const track of sortedTextTracks) {
      const overlappingItems = findOverlappingTimelineItemsOnTrack(
        track.id,
        startTime,
        endTime,
        unifiedStore.timelineItems,
      )

      if (overlappingItems.length === 0) {
        console.log('âœ… [ASR] æ‰¾åˆ°å¯ç”¨çš„textè½¨é“:', track.id)
        return track.id  // æ‰¾åˆ°ä¸å†²çªçš„è½¨é“
      }
    }

    // 4. æ‰€æœ‰è½¨é“éƒ½æœ‰å†²çªï¼Œåˆ›å»ºæ–°çš„textè½¨é“
    console.log('ğŸ“¦ [ASR] æ‰€æœ‰textè½¨é“éƒ½æœ‰å†²çªï¼Œåˆ›å»ºæ–°è½¨é“')
    await unifiedStore.addTrackWithHistory('text')
    const newTrackId = tracks.value[tracks.value.length - 1].id
    console.log('âœ… [ASR] æ–°å»ºtextè½¨é“:', newTrackId)

    return newTrackId
  }

  /**
   * åˆ›å»ºASRå ä½ç¬¦æ–‡æœ¬item
   * @param sourceTimelineItem æºéŸ³è§†é¢‘item
   * @param estimatedDuration é¢„ä¼°æ—¶é•¿ï¼ˆç§’ï¼‰
   * @returns åˆ›å»ºçš„å ä½ç¬¦item
   */
  async function createPlaceholderTextItem(
    sourceTimelineItem: UnifiedTimelineItemData,
    estimatedDuration: number,
  ): Promise<UnifiedTimelineItemData<'text'>> {
    // 1. è®¡ç®—æ—¶é—´èŒƒå›´ï¼ˆå¸§æ•°ï¼‰
    const startTimeFrames = sourceTimelineItem.timeRange.timelineStartTime
    const durationFrames = Math.round(estimatedDuration * RENDERER_FPS)

    // 2. æŸ¥æ‰¾åˆé€‚çš„textè½¨é“
    const targetTrackId = await findOrCreateAvailableTextTrack(
      startTimeFrames,
      startTimeFrames + durationFrames,
      sourceTimelineItem.trackId || '',
    )

    // 3. åˆ›å»ºå ä½ç¬¦æ–‡æœ¬item
    const placeholderItem = await createTextTimelineItem(
      'æ­£åœ¨è¯†åˆ«...',  // å ä½æ–‡æœ¬
      {
        fontSize: 48,
        color: '#ffffff',
        backgroundColor: 'rgba(0, 0, 0, 0.5)',
      },
      startTimeFrames,
      targetTrackId,
      durationFrames,
      `asr_placeholder_${sourceTimelineItem.id}`,  // ç‰¹æ®ŠIDå‰ç¼€
    )

    // 4. è®¾ç½®ä¸ºloadingçŠ¶æ€
    placeholderItem.timelineStatus = 'loading'

    // 5. è®¾ç½® bunny å¯¹è±¡ï¼ˆæ–‡æœ¬æ¸²æŸ“éœ€è¦ï¼‰
    await setupTimelineItemBunny(placeholderItem)

    // 6. ä» textBitmap è·å–å®é™…å®½é«˜å¹¶è®¾ç½®åˆ° config
    if (placeholderItem.runtime.textBitmap) {
      placeholderItem.config.width = placeholderItem.runtime.textBitmap.width
      placeholderItem.config.height = placeholderItem.runtime.textBitmap.height
    }

    // 7. æ·»åŠ åˆ°æ—¶é—´è½´ï¼ˆä¸éœ€è¦å†å²è®°å½•ï¼Œç›´æ¥æ·»åŠ ï¼‰
    await unifiedStore.addTimelineItem(placeholderItem)
    console.log('âœ… [ASR] å ä½ç¬¦itemåˆ›å»ºå®Œæˆ:', placeholderItem.id)

    return placeholderItem
  }

  /**
   * å¼€å§‹è¯­éŸ³è¯†åˆ«
   * æµç¨‹ï¼šæå–éŸ³é¢‘ -> ä¸Šä¼ åˆ°bizyair -> æäº¤ASRä»»åŠ¡ -> åˆ›å»ºå ä½ç¬¦item -> åˆ›å»ºMediaItem
   */
  async function startSpeechRecognition() {
    const clipId = contextMenuTarget.value.clipId
    if (!clipId) return

    const timelineItem = unifiedStore.getTimelineItem(clipId)
    if (!timelineItem) return

    console.log('ğŸ¬ [ASR] å¼€å§‹è¯­éŸ³è¯†åˆ«, clipId:', clipId)

    // åˆ›å»º loading å®ä¾‹
    const loading = unifiedStore.createLoading({
      title: t('timeline.speechRecognition.title'),
      showProgress: true,
      showDetails: true,
      showCancel: false,
    })

    try {
      // 1. æå–éŸ³é¢‘
      loading.update({ progress: 10, details: t('timeline.speechRecognition.extractingAudio') })
      console.log('ğŸ“¦ [ASR] æ­£åœ¨æå–éŸ³é¢‘...')
      
      const audioBlob = await exportTimelineItem({
        timelineItem,
        getMediaItem: unifiedStore.getMediaItem,
        exportType: 'audio',
      })
      console.log('âœ… [ASR] éŸ³é¢‘æå–å®Œæˆ, size:', audioBlob.size)

      // 2. ä¸Šä¼ åˆ° Bizyair
      loading.update({ progress: 30, details: t('timeline.speechRecognition.uploading') })
      console.log('â¬†ï¸ [ASR] æ­£åœ¨ä¸Šä¼ éŸ³é¢‘åˆ°Bizyair...')
      
      // æ„é€  FileData å¯¹è±¡
      const fileData: FileData = {
        __type__: 'FileData',
        name: `asr_${clipId}.mp3`,
        mediaType: 'audio',
        timelineItemId: clipId,
        source: 'timeline-item',
      }
      
      const uploadResult = await BizyairFileUploader.uploadFile(
        fileData,
        unifiedStore.getMediaItem,
        unifiedStore.getTimelineItem,
      )

      if (!uploadResult.success) {
        throw new Error(uploadResult.error || 'ä¸Šä¼ å¤±è´¥')
      }
      console.log('âœ… [ASR] ä¸Šä¼ å®Œæˆ, url:', uploadResult.url)

      // 3. æäº¤ ASR ä»»åŠ¡åˆ°åç«¯
      loading.update({ progress: 50, details: t('timeline.speechRecognition.creatingTask') })
      console.log('ğŸš€ [ASR] æäº¤ASRä»»åŠ¡åˆ°åç«¯...')

      const asrProcessor = ASRProcessor.getInstance()
      const estimatedDuration = (timelineItem.timeRange.clipEndTime - timelineItem.timeRange.clipStartTime) / RENDERER_FPS // ä½¿ç”¨RENDERER_FPSå¸¸é‡
      
      const submitResult = await asrProcessor.submitASRTask({
        audio_url: uploadResult.url!,
        audio_format: 'mp3',
        estimated_duration: estimatedDuration,
      })

      if (!submitResult.success || !submitResult.task_id) {
        throw new Error(submitResult.error_message || 'æäº¤ä»»åŠ¡å¤±è´¥')
      }
      console.log('âœ… [ASR] ä»»åŠ¡æäº¤æˆåŠŸ, taskId:', submitResult.task_id)

      // 4. åˆ›å»ºå ä½ç¬¦æ—¶é—´è½´item
      loading.update({ progress: 60, details: 'åˆ›å»ºå ä½ç¬¦...' })
      console.log('ğŸ“¦ [ASR] æ­£åœ¨åˆ›å»ºå ä½ç¬¦item...')
      
      const placeholderItem = await createPlaceholderTextItem(timelineItem, estimatedDuration)
      console.log('âœ… [ASR] å ä½ç¬¦itemåˆ›å»ºå®Œæˆ:', placeholderItem.id)

      // 5. åˆ›å»º ASR æ•°æ®æºï¼ˆåŒ…å«å ä½ç¬¦item IDï¼‰
      const asrSource = ASRSourceFactory.createASRSource(
        {
          type: 'asr',
          asrTaskId: submitResult.task_id,
          requestConfig: {
            audio_url: uploadResult.url!,
            audio_format: 'mp3',
            estimated_duration: estimatedDuration,
          },
          taskStatus: ASRTaskStatus.PENDING,
          sourceTimelineItemId: clipId,
          placeholderTimelineItemId: placeholderItem.id,  // ğŸ†• è®°å½•å ä½ç¬¦item ID
        },
        SourceOrigin.USER_CREATE,
      )

      // 6. åˆ›å»ºåª’ä½“é¡¹å¹¶æ·»åŠ åˆ°åº“
      const mediaId = generateMediaId('txt')
      const mediaName = `è¯­éŸ³è¯†åˆ«_${clipId.slice(0, 8)}`
      
      const mediaItem = unifiedStore.createUnifiedMediaItemData(
        mediaId,
        mediaName,
        asrSource,
        { mediaType: 'text', duration: estimatedDuration },
      )

      // æ·»åŠ åˆ°åª’ä½“åº“
      unifiedStore.addMediaItem(mediaItem)

      // æ·»åŠ åˆ°å½“å‰ç›®å½•
      if (unifiedStore.currentDir) {
        unifiedStore.addMediaToDirectory(mediaId, unifiedStore.currentDir.id)
      }

      // 6. å¯åŠ¨åª’ä½“å¤„ç†æµç¨‹
      unifiedStore.startMediaProcessing(mediaItem)

      loading.update({ progress: 100, details: t('timeline.speechRecognition.processing') })
      console.log('âœ… [ASR] ASRæµç¨‹å¯åŠ¨å®Œæˆ')

      loading.close()
      unifiedStore.messageSuccess(t('timeline.speechRecognition.success'))

    } catch (error) {
      loading.close()
      console.error('âŒ [ASR] è¯­éŸ³è¯†åˆ«å¤±è´¥:', error)
      unifiedStore.messageError(
        t('timeline.speechRecognition.error', {
          message: error instanceof Error ? error.message : String(error),
        })
      )
    }

    showContextMenu.value = false
  }

  /**
   * é‡å‘½åè½¨é“
   */
  function renameTrack() {
    if (contextMenuTarget.value.trackId) {
      const track = tracks.value.find((t) => t.id === contextMenuTarget.value.trackId)
      if (track) {
        startRename(track)
      }
      showContextMenu.value = false
    }
  }

  /**
   * æ˜¾ç¤ºæ·»åŠ è½¨é“èœå•
   * @param event é¼ æ ‡äº‹ä»¶ï¼ˆå¯é€‰ï¼‰
   */
  function showAddTrackMenu(event?: MouseEvent) {
    // å¦‚æœæ˜¯ç‚¹å‡»æŒ‰é’®è§¦å‘ï¼Œè·å–æŒ‰é’®ä½ç½®
    if (event) {
      const button = event.currentTarget as HTMLElement
      const rect = button.getBoundingClientRect()
      contextMenuOptions.value.x = rect.left
      contextMenuOptions.value.y = rect.bottom + 5
    } else {
      // é»˜è®¤ä½ç½®
      contextMenuOptions.value.x = 100
      contextMenuOptions.value.y = 100
    }

    contextMenuType.value = 'empty'
    contextMenuTarget.value = {}
    showContextMenu.value = true
  }

  /**
   * ä»å³é”®èœå•ä¸Šä¸‹æ–‡è·å–æ—¶é—´ä½ç½®
   * å°†å³é”®ç‚¹å‡»çš„å±å¹•åæ ‡è½¬æ¢ä¸ºæ—¶é—´è½´ä¸Šçš„å¸§æ•°ä½ç½®
   * @returns æ—¶é—´ä½ç½®ï¼ˆå¸§æ•°ï¼‰
   */
  function getTimePositionFromContextMenu(contextMenuOptions: { x: number }): number {
    // è·å–å³é”®ç‚¹å‡»çš„ä½ç½®
    const clickX = contextMenuOptions.x

    // è®¡ç®—ç›¸å¯¹äºæ—¶é—´è½´å†…å®¹åŒºåŸŸçš„ä½ç½®
    const timelineBodyRect = timelineBody.value?.getBoundingClientRect()
    if (!timelineBodyRect) {
      console.warn('âš ï¸ æ— æ³•è·å–æ—¶é—´è½´ä¸»ä½“è¾¹ç•Œï¼Œä½¿ç”¨é»˜è®¤ä½ç½®')
      return 0
    }

    // å‡å»è½¨é“æ§åˆ¶åŒºåŸŸçš„å®½åº¦
    const relativeX = clickX - timelineBodyRect.left - LayoutConstants.TRACK_CONTROL_WIDTH

    // è½¬æ¢ä¸ºå¸§æ•°
    const timeFrames = unifiedStore.pixelToFrame(relativeX, unifiedStore.TimelineContentWidth)

    // ç¡®ä¿æ—¶é—´ä½ç½®ä¸ä¸ºè´Ÿæ•°
    return Math.max(0, Math.round(timeFrames))
  }

  return {
    // çŠ¶æ€
    showContextMenu,
    contextMenuType,
    contextMenuTarget,
    contextMenuOptions,
    currentMenuItems,

    // æ–¹æ³•
    handleContextMenu,
    handleTimelineItemContextMenu,
    removeClip,
    duplicateClip,
    renameTrack,
    showAddTrackMenu,
    detectSceneBoundaries,
  }
}
